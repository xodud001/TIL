  # Chapter 1 하둡과의 만남

## 1.1 데이터!

- 수많은 곳에서 엄청난 데이터가 만들어지는중
- 특히 개인이 생산하는 디지털 스트림이 빠르게 증가하고 있음
- 공개 데이터의 크기 또한 매년 증가
    - 아마존 웹 서비스의 공개 데이터셋과 [Infochimps.org](http://Infochimps.org) 같은 정보 공유의 장이 열림

## 1.2 데이터 저장소와 분석

- 디스크의 용량은 엄청 증가했지만 데이터를 읽는 속도는 그에 미치지 못함
- 데이터를 읽는 속도를 줄이는 방법은 여러 개의 디스크에서 동시에 데이터를 읽는 것
- 여러 개의 디스크를 병렬로 쓰려면 몇몇 문제가 있음
    - 하드웨어 장애: 하드웨어를 사용할수록 장애가 발생할 확률도 높아짐. 여러곳에 데이터를 복제해서 해결. 이와 같은 방식이 RAID
    - 분할된 데이터의 결합. 1개의 디스크에서 읽은 데이터와 다른 디스크의 데이터를 결합해야 할지도 모름. 정합성을 지키는 것은 어려움
- 하둡은 안정적이고 확장성이 높은 저장 및 분석 플랫폼을 제공

## 1.3 전체 데이터에 질의하기

- 맵리듀스는 한 번의 쿼리로 전체나 상당한 규모의 데이터셋을 처리. 일괄 질의 처리기
- 전체 데이터셋을 대상으로 비정형 쿼리를 수행
- 이런 데이터를 통해 혁신의 기회를 얻음

## 1.4 일괄 처리를 넘어서

- 맵리듀스는 대화형 분석에는 적합하지 않음.
    - 지금은 이를 벗어나 진화중
- 하둡 에코시스템은 분산 컴퓨팅과 대규모 데이터 처리를 위한 기반 시설
- 하둡 기반에서 작동되는 다양한 처리 패턴
    - 대화형 SQL
    - 반복 처리
    - 스트림 처리
    - 검색

## 1.5 다른 시스템과의 비교

- 하둡은 데이터 저장과 분석을 위한 최초의 분산 시스템은 아님

### 1.5.1 관계형 데이터베이스 관리 시스템

- 관계형 DB는 데이터셋의 커다란 부분을 읽거나 쓰는 작업은 오래 걸릴것
- 일부 레코드를 변경하는 작업은 적합
- 맵리듀스는 비정형 분석과 같이 일괄 처리 방식으로 전체 데이터셋을 분석할 필요가 있는 문제에 적합
- 맵리듀스는 데이터를 한 번 쓰고 여러 번 읽는 애플리케이션에 적합. 관계형 DB는 지속적으로 변경되는 데이터셋에 적합

# 2. 맵리듀스

- 데이터 처리를 위한 프로그래밍 모델
- 다양한 언어로 작성된 맵리듀스 프로그램을 구동시킬 수 있음
- 병행성을 고려하여 설계됨

## 2.1. 기상 데이터셋

- 지구 전지역에서 매시간 데이터를 수집하는 기상 센서들은 대량의 로그 데이터를 모음
- 데이터가 반구조적이면서  레코드 지향적이기 때문에 맵리듀스를 이용한 데이터 분석에 적합

### 2.1.1. 데이터 포맷

- 데이터는 [국립기후자료센터](https://www.ncei.noaa.gov/)에서 받아서 사용
    - https://github.com/tomwhite/hadoop-book/ 저장소에 `input/ncdc`에 샘플 데이터 존재

```
# 국립기후자료센터의 레코드 형식
0057  
332130      # USAF 기상관측소 식별자
99999       # WBAN 기상관측소 식별자
19500101    # 관측 날짜
0300        # 관측 시간
4
+51317      # 위도 (위도 x 1000)
+028783.    # 경도 (경도 x 1000)
FM-12
+0171.      # 고도 (미터)
999999
V0202
320         # 바람 방향 (도)
1           # 특성 코드
N
0072
1
00450      # 구름 고도 (미터)
1          # 특성 코드
C
N
010000.    # 가시거리 (미터)
1          # 특성 코드
N
9
-0128      # 기온 (섭씨온도 x 10)
1          # 특성 코드
-0139      # 이슬점 온도 (섭씨온도 x 10)
1          # 특성 코드
10268.     # 대기 압력 (헥토파스칼 x10)
1          # 특성 코드
```

## 2.2. 하둡으로 데이터 분석하기

- 하둡이 제공하는 병렬 처리의 이점을 이용하기 위해서는 요구사항을 맵리듀스 잡으로 다시 표현

### 2.2.1. 맵과 리듀스

- 맵리듀스 작업은 크게 맵 단계와 리듀스 단계로 구분
- 각 단계는 입력과 출력으로 key-value의 쌍을 가지며, 타입은 프로그래머가 선택
- 프로그래머는 맵 함수와 리듀스 함수를 작성해야 함

### 2.2.2 자바 맵리듀스

**Mapper**

```java
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class MaxTemperatureMapper
  extends Mapper<LongWritable, Text, Text, IntWritable> {

  private static final int MISSING = 9999;
  
  @Override
  public void map(LongWritable key, Text value, Context context)
      throws IOException, InterruptedException {
    
    String line = value.toString();
    String year = line.substring(15, 19);
    int airTemperature;
    if (line.charAt(87) == '+') { // parseInt doesn't like leading plus signs
      airTemperature = Integer.parseInt(line.substring(88, 92));
    } else {
      airTemperature = Integer.parseInt(line.substring(87, 92));
    }
    String quality = line.substring(92, 93);
    if (airTemperature != MISSING && quality.matches("[01459]")) {
      context.write(new Text(year), new IntWritable(airTemperature));
    }
  }
}
```

**Reducer**

```java
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class MaxTemperatureReducer
  extends Reducer<Text, IntWritable, Text, IntWritable> {
  
  @Override
  public void reduce(Text key, Iterable<IntWritable> values,
      Context context)
      throws IOException, InterruptedException {
    
    int maxValue = Integer.MIN_VALUE;
    for (IntWritable value : values) {
      maxValue = Math.max(maxValue, value.get());
    }
    context.write(key, new IntWritable(maxValue));
  }
}
```

**Application**

```java
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class MaxTemperature {

  public static void main(String[] args) throws Exception {
    System.out.println(MaxTemperature.class.getPackage());
    if (args.length != 2) {
      System.err.println("Usage: MaxTemperature <input path> <output path>");
      System.exit(-1);
    }
    
    Job job = new Job();
    job.setJarByClass(MaxTemperature.class);
    job.setJobName("Max temperature");

    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    job.setMapperClass(MaxTemperatureMapper.class);
    job.setReducerClass(MaxTemperatureReducer.class);

    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}
```

**테스트 수행**

- jar 파일로 프로젝트 빌드 후 hadoop 명령어의 인자로 전달

```java
hadoop java hadoop-example.jar MaxTemperature sample.txt output
```

## 2.3 분산형으로 확장하기

- 확장을 위해서는 전체 데이터를 HDFS라는 분산 파일시스템에 저장할 필요가 있음
- 하둡은 데이터의 일부분이 저장된 클러스터의 각 머신에서 맵리듀스 프로그램을 실행
- 이를 위해 하둡은 YARN이라 불리는 하둡 자원 관리 시스템을 이용

### 2.3.1 데이터 흐름

- 맵리듀스 잡은 클라이언트가 수행하는 작업의 기본 단위
- 잡은 입력 데이터, 맵리듀스 프로그램, 설정 정보로 구성
- 하둡은 잡을 맵 태스크와 리듀스 태스크로 구분
- 각 태스크는 YARN을 이용항 스케줄링되고 노드에서 실행. 태스크 하나가 실패하면 자동으로 다른 노드를 재할당하여 다시 실행
- 맵리듀스 잡의 입력을 입력 스플릿이라 불리는 고정 크기 조각으로 분리. 각 스플릿마다 하나의 맵 태스크를 생성하고 각 레코드를 처리
- 스플릿이 작으면 부하 분산에 유리하지만 너무 작으면 관리의 오버헤드 때문에 실행 시간이 증가됨. 일반적인 잡의 적절한 스플릿 크지는 128MB가 적당
- 데이터 지역성 최적화: HDFS 내의 입력 데이터가 있는 노드에서 맵 태스크를 실행할 때 가장 빠르게 작동

### 2.3.2 컴바이너 함수

- 클러스터에서 맵리듀스 잡이 사용하는 네트워크 대역폭은 한계가 있기 때문에 맵과 리듀스 태스크 사이의 데이터 전송을 최소화할 필요가 있다
- 하둡은 맵의 결과를 처리하는 컴바이너 함수를 허용
    - 예로 최대값을 찾는 로직 같은 경우에는 각 맵에서 최대값을 찾아서 리듀스로 전달하면 데이터 전송량을 줄일 수 있음

## 2.4 하둡 스트리밍

- 자바 외에 다른 언어로 맵과 리듀스 함수를 작성할 수 있는 맵리듀스 API를 제공
- 하둡 스트리밍은 하둡과 사용자 프로그램 사이의 인터페이스로 유닉스 표준 스트림을 사용

# 3. 하둡 분산 파일시스템

- 데터가 단일 물리 머신의 저장 용량을 초과하게 되면 전체 데이터셋을 분리된 여러 머신에 나눠서 저장할 필요가 생김
- 네트워크로 연결된 여러 머신의 스토리지를 관리하는 파일시스템을 분산 파일시스템이라고 한다
- 하둡은 HDFS라는 분산 파일시스템을 제공

## 3.1 HDFS 설계

### 설계 특징

- 매우 큰 파일: 수백 메가, 기가, 테라, 페타 바이트
- 스트리밍 방식의 데이터 접근: 첫 번째 레코드를 읽는 데 걸리는 지연 시간보다 전체 데이터셋을 모두 읽을 때 걸리는 시간이 더 중요
- 범용 하드웨어 :노드 장애가 발생할 확률이 높은 범용 하드웨어로 구성된 대형 클러스터에서도 문제없이 실행되도록 설계

### 잘 맞지 않는 응용 분야

- 빠른 데이터 응답 시간
- 수많은 작은 파일

## 3.2 HDFS 개념

### 3.2.1 블록
- 블록 크기는 한 번에 읽고 쓸 수 있는 데이터의 최대량
- HDFS 블록은 기본적으로 128MB 단위
- HDFS의 파일은 단일 디스크를 위한 파일시스템처럼 특정 블록 크기의 청크로 쪼개지고 각 청크는 독립적으로 저장
- HDFS는 탐색 비용을 최소화하기 위해 크기가 큼
- 블록 추상화의 개념을 도입해서 얻은 이득
    - 파일 하나의 크기가 단일 디스크의 용량보다 더 클 수 있다
    - 스토리지의 서브시스템을 단순하게 만들 수 있음