# 5장 안정 해시 설계
- 수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요
- 이때 안정 해시를 보편적으로 사용

## 해시 키 재배치 문제

- N개의 캐시 서버가 있고 부하를 균등하게 나누기 위해 아래 해시 삼수를 사용
    + ServerIndex = hash(key) % N(서버 대수)
    + key0 키의 경우 해시가 18358617일때 % 4를 하면 1의 ServerIndex가 나온다
- 위 경우에서 서버의 풀에 변화가 생기면 문제가 발생
- 1번 서버로 가던 요청이 1번 서버의 장애로 서버 풀이 변경되면 해시 재배치가 일어나는데 이때 대규모 캐시 미스가 발생

## 안정 해시
- 해시 테이블 크기가 조정될 때 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술
    + k = 키의 개수
    + n = 슬롯의 개수
    + 전통적인 해시 테이블은 슬롯의 수가 변경되면 대부분 키를 재배치 함

### 해시 공간과 해시 링
- SHA-1로 예를 들때 해시 공간 범위는 0부터 2^160 - 1까지라 알려져 있음
- 따라서 x0은 0, xn은 2^160 - 1이다
- 이 해시 공간을 링으로 만들면 x0과 xn이 맞닿은 모양이 된다

### 해시 서버
- 이때 해시 함수를 사용해서 서버의 정보로 해시 링의 어떤 위치에 대응 시킬 수 있음
    + 해시 슬롯에 서버 정보로 해시 함수를 돌려 저장한다는 뜻

### 해시 키
- 이때 키에 해시 함수를 돌려 나머지 연산을 하지 않고 해시 키도 슬롯에 배치를 시킴

### 서버 조회
- 이때 저장된 해시 키는 시계 방향으로 링을 탐색하면서 만나는 첫 번째 서버를 조회함

### 서버 추가 및 제거
- 위 셜명한 내용에 따르면 서버를 추가 또는 제거하면 키 가운데 일부분만 재배치하면 됨
- 나머지 키에는 영향이 없음

## 기본 구현법의 두 가지 문제
- 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는게 불가능
- 키의 균등 분포를 달성하기가 어려움
- 해당 문제를 해결하기 위해 제안된 기법이 가상 노드 또는 복제 기법

### 가상 노드
- 실제 노드 또는 서버를 가리키는 노드로서 하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있다
- 가상 노드 개수를 늘리면 키의 분포는 점점 균등해 짐

# 6장 키-값 저장소 설계
- 키-값 저장소는 키-값 데이터베이스라고도 불리는 비 관계형 데이터베이스다
- 이 저장소에 저장되는 값은 고유 식별자를 키로 가져야 함
- 키와 값 사이의 연결 관계를 "키-값"쌍이라고 지칭
    + 키는 유일해야만 함
    + 값은 해당 키를 통해서만 접근 가능
- 키는 일반 텍스트일 수도 있고 해시 값 등이 될 수 있음
- 갑승ㄴ 문자열이나, 리스트, 객체 등일 수 있다
- 키-값 저장소로 널리 알려진것은 AWS 다이나모, memcached, Redis 등이 있다

## 문제 이해 및 설계 범위 확정
- 완벽한 설계란 없음
- 읽기, 쓰기, 메모리 사용량 사이에서 균형을 찾아 데이터 일관성과 가용성 사이에서 타협적 결정을 내리면 됨

## 단일 서버 키-값 저장소
- 가장 직관적인 방법은 키-값 쌍 전부를 메모리에 해시 테이블로 저장
    + 빠른 속도를 보장하긴 하지만 모든 데이터를 메모리에 두는 것이 불가능할 수 있음
    + 해결책으로는 데이터 압축, 자주 사용되는 데이터만 메모리에 적재 등이 있다

## 분산 키-값 저장소
- 분산 시스템을 설계할 때는 CAP 정리를 이해해야 함

```
CAP 정리
- 데이터 일관성(consistency), 가용성(availability), 파티션 감내(partition tolerance)라는 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리
```
- 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속하든 언제나 같은 데이터를 받아야 한다
- 가용성: 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다
- 파티션 감내: 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미. 파티션 감내는 네트워크에 파티션이 생기더라도 시스템은 계속 동작 해야함
- 위 요구사항 중 어떤 두 가지를 만족하면 하나는 반드시 희생해야 함
    + CP 시스템: 일관성과 파티션 감내를 지원. 가용성 희생
    + AP 시스템: 가용성과 파티션 감내를 지원. 데이터 일관성 희생
    + CA 시스템: 일관성과 가용성 지원. 파티션 감내 희생. 하지만 통상 네트워크 장애는 피할 수 없는 일로 여겨지므로, 분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계
- 은행 같은 곳은 데이터 일관성이 중요하기 때문에 CP 시스템을 사용할것이고 뉴스 같은 컨텐츠를 제공하는 곳은 가용성이 중요하기 때문에 AP 시스템을 사용

## 시스템 컴포넌트
- 키-값 저장소 구현에 사용될 핵심 컴포넌트들 및 기술

### 데이터 파티션
- 대규모 시스템의 경우 데이터를 나눠서 저장해야하는데 가장 단순한 방법은 작은 파티션들로 분할한 다음 여러 대 서버에 저장하는 것
- 파티션 단위로 나눌 때는 아래 두 가지 문제가 중요
    + 데이터를 여러 서버에 고르게 분산 가능한가
    + 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가
- 5장에서 다룬 안정 해시는 위 문제를 푸는데 적합
    + 규모 확장 자동화: 시스템 부하에 따라서 서버가 자동으로 추가되거나 삭제되도록 가능
    + 다양성: 각 서버의 용량에 맞게 가상 노드 수를 조정 할 수 있음

### 데이터 다중화
- 높은 가용성과 안정성을 확보하기 위해서 데이터를 N개 서버에 비동기적으로 다중화 할 필요가 있음
- N개 서버는 해시링 위에서 시계 방향으로 순회하며 만나는 N개의 서버에 데이터 사본을 저장
    + 가상 노드를 사용하면 선택한 N개의 노드가 대응될 실제 물리 서버의 개수가 N보다 작아질 수 있음
    + 그래서 노드 선택할 때 중복된 물리 서버를 선택하지 않도록 처리

### 데이터 일관성
- 여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 함
- 정족수 합의 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있음
    + N = 사본 개수
    + W = 쓰기 연산에 대한 정족수. 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 함
    + R = 읽기 연산에 대한 정족수. 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 함
    + R=1, W=N: 빠른 읽기 연산에 최적화
    + W=1, R=N: 빠른 쓰기 연산에 최적화
    + W+R > N: 강한 일관성이 보장됨
    + W+R <= N: 강한 일관성이 보장되지 않음

### 일관성 모델
- 일관성 모델은 데이터 일관성의 수준을 결정
- 강한 일관성: 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환
- 약한 일관성: 가장 최근에 갱신된 결과를 반환하지 못할 수 있음
- 최종 일관성: 갱신 결과가 결국에는 모든 사본에 반영되는 모델
    + 데이터에 버전 정보를 넣어 클라이언트에서 일관성이 깨진 데이터를 읽지 않도록 함

### 비 일관성 해소 기법: 데이터 버저닝
- 데이터를 다중화하면 사본 간 일관성이 깨질 가능성이 높음
- 버저닝과 벡터 시계로 문제를 해소할 수 있음
    + 버저닝: 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 생성. 각 버전의 데이터는 변경 불가능
    + 벡터 시계: 데이터 버저닝 과정에서 버전간 충돌이 발생했을 때 사용되는 기술로 [서버, 버전]의 순서쌍을 데이터에 매단 것

### 장애 처리
- 대규모 시스템에서 장애는 아주 흔한 일이기 때문에 장애를 어떻게 처리할 것인지는 굉장히 중요한 문제

### 장애 감지
- 분산 시스템에서는 노드 사이에 멀티캐스팅 채널을 구축해서 서로 장애를 감지할 수 있음
    + 서버가 많을 때는 비효율적인 방법
- gossip protocol 같은 분산형 장애 감지 솔루션이 효율적입
    + 각 노드는 멤버십 목록을 유지. 멤버심 목록은 각 멤버 ID와 해당 멤버의 heartbeat counter 쌍의 목록임
    + 각 노드는 주기적으로 자신의 heartbeat counter를 증가 시킴
    + 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기의 heartbeat counter 목록을 보냄
    + heartbeat counter 목록을 받은 노드는 멤버십 목록을 최신화
    + 어떤 멤버의 heartbeat counter 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주

### 일시적 장애 처리
- 장애를 감지한 시스템은 가용성을 보장하기 위해 필요한 조치를 해야 함
- 엄격한 정족수 접근법을 쓴다면 읽기와 쓰기 연산을 금지
- 느슨한 정족수 접근법을 쓴다면 쓰기 연산을 수행할 W개의 서버와 읽기 연산을 수행할 R개의 건강한 서버버를 해시 링에서 고름
- 네트워크나 서버 문제로 장애 상태인 서버로 가는 요청은 다른 서버로 우회
    + 해당 시간동안 발생한 변경 사항은 복구되었을 때 일괄 반영하여 데이터 일관성 보존
    + 이를 위해 연산을 처리한 서버는 단서를 남겨둠
    + 이런 장애 처리 방안을 단서 후 임시 위탁 기법이라 부름

### 영구 장애 처리
- hinted handoff 기법은 일시적 장애를 처리하기 위한 방법
- 영구적인 노드 장애 처리에는 반-엔트로피(anti_entropy) 프로토콜을 구현하여 사본들을 동기화
    + 사본들을 비교하여 최신 버전으로 갱신하는 과정
    + 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해서 Merkle 트리를 사용

```
머클 트리
- 해시 트리라고도 불리는 머클 트리는 각 노드에 그 자식 노드들에 보관된 값의 해시 또는 자식 노드들의 레이블로부터 계산된 해시 값을 레이블로 붙여두는 트리이다. 해시 트리를 사용하면 대규모 자료 구조의 내용을 효과적이면서도 보안상 안전한 방법으로 검증할 수 있다
```
1. 키 공간을 묶어서 버킷으로 나눔
2. 버킷별로 해시값을 계산한 후, 해당 버킷의 합을 다시 해시하여 해당 해시 값을 레이블로 갖는 노드를 만듬
3. 상향식으로 자식 노드의 레이블로부터 새로운 해시 값을 계산하여 이진 트리를 구성
4. 이렇게 완성된 두 머클 트리를 루트 노드부터 비교해서 틀린 부분만 찾아나감

### 데이터 센터 장애 처리
- 데이터 센터는 다양한 이유로 장애가 발생할 수 있다.
- 장애에 대응할 수 있는 시스템을 만들려면 여러 데이터 센터에 다중화하는 것이 중요

# 7장 - 분산 시스템을 위한 유일 ID 생성기 설계
- 분산 환경에서는 Auto Increment 속성을 사용하는 관계형 데이터베이스 기본키를 사용할 수 없음
    + 데이터베이스 서버 한 대로는 요청을 감당할 수 없고 여러 데이터베이스 서버를 쓰는 경우에는 지연 시간을 낮추기가 힘듬

## 1단계 - 문제 이해 및 설계 범위 확정
- ID는 어떤 특성을 갖나?
- 새로운 레코드에 붙일 ID는 항상 1만큼 큰 값이어야 하나?
- ID는 숫자로만 구성되나?
- 시스템 규모는 어느정도 인가?

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- 유일성이 보장되는 ID를 만드는 방법은 여러가지
    + 다중 마스터 복제
    + UUID
    + 티켓 서버
    + 트위터 스노플레이크 접근법

### 다중 마스터 복제
- 해당 접근법은 데이터베이스의 auto_increment 기능을 활용하는 것. 다만 다음 ID를 구할 때 K만큼 증가 시킴
    + K는 현재 사용 중인 데이터베이스 서버의 수
- 규모 확장성 문제를 해결할 수는 있지만 중대한 단점이 있음
    + 여러 데이터 센터에 걸쳐 규모를 늘리기 어려움
    + 유일성은 보장되겠지만 값이 시간 흐름에 맞추어 커지도록 보장할 수는 없음
    + 서버를 추가하거나 삭제할 때도 잘 동작하도록 만들기 어려움

### UUID
- 컴퓨터 시스템에 저장되는 정보를 유일하게 식별하기 위한 128비트짜리 수
- 각각의 웹 서버가 별도의 ID 생성기를 사용해 독립적으로 ID를 만들 수 있음
- 장점
    + UUID를 만드는 것은 단순함. 동기화 이슈도 없음
    + 각 서버가 ID를 알아서 만드는 구조이므로 규모 확장도 쉬움
- 단점
    + ID가 128비트로 김
    + 시간순으로 정렬할 수 없음
    + 숫자 아닌 값이 포함될 수 있음

### 티켓 서버
- auto_increment 기능을 갖춘 데이터베이스 서버를 중앙 집중형으로 사용
- 장점
    + 유일성 보장이 되는 숫자로만 구성된 ID를 쉽게 만듬
    + 구현하기 쉽고, 중소 규모 애플리케이션에 적합
- 단점
    + 티켓 서버가 SPOF(Single-Point-of-Failure)가 됨

### 트위터 스노플레이크 접근법
+ 생성해야 하는 ID의 구조를 여러 절로 분할해 생성
    + 사인 비트: 1비트 할당. 쓰임새가 없지만 나중을 위해 유보
    + 타임스탬프: 41비트 할당. epoch(기원 시각)) 이후로 몇 밀리초가 경과했는지를 나타내는 값
    + 데이터센터 ID: 5비트 할당
    + 서버 ID: 5비트 할당
    + 일련번호: 12비트 할당. 각 서버에서 ID를 생성할 때마다 해당 일련번호를 1만큼 증가. 1밀리초가 지날때마다 0으로 초기화

# 8장 - URL 단축기 설계

## 1단계 - 문제 이해 및 설계 범위 확정
- 항상 성공적으로 설계하려면 질문을 통해 모호함을 줄이고 요구사항을 알아야 함
    + 쓰기 연산: 매일 1억 개의 단축 URL 생성
    + 초당 쓰기 연산: 1160
    + 읽기 연산: 읽기 연산과 쓰기 연산 비율을 10:1로 하면 초당 11,600회
    + 10년간 운영한다고 하면 3650억개의 레코드를 보관
    + 축약 전 URL의 평균 길이는 100정도
    + 10년동안 필요한 저장 용량은 3650억 X 100바이트 = 36.5TB

## 2단계 - 개략적 설계안 제시 및 동의 구하기

### API 엔드포인트
- URL 단축기에는 기본적으로 두 개의 엔드포인트가 필요
    + URL을 단축을 위한 엔드포인트: 클라이언트가 단축하고자 하는 URL을 담아서 POST 요청을 보냄
    + URL 리디렉션용 엔드포인트: 단축 URL에 대해서 원래 URL로 보내주기 위한 용도

### URL 리디렉션
- 단축 URL을 받은 서버는 해당 URL을 원래 URL로 바꾸어서 301응답의 Location 헤더에 넣어 반환
    + 301 Permanently Moved: 해당 URL에 대한 HTTP 요청의 처리 책임이 영구적으로 Location 헤더에 반환된 URL로 이전되었다는 뜻
    + 302 Found: 주어진 URL로의 요청이 일시적으로 Location 헤더가 지정하는 URL에 의해 처리되어야 한다는 응답
- 서버 부하를 줄일때는 301이 좋고 트래픽 분석이 중요할 때는 302를 쓰는 쪽이 좀더 유리
- URL 리디렉션을 구현하는 가장 직관적인 방법은 해시 테이블을 사용

### URL 단축
- 중요한 것은 긴 URL을 해당 해시 값으로 대응시킬 해시 함수 fx를 찾은 것
- 해시 함수는 아래 요구사항을 만족
    + 입력으로 주어지는 긴 URL이 다른 값이면 해시 값도 달라야 한다
    + 계산된 해시 값은 원래 입력으로 주어졌던 긴 URL로 복원될 수 있어야 함

## 3단계 - 상세 설계

### 데이터 모델
- 개략적 설계에서는 모든 것을 해시 테이블에 두었지만 실제 시스템에 적용하기는 곤란
- 더 좋은 방법으로는 관계형 데이터베이스에 쌍을 저장
    + id, shortURL, longURL의 세 개 칼럼을 가짐

### 해시 함수
- 원래 URL을 단축 URL로 변환하는 데 사용

#### 해시 값 길이
- hashValue는 [0-9, a-z, A-Z]의 문자들로 구성
- 사용할 수 있는 문자의 개수는 62개. 10 + 26 + 26 = 62
- hashValue 길이를 정하기 위해서는 62^n >= 3650억인 n의 최솟값을 찾아야 함
    + n=7이면 3.5조개의 URL을 만들 수 있음

#### 해시 후 충돌 해소
- CRC32, MD5, SHA-1 같은 해시 함수를 이용해 단축 후 앞에 7자를 사용하면 충돌 확률이 높아 짐
- 첫번째 방법은 충돌이 해소될 때까지 사전에 정한 문자열을 해시값에 덧붙임
    + 충돌은 해소할 수 있지만 데이터베이스 질의를 해야하므로 오버헤드가 큼

#### base-62 변환
- 진법 변환은 URL 단축기를 구현할 때 흔히 사용되는 접근법
- 해당 기법은 수의 표현 방식이 다른 두 시스템이 같은 수를 공유하여야 하는 경우에 유용
- hashValue의 문자 개수가 62개이기 때문에 base-62 사용
- 62진법은 0은 0, 9는 9, a는 11... 61은Z로 대응시켜 표현
- ID의 유일성이 보장되진 않음

### URL 단축기 상세 설계
1. 입력으로 긴 URL을 받음
2. 데이터베이스에 해당 URL이 있는지 검사
3. 있다면 단축 URL을 가져와 반환
4. 없다면 DB의 기본기로 사용된 유일한 ID를 생성
5. 62진법 변환을 적용. ID를 단축 URL로 생성
6. ID, 단축 URL, 원래 URL로 새 데이터베이스 레코드를 만든 후 단축 URL을 클라이언트에 전달

# 9장 - 웹 크롤러 설계
- 웹 크롤러: 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아내는 것이 주된 목적
- 크롤러가 이용되는 방법
    + 검색 엔진 인덱싱
    + 웹 아카이빙: 장기보관하기 위해 웹에서 정보를 모으는 절차
    + 웹 마이닝
    + 웹 모니터링: 인터넷에서 저작권이나 상표권이 침해되는 사례를 모니터링 할 수 있음

## 1단계 - 문제 이해 및 설계 범위 확정
- 웹 크롤러의 기본 알고리즘은 간단함
    1. URL 집합이 주어지면, 해당 URL들이 가리키는 모든 웹 페이지를 다운로드
    2. 다운받은 웹 페이지에서 URL을  추출
    3. 추출된 URL들을 다운로드할 URL 목록에 추가하고 1번부터 반복
- 엄청난 규모 확장성을 갖는 웹 크롤러를 설계하는 것은 엄청나게 어려운 작업. 설계 하기 전 요구사항을 알아내고 설계 범위를 좁히는게 중요
    + 크롤러의 주된 용도
    + 수집해야하는 웹 페이지 수
    + 새로 만들어졌거나 수정된 웹 페이지도 포함
    + 저장 여부
    + 중복 콘텐츠 처리
    + 규모 확장성
    + 안정성: 잘못된 링크들에 대해서 잘 대응할 수 있어야 됨
    + 예절: 수집 대상 웹 사이드에 짧은 시간 동안 너무 많이 요청하면 안됨
    + 확장성

### 개략적 규모 추정
- 매달 10억 개의 웹 페이지를 다운로드해야 함
- QPS=10억 / 30일 / 24시간 / 3600초 = 약 400페이지/초
- 최대 QPS = 2 X QPS = 800
- 웹 페이지의 크기 평균은 500k라고 가정
- 10억 페이지 x 500k = 500TB/월
- 1개월치 데이터를 보관하는 데는 500TB. 5년간 보관한다고 가정하면 500TB X 12개월 X 5년 = 30PB의 저장용량 필요

## 2단계 - 개략적 설계안 제시 및 동의 구하기
1. 시작 URL 집합 -> 2. 미수집 URL 저장소 -> 3. HTML 다운로더 -> 4. 컨텐츠 파서 -> 5. 중복 컨텐츠?
-> 6. URL 추출기 -> 7. URL 필터 -> 8. 이미 방문한 URL? -> <8-예>: 2 | <8-아니오>: 10. URl 저장소

### 시작 URL 집합
- 크롤러가 크롤링을 시작하는 출발점
- 특정 대학 웹사이트로부터 찾아 나갈 수 있는 모든 웹 페이지를 크롤링하는 가장 직관적인 방법은 해당 대학의 도메인 이름이 붙은 모든 페이지의 URL을 시작 URL로 사용

### 미수집 URL 저장소
- 웹 크롤러는 크롤링 상태를 다운로드할 URL과 다운로드된 URL 두 가지로 나눠 관리
- 다운로드할 URL을 관리하는 컴포넌트를 미수집 URL 저장소라고 부른다

### HTML 다운로더
- 인터넷에서 웹 페이지를 다운로드하는 컴포넌트

### 도메인 이름 변환기
- 웹 페이지를 다운받으려면 URL을 IP 주소로 변환하는 절차가 필요
- HTML 다운로더는 도메인 이름 변환기를 사용하여 URl에 대응되는 IP 주소를 알아낸다

### 콘텐츠 파서
- 웹 페이지를 다운로드하면 파싱과 검증 절차를 거쳐야 함
- 이상한 웹 페이지는 문제를 일으킬 수 있고 저장 공강만 낭비하게 됨

### 중복 콘텐츠인가?
- 연구 결과에 따르면, 29% 가량의 웹 페이지 콘텐츠는 중복임
- 위 문제를 해결하기 위해 자료 구조를 도입해서 데이터 중복을 줄이고 데이터 처리에 소요되는 시간을 줄임

### 콘텐츠 저장소
- HTML 문서를 보관하는 시스템
- 저장소를 구현할때는 저장할 데이터의 유형, 크기, 저장소 접근 빈도, 데이터의 유효 기간 등을 종합적으로 고려

### URL 추출기
- HTML 페이지를 파싱하여 링크들을 골라내는 역할을 함
    + HTML 페이지 내의 상대 경로를 전부 도메인을 붙여 절대 경로로 변환

### URL 필터
- 특정한 콘텐츠 타입이나 파일 확장자를 갖는 URL, 접속 시 오류가 발생하는 URL, 접근 제외 목록에 포함된 URL 등을 크롤링 대상에서 배제하는 역할을 함

### 이미 방문한 URL?
- 이 단계를 위해서 보간된 URL을 추적할 수 있도록 하는 자료 구조를 사용
- 해당 기능으로 같은 URL을 여러번 처리하는 일을 방지할 수 있고 시스템이 무한 루프에 빠지는 일을 방지할 수 있음
- 해당 자료 구조는 블룸 필터를 이용

```
블룸 필터
원소가 집합에 속하는지 여부를 검사하는데 사용되는 확률적 자료 구조.
어떤 원소가 집합에 속한다고 판단된 경우 실제로는 원소가 속하지 않는 긍정 오류가 발생하는 것이 가능하지만, 반대로 원소가 집합에 속하지 않는 것으로 판단되었는데 실제로는 원소가 집합에 속하는 부정 오류는 절대 발생하지 않음.
집합에 원소를 추가하는 것은 가능하나, 집합에서 원소를 삭제하는 것은 불가능
```

### URL 저장소
- 이미 방문한 URL을 보관하는 저장소

## 3단계 - 상세 설계
- 아래는 가장 중요한 컴포넌트 목록
    + DFS vs BFS
    + 미수집 URL 저장소
    + HTML 다운로더
    + 안정성 확보 전략
    + 확장성 확보 전략
    + 문제 있는 콘텐츠 감지 및 회피 전략

### DFS를 쓸 것인가, BFS를 쓸 것인가
- 웹은 유향 그래프(directed graph) 같다
    + 페이지가 노드이고 하이퍼링크가 에지라고 보면 됨
- 크롤링 프로세스는 유향 그래프를 에지를 따라 탐색하는 과정
- DFS는 좋은 선택이 아닐 가능성이 높음
    + 그래프 크기가 클 경우 어느 정도로 깊숙이 가게 될지 가늠이 어려움
- 그래서 웹 크롤러는 보통 BFS를 사용
    + FIFO 방식으로 탐색할 URL을 넣고 한쪽에서 꺼내서 처리한다
- 하지만 BFS에는 두 가지 문제 점이 있음
    + 한 페이지에서 나오는 링크는 대부분 같은 서버로 되돌아 감. 그럼 크롤러는 같은 호스트에 속한 많은 링크를 받게되고 다운을 병렬로 처리하게 되면 해당 서버는 수많은 요청으로 과부하에 걸림. 이 같은 크롤러를 보통 예의 없는(impolite) 크롤러라 함
    + 표준적 BFS 알고리즘은 URl 간에 우선순위를 두지 않음

### 미수집 URL 저장소
- 해당 저장소를 활용하면 위 문제를 쉽게 해결할 수 있음
- 해당 저장소를 잘 구현하면 예의를 갖춘 크롤러, URL 사이의 우선순위와 신선도를 구별하는 크롤러를 구현할 수 있음

### HTML 다운로더
- HTTP 프로토콜을 통해 웹 페이지를 내려 받음

#### Robots.txt
- 로봇 제외 프로토콜이라고도 부르는 Robots.txt는 웹사이트가 크롤러와 소통하는 표준적 방법임
    + 해당 파일에는 크롤러가 수집해도 되는 페이지 목록이 들어 있음

#### 성능 최적화
1. 분산 크롤링 : 성능을 높이기 위해 크롤링 작업을 여러 서버에 분산하는 방법
2. 도메인 이름 변환 결과 캐시: 도메인 이름 변환기는 크롤러 성능 병목 중 하나. DNS 요청을 보내고 결과를 받는 동기적 특성 때문. 크롤러 스레드 가운데 하나가 이 작업을 하고 있으면 다른 스레드의 DNS 요청은 전부 블록됨. 그래서 결과를 캐시하고 크론 잡 등을 돌려 주기적으로 갱신하도록 해 놓으면 성능을 효과적으로 높일 수 있다
3. 지역성: 크롤링 작업을 수행하는 서버를 지역별로 분산. 크롤링 서버가 대상 서버와 지역적으로 가짜우면 다운로드 시가이 줄어들것
4. 짧은 타임아웃: 어떤 웹 서버는 응답이 느리거나 아예 응답하지 않음. 그래서 최대 얼마나 기다릴지를 미리 정해 둠

### 안정성
- 안정성도 다운로더 설계 시 중요하게 고려해야 함
- 안정성을 향상시키기 위한 접근법 가운데 중요한 몇 가지
    + 안정 해시
    + 크롤링 상태 및 수집 데이터 저장: 장애가 발생한 경우에도 쉽게 복구할 수 있도록 크롤링 상태와 수집된 데이터를 지속적 저장장치에 기록해 두는것이 바람직
    + 예외 처리: 대규모 시스템에서 에러는 흔하게 일어남. 예외가 발생해도 전체 시스템이 중단되는 일 없이 작업을 우아하게 이어나갈 수 있어야 한다
    + 데이터 검증: 시스템 오류를 방지하기 위한 중요한 수단

### 확장성
- 시스템은 계속 진화하기 때문에, 새로운 형태의 콘텐츠를 쉽게 지원할 수 있도록 신경 써야 함

### 문제 있는 콘텐츠 감지 및 회피
1. 중복 콘텐츠
    - 웹 콘텐츠의 30% 가량은 중복임. 해시나 체크섬을 사용해서 중복 콘텐츠를 쉽게 탐지
2. 거미 덫
    - 크롤러를 무한 루프에 빠뜨리도록 설계한 웹 페이지
    - URL의 최대 길이를 제한해서 회피
3. 데이터 노이즈
    - 가치가 없는 콘텐츠도 있기 때문에 가능한한 제외할 수 있도록 처리

# 10장 - 알림 시스템 설계
- 알림 시스템은 모바일 푸시 알림, SMS 메시지, 이메일 세 가지로 분류

## 1단계 - 문제 이해 및 설계 범위 확정
- 푸시 알림, SMS 메시지, 이메일 지원
- 연성 실시간(soft real-time) 시스템 <-> 경성 실시간(hard real-time)
- iOS 단말, 안드로이드 단말, 랩톱/데스크톱 지원
- 클라이언트 애플리케이션 또는 서버 측에서 스케줄링으로 알람 생성
- 알림 거부 설정 여부
- 하루에 보내야할 알림 횟수
    - 모바일 푸시 알림: 10,000,000건
    - SMS 메시지: 1,000,000건
    - 이메일: 5,000,000건

## 2단계 개략적 설계안 제시 및 동의 구하기

### 알림 유형별 지원 방안
- 각 알림 메커니즘이 어떻게 동작하는지부터 이해

#### iOS 푸시 알림
- iOS에서 푸시 알림을 보내기 위해서는 세 가지 컴포넌트가 필요
    + 알림 제공자: 알림 요청을 만들어 애플 푸시 알림 서비스(APNS)로 보내는 주체
    + APNS: 애플이 제공하는 원격 서비스. 푸시 알림을 iOS 장치로 보내는 역할을 담당
    + iOS 단말: 푸시 알림을 수신하는 사용자 단말

#### 안드로이드 푸시 알림
- 안드로이드 푸시 알림은 APNS 대신 FCM을 사용하는 점을 제외하면 APNS와 동일

#### SMS 메시지
- 보통 트윌리오, 넥스모 같은 제3 사업자의 서비스를 많이 이용
- 대부분 사용 서비스라서 이용요금을 내야 함

#### 이메일
- 대부분 이메일 서버를 구축할 역량은 있지만, 그럼에도 상용 이메일 서비스를 이용
- 대표적으로 센드그리드, 메일침프가 있음. 전송 성공률도 높고, 데이터 분석 서비스도 제공

### 연락처 정보 수집 절차
- 알림을 보내려면 모바일 단말 토큰, 전화번호, 이메일 주소 등의 정보가 필요
- 사용자가 앱을 처음 설치하거나 처음 계정을 등록하면 API 서버는 해당 사용자의 정보를 수집하여 데이터베이스에 저장

### 알림 전송 및 수신 절차
- 개략적 설계안(초안)
    + 서비스 -> 알림 시스템 -> 제3자 서비스 -> 단말
    + 1부터 N까지의 서비스: 알림 시스템으로 알림 전송 요청을 보내는 시스템의 서비스
    + 알림 시스템: 알림 전송/수신 처리의 핵심
    + 제3자 서비스: 사용자에게 알림을 실제로 전달하는 역할을 함
    + iOS, 안드로이드, SMS, 이메일 단말: 사용자가 이메일을 수신할 때 사용하는 단말
- 위 설계의 문제
    + SPOF: 알림 서비스에 서버가 하나밖에 없다는 것은 알림 시스템에 장애가 생기면 전체 서비스의 장애로 이어짐
    + 규모 확장성: 한 대 서비스로 푸시 알림에 관계된 모든 것을 처리하므로, 데이터베이스나 캐시 등 중요 컴포넌트의 규모를 개별적으로 늘릴 방법이 없다
    + 성능 병목: 알림을 처리하고 보내는 것은 자원을 많이 필요로 하는 작업. 한 서버로 처리하면 사용자 트래픽이 많이 몰리는 시간에는 시스템이 과부하 상태에 빠질 수 있음

- 개략적 설계안(개선된 버전)
    + 데이터베이스와 캐시를 알림 시스템의 주 서버에서 분리해 별도로 관리
    + 알림 서버를 증설하고 자동으로 수평적 규모 확장이 이루어질 수 있도록 한다
    + 메시지 큐를 이용해 시스템 컴포넌트 사이의 강한 결합을 끊음
    + 메시지 큐에서 전송할 알림을 꺼내서 제3자 서비스로 전달하는 작업 서버 추가
- 컴포넌트들이 협력하여 알림을 전송하게 되는 방법
    1. API를 호출하여 알림 서버로 알림을 전송
    2. 알림 서버는 사용자 정보, 단말 토큰, 알림 설정 같은 메타데이터를 캐시나 데이터베이스에서 가져옴
    3. 알림 서버는 전송할 알림에 맞는 이벤트를 만들어서 해당 이벤트를 위한 큐에 넣음
    4. 작업 서버는 메시지 큐에서 알림 이벤트를 꺼냄
    5. 작업 서버는 알림을 제3자 서비스로 보냄
    6. 제3자 서비스는 사용자 단말기로 알림을 전송
## 3단계 - 상세 설계
- 상세 설계에서 아래 내용을 좀 더 자세히 알아봄
    + 안정성(reliability)
    + 추가로 필요한 컴포넌트 및 고려사항: 알림 템플릿, 알림 설정, 전송률 제한, 재시도 메커니즘, 보안, 큐에 보관된 알림에 대한 모니터링과 이벤트 추적

### 안정성
- 분산 환경에서 운영될 알림 시스템을 설계할 때는 안정성을 확보하기 위한 사항 몇 가지를 반드시 고려

#### 데이터 손실 방지
- 가장 중요한 요구사항 가운데 하나는 어떤 상황에서도 알림이 소실되면 안 된다는 것
- 알림이 지연되거나 순서가 틀려도 괜찮지만 사라지면 곤란함
- 그래서 알림 데이터를 데이터베이스에 보관하고 재시도 메커니즘을 구현해야 됨

#### 알림 중복 전송 방지
- 같은 알람이 여러 번 전송되는 것을 완전히 막는 것은 불가능
- 분산 시스템의 특성상 가끔은 같은 알림이 중복되어 전송됨
- 간단하게 알림 중복을 검사하려면 알림에 ID를 부여하고 이전에 전송된 이벤트인지 보고 전송 여부 결정

### 추가로 필요한 컴포넌트 및 고려사항
- 알림 시스템은 위 내용 보다 훨씬 복잡하기 때문에 알림 템플릿, 알림 설정, 이벤트 추적, 시스템 모니터링, 처리율 제한 등 알림 시스템 구현을 위해 필요한 추가 컴포넌트을 자세히 보자

#### 알림 템플릿
- 대형 알림 시스템은 하루에 수백만 건 이상의 알림을 처리
- 대부분의 알림 메시지는 형식이 비슷해서 모든 부분을 처음부터 다시 만들 필요 없도록 해줌

#### 알림 설정
- 사용자는 대부분 많은 알림을 받고 있어서 쉽게 피곤함을 느낌
_ 따라서 사용자가 알림 설정을 상세히 조정할 수 있도록 함

#### 전송률 제한
- 한 사용자가 받을 수 있는 알림의 빈도를 제한
- 너무 많은 알림을 보내면 사용자가 알림을 아예 꺼 버릴 수도 있음

#### 재시도 방법
- 제3자 서비스가 알림 전송에 실패하면, 해당 알림을 재시도 전용 큐에 넣음

#### 푸시 알림과 보안
- iOS와 안드로이드 앱의 경우 알림 전송 API는 appKey와 appSecret을 사용하여 보안 유지

#### 큐 모니터링
- 알림 시스템을 모니터링 할 때 중요한 메트릭중 하나는 큐에 쌓인 알람의 개수임
- 알림 개수를 보며 작업 서버를 조절

#### 이벤트 추적
- 알림 확인율, 클릭율, 실제 앱 사용으로 이어지는 비율 같은 메트릭이 사용자를 이해하는데 중요함

# 11장 - 뉴스 피드 시스템 설계
- 뉴스 피드는 우리 홈 페이지 중앙에 지속적으로 업데이트되는 스토리들

## 1단계 - 문제 이해 및 설계 범위 확정
- 모바일 앱, 웹 둘 다 지원
- 사용자가 뉴스 피드 페이지에 새로운 스토리를 올릴 수 있어야 하고, 친구들이 올리는 스토리를 볼 수도 있어야 함
- 포스팅은 시간 흐름 역순으로 정렬
- 한 명의 사용자는 최대 5,000명의 친구를 가질 수 있음
- 트래픽 규모는 매일 천만 명이 방문
- 피드에는 이미지나 비디오도 포함 가능

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- 크게 설계안은 피드 발행과 뉴스 피드 생성으로 나뉨
    + 피드 발행: 사용자가 스토리를 포스팅하면 해당 데이터를 캐시와 데이터베이스에 기록
    + 뉴스 피드 생성: 지면 관계상 뉴스 피드는 모든 친구의 포스팅을 시간 흐름 역순으로 모아서 만든다고 가정

### 뉴스 피드 API
- HTTP 기반으로 상태 정보 업데이트, 뉴스 피드 가져오기, 친구 추가 등의 다양한 작업을 수행하는데 사용

#### 피드 발행
- 사용자: 모바일 앱이나 브라우저에서 새 포스팅을 올리는 주체
- 로드밸런서: 트래픽들을 웹 서버들로 분산
- 포스팅 저장 서비스: 새 포스팅을 데이터베이스와 캐시에 저장
- 포스팅 전송 서비스: 새 포스팅을 친구의 뉴스 피드에 푸시. 뉴스 피드 데이터는 캐시에 보관하여 빠르게 읽을 수 있도록 처리
- 알림 서비스: 새 포스팅이 올라왔음을 알림

#### 뉴스 피드 생성
- 사용자: 뉴스 피드를 읽는 주체
- 로드 밸런서: 트래픽을 웹 서버들로 분산
- 웹 서버: 트래픽을 뉴스 피드 서비스로 보냄
- 뉴스 피드 서비스: 캐시에서 뉴스 피드를 가져옴
- 뉴스 피드 캐시: 뉴스 피드를 렌더링할 때 필요한 피드 ID를 보관

## 3단계 - 상세 설계
- 뉴스 피드 발행과 생성의 두 가지 설계를 보다 상세히 정리

### 피드 발행 흐름 상세 설계
- 컴포넌트 자체는 개략적 설계안에서 다룬 정도로 충분
- 웹 서버와 포스팅 전송 서비스에 초점

#### 웹 서버
- 클라이언트와 통신, 인증 처리, 처리율 제한 등의 기능도 수행

#### 포스팅 전송(팬아웃) 서비스
- 포스팅 전송(fanout)은 어떤 사용자의 새 포스팅을 그 사용자와 친구 관계에 있는 모든 사용자에게 전달하는 과정
- 팬아웃에는 두 가지 모델이 있음
    + 쓰기 시점에 팬아웃(push 모델)
    + 읽기 시점에 팬아웃(pull 모델)
- 쓰기 시점에 하는 팬아웃: 새로운 포스팅을 기록하는 시점에 뉴스 피드를 갱신
    + 장점
        1. 뉴스 피드가 실시간으로 갱신되며 친구 목록 사용자에게 즉시 전송
        2. 새 포스팅이 기록되는 순간에 뉴스 피드가 갱신 되므로 뉴스 피드를 읽는데 드는 시간이 짧아짐
    + 단점
        1. 친구가 많은 사용자의 경우 친구 목록을 가져오고 해당 목록에 있는 사용자 모두의 뉴스 피드를 갱신하는 데 많은 시간이 소요
        2. 서비스를 자주 이용하지 않는 사용자의 피드까지 갱신해야 하므로 컴퓨팅 자원이 낭비됨
- 읽기 시점에 팬아웃: 피드를 읽어야 하는 시점에 뉴스 피드를 갱신
    + 장점
        1. 비활성화된 사용자에 대한 자원 소모가 없음
        2. 데이터를 모든 친구들에게 푸시하는 작업이 필요 없으므로 핫키 문제가 발생하지 않음
    + 단점
        1. 뉴스 피드를 읽는 데 많은 시간이 소요될 수 있음
- 해당 설계안에서는 두 가지 방법을 결합하여 장점은 취하고 단점은 버림
    + 대부분의 사용자에 대해서는 푸시 모델 선택
    + 친구가 아주 많은 사용자의 경우에는 팔로어로 하여금 피드를 가져올 때 풀 모델을 사용하여 시스템 과부하 방지
    + 추가로 안정 해시를 통해 요청과 데이터를 보다 고르게 분산하여 핫키 문제를 줄임

# 12장 - 채팅 시스템 설계
- 채팅 시스템은 종류가 제각각이기 때문에 요구사항을 확실하게 해야됨

## 1단계 - 문제 이해 및 설계 범위 확정
- 1:1과 그룹 채팅 모두 지원
- 모바일 앱과 웹 모두 지원
- 트래픽은 일별 능동 사용자 수 기준으로 5천만 명 처리 가능 해야함
- 그룹 채팅은 최대 100명까지 참가
- 중요 기능
    + 1:1 채팅
    + 그룹 채팅
    + 사용자 접속상태 표시
    + 텍스트 메시지만 주고 받을 수 있음
- 메시지 길이는 100,000자 이하
- 종단 간 암호화는 필요 없음
- 채팅 이력은 영원히 보관

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- 클라이언트가 직접 통신하지 않기 때무넹 클라이언트와 서버의 통신 방법에 대한 기본적인 지식이 있어야 됨
- 채팅 서비스는 아래 기능을 제공해야 됨
    + 클라이언트들로부터 메시지 수신
    + 메시지 수신자 결정 및 전달
    + 수신자가 접속 상태가 아닌 경우에는 접속할 때까지 해당 메시지 보관
- 메시지 송신 클라이언트 -> 채팅 서비스(메시지 저장 및 전달 -> 메시지 수신 클라이언트
- 메시지 전송에는 HTTP 메시지, 폴링, 롱 폴링, 웹소켓 등을 사용할 수 있다

### 폴링
- 클라이언트가 주기적으로 서버에게 새 메시지가 있는지 확인하는 방법
- 폴링은 받을 메시지가 없는 경우 서버 자원이 불필요하게 낭비되는 문제 발생

### 롱 폴링
- 폴링이 여러 가지로 비효울적이라 나온 기법
- 클라이언트가 새 메시지를 받거나 타임아웃 될 때까지 연결을 유지
- 새 메시지를 받으면 기존 연결을 종료하고 새로운 요청을 보내어 위 절차를 다시 시작
- 약점
    + 메시지를 보내는 클라이언트와 수신하는 클라이언트가 같은 채팅 서버에 접속하게 되지 않을 수도 있음
    + 서버 입장에서는 클라이언트가 연결을 해제했는지 아닌지 알 방법이 없음
    + 여전히 비효율적임. 메시지를 많이 받지 않는 클라이언트도 타임아웃이 일어날 때마다 주기적으로 서버에 다시 접속

### 웹소켓
- 서버가 클라이언트에게 비동기 메시지를 보낼 때 가장 널리 사용하는 기술
- 연결은 클라이언트가 시작
- 한번 맺어진 연결은 항구적이며 양방향이다
- 웹소켓은 첫 연결은 HTTP 이지만 특정 핸드셰이크 절차를 거쳐 웹소켓 연결로 업그레이드 됨
- 서버 측에서 연결 관리를 효율적으로 해야 함

### 개략적 설계안
- 클라이언트와 서버 사이의 주 통신 프로토콜로 웹소켓을 사용하기로 했지만 대부분의 기능은 일반적인 HTTP 상에서 구현해도 됨
- 채팅 시스템은 세 부분으로 나누어 볼 수 있음
    + 무상태 서비스
    + 상태유지 서비스
    + 제3자 서비스 연동

#### 무상태 서비스
- 무상태 서비스는 로그인, 회원가입, 사용자 프로파일 표시 등을 처리하는 전통적인 요청/응답 서비스
- 무상태 서비스는 로드밸런서 뒤에 위치, 로드밸런서는 요청을 그 경로에 맞는 서비스로 정확하게 전달

#### 상태 유지 서비스
- 해당 설계안에서 상태 유지가 필요한 서비스는 채팅 서비스임
- 각 클라이언트가 채팅 서버와 독립적인 네트워크 연결을 유지해야 됨

#### 제3자 서비스 연동
- 채팅 앱에서 가장 중요한 제3자 서비스는 푸시 알림

#### 규모 확장성
- 트래픽 규모가 얼마 되지 않을 때는 모든 기능을 서버 한 대로 구현할 수 있다
- 하지만 트래픽이 커진다면 서버 한대에 모든 기능을 담는건 위험함
    + SPOF가 될 수 있음
    + 트래픽이 몰릴때 대처가 안됨

#### 저장소
- 기술 스택 깊은 곳에 데이터 계층이 있고, 데이터 계층을 올바르게 만드는 데는 노력이 필요함
- 일반적인 사용자 프로파일, 설정, 친구 목록 같은 데이터는 관계형 데이터베이스에 저장
- 채팅 이력은 데이터가 어마어마하고 읽기:쓰기 비율이 대략 1:1 정도이기 때문에 키-값 저장소 추천
    + 키-값 저장소는 수평적 규모확장이 쉽다
    + 키-값 저장소는 데이터 접근 지연시간이 낮다
    + 관계형 데이터베이스는 데이터 가운데 롱 테일에 해당하는 부분을 잘 처리하지 못하는 경향이 있음. mysql의 offset 문제
    + 이미 많은 안정적인 채팅 시스템이 키-값 저장소를 채택

## 3단계 - 상세 설계
- 채팅 시스템에서는 서비스 탐색, 메시지 전달 흐름, 사용자 접속 상태 표시 방법 정도가 자세히 살펴볼 만한 부분

### 서비스 탐색
- 클라이언트에게 가장 적합한 채팅 서버를 추천
- 많이 사용되는 오픈 소스 솔루션으로는 아파치 주키퍼 같은 것이 있음
    + 사용 가능한 모든 채팅 서버를 주키퍼에 등록하고, 클라이언트가 접속을 시도하면 사전에 정한 기준에 따라 최적의 채팅 서버를 선택
- 서비스 탐색 흐름
    1. 사용자가 시스템에 로그인을 시도
    2. 로드밸런서가 로그인 요청을 API 서버로 전달
    3. API 서버가 사용자 인증을 처리하고 서비스 탐색 기능이 동작하여 최적의 채팅 서버를 찾음
    4. 사용자는 선택된 채팅 서버에 연결

### 메시지 흐름
- 채팅 시스템에서 종단 간 메시지 흐름을 이해하는 것은 중요함

#### 1:1 채팅 메시지 처리 흐름
1. 사용자 A가 채팅 서버로 메시지 전송
2. 채팅 서버는 ID 생성기를 사용해 해당 메시지의 ID 결정
3. 채팅 서버는 해당 메시지를 메시지 동기화 큐로 전송
4. 메시지가 키-값 저장소에 보관됨
5. 사용자 B가 접속중인 경우에는 채팅 서버로 전송하고, 접속 중이 아니라면 푸시 알림 메시지를 보냄
6. 채팅 서버는 메시지를 사용자 B에게 전송. 사용자 B와 연결된 웹소켓 연결 사용

#### 여러 단말 사이의 메시지 동기화
- 한 명의 사용자가 여러 개의 단말을 사용하는 경우가 있음
- 각 단말은 cur_max_message_id라는 변수를 유지. 해당 단말에서 관측된 가장 최신 메시지의 ID를 추적하는 용도

### 접속상태 표시
- 접속상태 서버를 통해 사용자의 상태를 관리
- 접속상태 서버는 클라이언트와 웹소켓으로 통신하는 실시간 서비스임

#### 사용자 로그인
- 클라이언트와 실시간 서비스 사이에 웹소켓 연결이 맺어지면 사용자에 대한 상태와 last_active_at 타임스탬프 값을 키-값 저장소에 보관

#### 로그아웃
- API 서버로 로그아웃을 요청하면 접속상태 서버로 로그아웃 요청을 보내고, 키-값 저장소에 상태가 로그아웃으로 등록된다

#### 접속 장애
- 인터넷 연결이 좋지 못한 상황에 대응할 수 있는 설계를 준비해야 됨
- 간단한 방법은 사용자를 오프라인 상태로 표시
- 좀더 좋은 방법은 heartbeat 검사를 통해 문제 해결
    + 클라이언트로부터 계속 heartbeat 이벤트를 받고 일정 시간동안 오지 않으면 상태를 오프라인으로 바꾸는 방법

#### 상태 정보의 전송
- 상태정보 서버는 발행-구독 모델을 사용
- A 사용자가 로그아웃 하면 B, C, D 친구의 채널에 이벤트 전송
- 위 방법은 그룹 크기가 작을때 사용할 수 있다
- 그룹 크기가 커지면 상태 정보를 수동으로 갱신하도록 유도

# 13장 - 검색어 자동완성 시스템
- 입력 중인 글자에 맞는 검색어가 자동으로 완성되는 기능
- 가장 많이 사용되는 검색어 k개를 자동완성하여 출력하는 시스템을 설계

## 1단계 - 문제 이해 및 설계 범위 확정
- prefix 검색으로 한정
- 최대 5개의 자동완성 검색어 표시
- 순위는 질의 빈도에 따라 정해지는 검색어 인기 순위를 기준
- 맞춤법 검사나 자동수정은 지원하지 않음
- 영어만 해도 되고 다국어도 해도 됨
- 모든 질의는 영어 소문자로 처리
- DAU 기준으로 천만명의 트래픽

### 요구사항
- 빠른 응답 속도: 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빨리 표시되어야 한다
    + 페이스북 검색어 자동완성 시스템에 관한 문서를 보면 시스템 응답 속도는 100 밀리초 이내
- 연관성: 자동완성되어 출력되는 검색어는 사용자가 입력한 단어와 연관된것이어야 함
- 정렬: 계산 결과는 인기도 등의 순위 모델에 의해 정렬되어 있어야 함
- 규모 확장성: 시스템은 많은 트래픽을 감당할 수 있도록 확장 가능해야 함
- 고가용성: 시스템의 일부에 장애가 발생하거나 느려지거나, 예상치 못한 네트워크 문제가 생겨도 시스템은 계속 사용 가능해야 함

### 개략적 규모 추정
- DUA는 천만명으로 가정
- 평균적으로 한 사용자는 매일 10건의 검색을 수행
- 질의 할때마다 평균적으로 20바이트의 데이터를 입력
- 검색착에 글자를 입력할 때마다 클라이언트는 검색어 자동완성 백엔드에 요청을 보냄
    + 평균적으로 1회 검색당 20건의 요청이 백엔드로 전달
- 대략 초당 24,000건의 질의(QPS)가 발생
- 최대 QPS=QPS x 2 = 대략 48,000
- 질의 가운데 20% 정도는 신규 검색이라고 가정
    + 대략 0.4GB의 신규 데이터가 시스템에 추가

