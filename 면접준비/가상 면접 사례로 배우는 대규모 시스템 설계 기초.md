# 5장 안정 해시 설계
- 수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요
- 이때 안정 해시를 보편적으로 사용

## 해시 키 재배치 문제

- N개의 캐시 서버가 있고 부하를 균등하게 나누기 위해 아래 해시 삼수를 사용
    + ServerIndex = hash(key) % N(서버 대수)
    + key0 키의 경우 해시가 18358617일때 % 4를 하면 1의 ServerIndex가 나온다
- 위 경우에서 서버의 풀에 변화가 생기면 문제가 발생
- 1번 서버로 가던 요청이 1번 서버의 장애로 서버 풀이 변경되면 해시 재배치가 일어나는데 이때 대규모 캐시 미스가 발생

## 안정 해시
- 해시 테이블 크기가 조정될 때 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술
    + k = 키의 개수
    + n = 슬롯의 개수
    + 전통적인 해시 테이블은 슬롯의 수가 변경되면 대부분 키를 재배치 함

### 해시 공간과 해시 링
- SHA-1로 예를 들때 해시 공간 범위는 0부터 2^160 - 1까지라 알려져 있음
- 따라서 x0은 0, xn은 2^160 - 1이다
- 이 해시 공간을 링으로 만들면 x0과 xn이 맞닿은 모양이 된다

### 해시 서버
- 이때 해시 함수를 사용해서 서버의 정보로 해시 링의 어떤 위치에 대응 시킬 수 있음
    + 해시 슬롯에 서버 정보로 해시 함수를 돌려 저장한다는 뜻

### 해시 키
- 이때 키에 해시 함수를 돌려 나머지 연산을 하지 않고 해시 키도 슬롯에 배치를 시킴

### 서버 조회
- 이때 저장된 해시 키는 시계 방향으로 링을 탐색하면서 만나는 첫 번째 서버를 조회함

### 서버 추가 및 제거
- 위 셜명한 내용에 따르면 서버를 추가 또는 제거하면 키 가운데 일부분만 재배치하면 됨
- 나머지 키에는 영향이 없음

## 기본 구현법의 두 가지 문제
- 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는게 불가능
- 키의 균등 분포를 달성하기가 어려움
- 해당 문제를 해결하기 위해 제안된 기법이 가상 노드 또는 복제 기법

### 가상 노드
- 실제 노드 또는 서버를 가리키는 노드로서 하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있다
- 가상 노드 개수를 늘리면 키의 분포는 점점 균등해 짐

# 6장 키-값 저장소 설계
- 키-값 저장소는 키-값 데이터베이스라고도 불리는 비 관계형 데이터베이스다
- 이 저장소에 저장되는 값은 고유 식별자를 키로 가져야 함
- 키와 값 사이의 연결 관계를 "키-값"쌍이라고 지칭
    + 키는 유일해야만 함
    + 값은 해당 키를 통해서만 접근 가능
- 키는 일반 텍스트일 수도 있고 해시 값 등이 될 수 있음
- 갑승ㄴ 문자열이나, 리스트, 객체 등일 수 있다
- 키-값 저장소로 널리 알려진것은 AWS 다이나모, memcached, Redis 등이 있다

## 문제 이해 및 설계 범위 확정
- 완벽한 설계란 없음
- 읽기, 쓰기, 메모리 사용량 사이에서 균형을 찾아 데이터 일관성과 가용성 사이에서 타협적 결정을 내리면 됨

## 단일 서버 키-값 저장소
- 가장 직관적인 방법은 키-값 쌍 전부를 메모리에 해시 테이블로 저장
    + 빠른 속도를 보장하긴 하지만 모든 데이터를 메모리에 두는 것이 불가능할 수 있음
    + 해결책으로는 데이터 압축, 자주 사용되는 데이터만 메모리에 적재 등이 있다

## 분산 키-값 저장소
- 분산 시스템을 설계할 때는 CAP 정리를 이해해야 함

```
CAP 정리
- 데이터 일관성(consistency), 가용성(availability), 파티션 감내(partition tolerance)라는 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리
```
- 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속하든 언제나 같은 데이터를 받아야 한다
- 가용성: 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다
- 파티션 감내: 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미. 파티션 감내는 네트워크에 파티션이 생기더라도 시스템은 계속 동작 해야함
- 위 요구사항 중 어떤 두 가지를 만족하면 하나는 반드시 희생해야 함
    + CP 시스템: 일관성과 파티션 감내를 지원. 가용성 희생
    + AP 시스템: 가용성과 파티션 감내를 지원. 데이터 일관성 희생
    + CA 시스템: 일관성과 가용성 지원. 파티션 감내 희생. 하지만 통상 네트워크 장애는 피할 수 없는 일로 여겨지므로, 분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계
- 은행 같은 곳은 데이터 일관성이 중요하기 때문에 CP 시스템을 사용할것이고 뉴스 같은 컨텐츠를 제공하는 곳은 가용성이 중요하기 때문에 AP 시스템을 사용

## 시스템 컴포넌트
- 키-값 저장소 구현에 사용될 핵심 컴포넌트들 및 기술

### 데이터 파티션
- 대규모 시스템의 경우 데이터를 나눠서 저장해야하는데 가장 단순한 방법은 작은 파티션들로 분할한 다음 여러 대 서버에 저장하는 것
- 파티션 단위로 나눌 때는 아래 두 가지 문제가 중요
    + 데이터를 여러 서버에 고르게 분산 가능한가
    + 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가
- 5장에서 다룬 안정 해시는 위 문제를 푸는데 적합
    + 규모 확장 자동화: 시스템 부하에 따라서 서버가 자동으로 추가되거나 삭제되도록 가능
    + 다양성: 각 서버의 용량에 맞게 가상 노드 수를 조정 할 수 있음

### 데이터 다중화
- 높은 가용성과 안정성을 확보하기 위해서 데이터를 N개 서버에 비동기적으로 다중화 할 필요가 있음
- N개 서버는 해시링 위에서 시계 방향으로 순회하며 만나는 N개의 서버에 데이터 사본을 저장
    + 가상 노드를 사용하면 선택한 N개의 노드가 대응될 실제 물리 서버의 개수가 N보다 작아질 수 있음
    + 그래서 노드 선택할 때 중복된 물리 서버를 선택하지 않도록 처리

### 데이터 일관성
- 여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 함
- 정족수 합의 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있음
    + N = 사본 개수
    + W = 쓰기 연산에 대한 정족수. 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 함
    + R = 읽기 연산에 대한 정족수. 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 함
    + R=1, W=N: 빠른 읽기 연산에 최적화
    + W=1, R=N: 빠른 쓰기 연산에 최적화
    + W+R > N: 강한 일관성이 보장됨
    + W+R <= N: 강한 일관성이 보장되지 않음

### 일관성 모델
- 일관성 모델은 데이터 일관성의 수준을 결정
- 강한 일관성: 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환
- 약한 일관성: 가장 최근에 갱신된 결과를 반환하지 못할 수 있음
- 최종 일관성: 갱신 결과가 결국에는 모든 사본에 반영되는 모델
    + 데이터에 버전 정보를 넣어 클라이언트에서 일관성이 깨진 데이터를 읽지 않도록 함

### 비 일관성 해소 기법: 데이터 버저닝
- 데이터를 다중화하면 사본 간 일관성이 깨질 가능성이 높음
- 버저닝과 벡터 시계로 문제를 해소할 수 있음
    + 버저닝: 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 생성. 각 버전의 데이터는 변경 불가능
    + 벡터 시계: 데이터 버저닝 과정에서 버전간 충돌이 발생했을 때 사용되는 기술로 [서버, 버전]의 순서쌍을 데이터에 매단 것

### 장애 처리
- 대규모 시스템에서 장애는 아주 흔한 일이기 때문에 장애를 어떻게 처리할 것인지는 굉장히 중요한 문제

### 장애 감지
- 분산 시스템에서는 노드 사이에 멀티캐스팅 채널을 구축해서 서로 장애를 감지할 수 있음
    + 서버가 많을 때는 비효율적인 방법
- gossip protocol 같은 분산형 장애 감지 솔루션이 효율적입
    + 각 노드는 멤버십 목록을 유지. 멤버심 목록은 각 멤버 ID와 해당 멤버의 heartbeat counter 쌍의 목록임
    + 각 노드는 주기적으로 자신의 heartbeat counter를 증가 시킴
    + 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기의 heartbeat counter 목록을 보냄
    + heartbeat counter 목록을 받은 노드는 멤버십 목록을 최신화
    + 어떤 멤버의 heartbeat counter 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주

### 일시적 장애 처리
- 장애를 감지한 시스템은 가용성을 보장하기 위해 필요한 조치를 해야 함
- 엄격한 정족수 접근법을 쓴다면 읽기와 쓰기 연산을 금지
- 느슨한 정족수 접근법을 쓴다면 쓰기 연산을 수행할 W개의 서버와 읽기 연산을 수행할 R개의 건강한 서버버를 해시 링에서 고름
- 네트워크나 서버 문제로 장애 상태인 서버로 가는 요청은 다른 서버로 우회
    + 해당 시간동안 발생한 변경 사항은 복구되었을 때 일괄 반영하여 데이터 일관성 보존
    + 이를 위해 연산을 처리한 서버는 단서를 남겨둠
    + 이런 장애 처리 방안을 단서 후 임시 위탁 기법이라 부름

### 영구 장애 처리
- hinted handoff 기법은 일시적 장애를 처리하기 위한 방법
- 영구적인 노드 장애 처리에는 반-엔트로피(anti_entropy) 프로토콜을 구현하여 사본들을 동기화
    + 사본들을 비교하여 최신 버전으로 갱신하는 과정
    + 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해서 Merkle 트리를 사용

```
머클 트리
- 해시 트리라고도 불리는 머클 트리는 각 노드에 그 자식 노드들에 보관된 값의 해시 또는 자식 노드들의 레이블로부터 계산된 해시 값을 레이블로 붙여두는 트리이다. 해시 트리를 사용하면 대규모 자료 구조의 내용을 효과적이면서도 보안상 안전한 방법으로 검증할 수 있다
```
1. 키 공간을 묶어서 버킷으로 나눔
2. 버킷별로 해시값을 계산한 후, 해당 버킷의 합을 다시 해시하여 해당 해시 값을 레이블로 갖는 노드를 만듬
3. 상향식으로 자식 노드의 레이블로부터 새로운 해시 값을 계산하여 이진 트리를 구성
4. 이렇게 완성된 두 머클 트리를 루트 노드부터 비교해서 틀린 부분만 찾아나감

### 데이터 센터 장애 처리
- 데이터 센터는 다양한 이유로 장애가 발생할 수 있다.
- 장애에 대응할 수 있는 시스템을 만들려면 여러 데이터 센터에 다중화하는 것이 중요

# 7장 - 분산 시스템을 위한 유일 ID 생성기 설계
- 분산 환경에서는 Auto Increment 속성을 사용하는 관계형 데이터베이스 기본키를 사용할 수 없음
    + 데이터베이스 서버 한 대로는 요청을 감당할 수 없고 여러 데이터베이스 서버를 쓰는 경우에는 지연 시간을 낮추기가 힘듬

## 1단계 - 문제 이해 및 설계 범위 확정
- ID는 어떤 특성을 갖나?
- 새로운 레코드에 붙일 ID는 항상 1만큼 큰 값이어야 하나?
- ID는 숫자로만 구성되나?
- 시스템 규모는 어느정도 인가?

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- 유일성이 보장되는 ID를 만드는 방법은 여러가지
    + 다중 마스터 복제
    + UUID
    + 티켓 서버
    + 트위터 스노플레이크 접근법

### 다중 마스터 복제
- 해당 접근법은 데이터베이스의 auto_increment 기능을 활용하는 것. 다만 다음 ID를 구할 때 K만큼 증가 시킴
    + K는 현재 사용 중인 데이터베이스 서버의 수
- 규모 확장성 문제를 해결할 수는 있지만 중대한 단점이 있음
    + 여러 데이터 센터에 걸쳐 규모를 늘리기 어려움
    + 유일성은 보장되겠지만 값이 시간 흐름에 맞추어 커지도록 보장할 수는 없음
    + 서버를 추가하거나 삭제할 때도 잘 동작하도록 만들기 어려움

### UUID
- 컴퓨터 시스템에 저장되는 정보를 유일하게 식별하기 위한 128비트짜리 수
- 각각의 웹 서버가 별도의 ID 생성기를 사용해 독립적으로 ID를 만들 수 있음
- 장점
    + UUID를 만드는 것은 단순함. 동기화 이슈도 없음
    + 각 서버가 ID를 알아서 만드는 구조이므로 규모 확장도 쉬움
- 단점
    + ID가 128비트로 김
    + 시간순으로 정렬할 수 없음
    + 숫자 아닌 값이 포함될 수 있음

### 티켓 서버
- auto_increment 기능을 갖춘 데이터베이스 서버를 중앙 집중형으로 사용
- 장점
    + 유일성 보장이 되는 숫자로만 구성된 ID를 쉽게 만듬
    + 구현하기 쉽고, 중소 규모 애플리케이션에 적합
- 단점
    + 티켓 서버가 SPOF(Single-Point-of-Failure)가 됨

### 트위터 스노플레이크 접근법
+ 생성해야 하는 ID의 구조를 여러 절로 분할해 생성
    + 사인 비트: 1비트 할당. 쓰임새가 없지만 나중을 위해 유보
    + 타임스탬프: 41비트 할당. epoch(기원 시각)) 이후로 몇 밀리초가 경과했는지를 나타내는 값
    + 데이터센터 ID: 5비트 할당
    + 서버 ID: 5비트 할당
    + 일련번호: 12비트 할당. 각 서버에서 ID를 생성할 때마다 해당 일련번호를 1만큼 증가. 1밀리초가 지날때마다 0으로 초기화

# 8장 - URL 단축기 설계

## 1단계 - 문제 이해 및 설계 범위 확정
- 항상 성공적으로 설계하려면 질문을 통해 모호함을 줄이고 요구사항을 알아야 함
    + 쓰기 연산: 매일 1억 개의 단축 URL 생성
    + 초당 쓰기 연산: 1160
    + 읽기 연산: 읽기 연산과 쓰기 연산 비율을 10:1로 하면 초당 11,600회
    + 10년간 운영한다고 하면 3650억개의 레코드를 보관
    + 축약 전 URL의 평균 길이는 100정도
    + 10년동안 필요한 저장 용량은 3650억 X 100바이트 = 36.5TB

## 2단계 - 개략적 설계안 제시 및 동의 구하기

### API 엔드포인트
- URL 단축기에는 기본적으로 두 개의 엔드포인트가 필요
    + URL을 단축을 위한 엔드포인트: 클라이언트가 단축하고자 하는 URL을 담아서 POST 요청을 보냄
    + URL 리디렉션용 엔드포인트: 단축 URL에 대해서 원래 URL로 보내주기 위한 용도

### URL 리디렉션
- 단축 URL을 받은 서버는 해당 URL을 원래 URL로 바꾸어서 301응답의 Location 헤더에 넣어 반환
    + 301 Permanently Moved: 해당 URL에 대한 HTTP 요청의 처리 책임이 영구적으로 Location 헤더에 반환된 URL로 이전되었다는 뜻
    + 302 Found: 주어진 URL로의 요청이 일시적으로 Location 헤더가 지정하는 URL에 의해 처리되어야 한다는 응답
- 서버 부하를 줄일때는 301이 좋고 트래픽 분석이 중요할 때는 302를 쓰는 쪽이 좀더 유리
- URL 리디렉션을 구현하는 가장 직관적인 방법은 해시 테이블을 사용

### URL 단축
- 중요한 것은 긴 URL을 해당 해시 값으로 대응시킬 해시 함수 fx를 찾은 것
- 해시 함수는 아래 요구사항을 만족
    + 입력으로 주어지는 긴 URL이 다른 값이면 해시 값도 달라야 한다
    + 계산된 해시 값은 원래 입력으로 주어졌던 긴 URL로 복원될 수 있어야 함

## 3단계 - 상세 설계

### 데이터 모델
- 개략적 설계에서는 모든 것을 해시 테이블에 두었지만 실제 시스템에 적용하기는 곤란
- 더 좋은 방법으로는 관계형 데이터베이스에 쌍을 저장
    + id, shortURL, longURL의 세 개 칼럼을 가짐

### 해시 함수
- 원래 URL을 단축 URL로 변환하는 데 사용

#### 해시 값 길이
- hashValue는 [0-9, a-z, A-Z]의 문자들로 구성
- 사용할 수 있는 문자의 개수는 62개. 10 + 26 + 26 = 62
- hashValue 길이를 정하기 위해서는 62^n >= 3650억인 n의 최솟값을 찾아야 함
    + n=7이면 3.5조개의 URL을 만들 수 있음

#### 해시 후 충돌 해소
- CRC32, MD5, SHA-1 같은 해시 함수를 이용해 단축 후 앞에 7자를 사용하면 충돌 확률이 높아 짐
- 첫번째 방법은 충돌이 해소될 때까지 사전에 정한 문자열을 해시값에 덧붙임
    + 충돌은 해소할 수 있지만 데이터베이스 질의를 해야하므로 오버헤드가 큼

#### base-62 변환
- 진법 변환은 URL 단축기를 구현할 때 흔히 사용되는 접근법
- 해당 기법은 수의 표현 방식이 다른 두 시스템이 같은 수를 공유하여야 하는 경우에 유용
- hashValue의 문자 개수가 62개이기 때문에 base-62 사용
- 62진법은 0은 0, 9는 9, a는 11... 61은Z로 대응시켜 표현
- ID의 유일성이 보장되진 않음

### URL 단축기 상세 설계
1. 입력으로 긴 URL을 받음
2. 데이터베이스에 해당 URL이 있는지 검사
3. 있다면 단축 URL을 가져와 반환
4. 없다면 DB의 기본기로 사용된 유일한 ID를 생성
5. 62진법 변환을 적용. ID를 단축 URL로 생성
6. ID, 단축 URL, 원래 URL로 새 데이터베이스 레코드를 만든 후 단축 URL을 클라이언트에 전달

# 9장 - 웹 크롤러 설계
- 웹 크롤러: 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아내는 것이 주된 목적
- 크롤러가 이용되는 방법
    + 검색 엔진 인덱싱
    + 웹 아카이빙: 장기보관하기 위해 웹에서 정보를 모으는 절차
    + 웹 마이닝
    + 웹 모니터링: 인터넷에서 저작권이나 상표권이 침해되는 사례를 모니터링 할 수 있음

## 1단계 - 문제 이해 및 설계 범위 확정
- 웹 크롤러의 기본 알고리즘은 간단함
    1. URL 집합이 주어지면, 해당 URL들이 가리키는 모든 웹 페이지를 다운로드
    2. 다운받은 웹 페이지에서 URL을  추출
    3. 추출된 URL들을 다운로드할 URL 목록에 추가하고 1번부터 반복
- 엄청난 규모 확장성을 갖는 웹 크롤러를 설계하는 것은 엄청나게 어려운 작업. 설계 하기 전 요구사항을 알아내고 설계 범위를 좁히는게 중요
    + 크롤러의 주된 용도
    + 수집해야하는 웹 페이지 수
    + 새로 만들어졌거나 수정된 웹 페이지도 포함
    + 저장 여부
    + 중복 콘텐츠 처리
    + 규모 확장성
    + 안정성: 잘못된 링크들에 대해서 잘 대응할 수 있어야 됨
    + 예절: 수집 대상 웹 사이드에 짧은 시간 동안 너무 많이 요청하면 안됨
    + 확장성

### 개략적 규모 추정
- 매달 10억 개의 웹 페이지를 다운로드해야 함
- QPS=10억 / 30일 / 24시간 / 3600초 = 약 400페이지/초
- 최대 QPS = 2 X QPS = 800
- 웹 페이지의 크기 평균은 500k라고 가정
- 10억 페이지 x 500k = 500TB/월
- 1개월치 데이터를 보관하는 데는 500TB. 5년간 보관한다고 가정하면 500TB X 12개월 X 5년 = 30PB의 저장용량 필요

## 2단계 - 개략적 설계안 제시 및 동의 구하기
1. 시작 URL 집합 -> 2. 미수집 URL 저장소 -> 3. HTML 다운로더 -> 4. 컨텐츠 파서 -> 5. 중복 컨텐츠?
-> 6. URL 추출기 -> 7. URL 필터 -> 8. 이미 방문한 URL? -> <8-예>: 2 | <8-아니오>: 10. URl 저장소

### 시작 URL 집합
- 크롤러가 크롤링을 시작하는 출발점
- 특정 대학 웹사이트로부터 찾아 나갈 수 있는 모든 웹 페이지를 크롤링하는 가장 직관적인 방법은 해당 대학의 도메인 이름이 붙은 모든 페이지의 URL을 시작 URL로 사용

### 미수집 URL 저장소
- 웹 크롤러는 크롤링 상태를 다운로드할 URL과 다운로드된 URL 두 가지로 나눠 관리
- 다운로드할 URL을 관리하는 컴포넌트를 미수집 URL 저장소라고 부른다

### HTML 다운로더
- 인터넷에서 웹 페이지를 다운로드하는 컴포넌트

### 도메인 이름 변환기
- 웹 페이지를 다운받으려면 URL을 IP 주소로 변환하는 절차가 필요
- HTML 다운로더는 도메인 이름 변환기를 사용하여 URl에 대응되는 IP 주소를 알아낸다

### 콘텐츠 파서
- 웹 페이지를 다운로드하면 파싱과 검증 절차를 거쳐야 함
- 이상한 웹 페이지는 문제를 일으킬 수 있고 저장 공강만 낭비하게 됨

### 중복 콘텐츠인가?
- 연구 결과에 따르면, 29% 가량의 웹 페이지 콘텐츠는 중복임
- 위 문제를 해결하기 위해 자료 구조를 도입해서 데이터 중복을 줄이고 데이터 처리에 소요되는 시간을 줄임

### 콘텐츠 저장소
- HTML 문서를 보관하는 시스템
- 저장소를 구현할때는 저장할 데이터의 유형, 크기, 저장소 접근 빈도, 데이터의 유효 기간 등을 종합적으로 고려

### URL 추출기
- HTML 페이지를 파싱하여 링크들을 골라내는 역할을 함
    + HTML 페이지 내의 상대 경로를 전부 도메인을 붙여 절대 경로로 변환

### URL 필터
- 특정한 콘텐츠 타입이나 파일 확장자를 갖는 URL, 접속 시 오류가 발생하는 URL, 접근 제외 목록에 포함된 URL 등을 크롤링 대상에서 배제하는 역할을 함

### 이미 방문한 URL?
- 이 단계를 위해서 보간된 URL을 추적할 수 있도록 하는 자료 구조를 사용
- 해당 기능으로 같은 URL을 여러번 처리하는 일을 방지할 수 있고 시스템이 무한 루프에 빠지는 일을 방지할 수 있음
- 해당 자료 구조는 블룸 필터를 이용

```
블룸 필터
원소가 집합에 속하는지 여부를 검사하는데 사용되는 확률적 자료 구조.
어떤 원소가 집합에 속한다고 판단된 경우 실제로는 원소가 속하지 않는 긍정 오류가 발생하는 것이 가능하지만, 반대로 원소가 집합에 속하지 않는 것으로 판단되었는데 실제로는 원소가 집합에 속하는 부정 오류는 절대 발생하지 않음.
집합에 원소를 추가하는 것은 가능하나, 집합에서 원소를 삭제하는 것은 불가능
```

### URL 저장소
- 이미 방문한 URL을 보관하는 저장소

## 3단계 - 상세 설계
- 아래는 가장 중요한 컴포넌트 목록
    + DFS vs BFS
    + 미수집 URL 저장소
    + HTML 다운로더
    + 안정성 확보 전략
    + 확장성 확보 전략
    + 문제 있는 콘텐츠 감지 및 회피 전략

### DFS를 쓸 것인가, BFS를 쓸 것인가
- 웹은 유향 그래프(directed graph) 같다
    + 페이지가 노드이고 하이퍼링크가 에지라고 보면 됨
- 크롤링 프로세스는 유향 그래프를 에지를 따라 탐색하는 과정
- DFS는 좋은 선택이 아닐 가능성이 높음
    + 그래프 크기가 클 경우 어느 정도로 깊숙이 가게 될지 가늠이 어려움
- 그래서 웹 크롤러는 보통 BFS를 사용
    + FIFO 방식으로 탐색할 URL을 넣고 한쪽에서 꺼내서 처리한다
- 하지만 BFS에는 두 가지 문제 점이 있음
    + 한 페이지에서 나오는 링크는 대부분 같은 서버로 되돌아 감. 그럼 크롤러는 같은 호스트에 속한 많은 링크를 받게되고 다운을 병렬로 처리하게 되면 해당 서버는 수많은 요청으로 과부하에 걸림. 이 같은 크롤러를 보통 예의 없는(impolite) 크롤러라 함
    + 표준적 BFS 알고리즘은 URl 간에 우선순위를 두지 않음

### 미수집 URL 저장소
- 해당 저장소를 활용하면 위 문제를 쉽게 해결할 수 있음
- 해당 저장소를 잘 구현하면 예의를 갖춘 크롤러, URL 사이의 우선순위와 신선도를 구별하는 크롤러를 구현할 수 있음

### HTML 다운로더
- HTTP 프로토콜을 통해 웹 페이지를 내려 받음

#### Robots.txt
- 로봇 제외 프로토콜이라고도 부르는 Robots.txt는 웹사이트가 크롤러와 소통하는 표준적 방법임
    + 해당 파일에는 크롤러가 수집해도 되는 페이지 목록이 들어 있음

#### 성능 최적화
1. 분산 크롤링 : 성능을 높이기 위해 크롤링 작업을 여러 서버에 분산하는 방법
2. 도메인 이름 변환 결과 캐시: 도메인 이름 변환기는 크롤러 성능 병목 중 하나. DNS 요청을 보내고 결과를 받는 동기적 특성 때문. 크롤러 스레드 가운데 하나가 이 작업을 하고 있으면 다른 스레드의 DNS 요청은 전부 블록됨. 그래서 결과를 캐시하고 크론 잡 등을 돌려 주기적으로 갱신하도록 해 놓으면 성능을 효과적으로 높일 수 있다
3. 지역성: 크롤링 작업을 수행하는 서버를 지역별로 분산. 크롤링 서버가 대상 서버와 지역적으로 가짜우면 다운로드 시가이 줄어들것
4. 짧은 타임아웃: 어떤 웹 서버는 응답이 느리거나 아예 응답하지 않음. 그래서 최대 얼마나 기다릴지를 미리 정해 둠

### 안정성
- 안정성도 다운로더 설계 시 중요하게 고려해야 함
- 안정성을 향상시키기 위한 접근법 가운데 중요한 몇 가지
    + 안정 해시
    + 크롤링 상태 및 수집 데이터 저장: 장애가 발생한 경우에도 쉽게 복구할 수 있도록 크롤링 상태와 수집된 데이터를 지속적 저장장치에 기록해 두는것이 바람직
    + 예외 처리: 대규모 시스템에서 에러는 흔하게 일어남. 예외가 발생해도 전체 시스템이 중단되는 일 없이 작업을 우아하게 이어나갈 수 있어야 한다
    + 데이터 검증: 시스템 오류를 방지하기 위한 중요한 수단

### 확장성
- 시스템은 계속 진화하기 때문에, 새로운 형태의 콘텐츠를 쉽게 지원할 수 있도록 신경 써야 함

### 문제 있는 콘텐츠 감지 및 회피
1. 중복 콘텐츠
    - 웹 콘텐츠의 30% 가량은 중복임. 해시나 체크섬을 사용해서 중복 콘텐츠를 쉽게 탐지
2. 거미 덫
    - 크롤러를 무한 루프에 빠뜨리도록 설계한 웹 페이지
    - URL의 최대 길이를 제한해서 회피
3. 데이터 노이즈
    - 가치가 없는 콘텐츠도 있기 때문에 가능한한 제외할 수 있도록 처리
