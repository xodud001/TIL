# HTTP: 웹의 기초

## **1장 HTTP 개관**
이번 장에서 다루게 될 것
* 얼마나 많은 클라이언트와 서버가 통신하는지
* 리소스가(웹 콘텐츠) 어디서 오는지
* 웹 트랜잭션이 어떻게 동작하는지
* HTTP 통신을 위해 사용하는 메시지의 형식
* HTTP 기저의 TCP 네트워크 전송
* 여러 종류의 HTTP 프로토콜
* 인터넷 곳곳에 설치된 다양한 HTTP 구성요소

### **1.1 HTTP: 인터넷의 멀티미디어 배달부**
* HTTP는 전 세계의 웹 서버로부터 대량의 정보를 빠르고, 간편하고 정확하게 사람들의 PC에 설치 된 웹브라우저로 옮겨준다.
* HTTP는 `신뢰성 있는 데이터 전송 프로토콜을 사용`하기 때문에, 전송 중 손상되지 않음을 보장한다.

### **1.2 웹 클라이언트와 서버**
* 웹 콘텐츠는 웹 서버에 존재
* 웹 서버는 데이터를 저장하고 HTTP 클라이언트가 요청한 데이터를 제공
* 웹브라우저 같은 것들을 HTTP 클라이언트라고 함

### **1.3 리소스**
* 웹 서버는 웹 리소스를 관리하고 제공
* `정적 리소스` - 이미지, HTML 파일, 텍스트 파일, 워드 파일 등
* `동적 리소스` - 요청에 따라 달라짐. 카메라 라이브 영상, 주식 거래, 부동산 데이터베이스 등
* 어떤 종류의 콘텐츠 소스도 리소스가 될 수 있음

#### **1.3.1 미디어 타입**
* 인터넷은 수천 가지 데이터 타입을 다루기 때문에, HTTP는 웹에서 전송되는 객체 각각에 MIME 타입이라는 데이터 포맷 라벨을 붙인다.
    * `MIME` : Multipurpose Internet Mail Extensions
* MIME는 원래 각기 다른 전자메일 시스템 사이에서 메시지가 오갈 때 겪는 문제점을 해결하기 위해 설계
* MIME가 이메일에서 잘 동작해서, HTTP에서도 멀티미디어 콘텐츠를 기술하고 라벨을 붙이기 위해 채택
* MIME 타입은 사선(/)으로 구분된 주 타입과 부 타입으로 이루어진 문자열 라벨.
    * HTML로 작성된 텍스트 문서 : `text/html`
    * plain ASCII 텍스트 문서 : `text/plain`
    * JPEG 이미지 : `image/jpeg`
    * GIF 이미지 : `image/gif`

#### **1.3.2 URI**
* 웹 서버 리소스는 각자 이름을 갖고 있음. 클라이언트는 관심 있는 리소스 지목 가능
* 서버 리소스 이름은 `통합 자원 식별자, 혹은 URI(uniform resource identifier)`로 불림
* URI는 정보 리소스를 고유하게 식별하고 위치를 지정할 수 있다.

#### **1.3.3 URL**
* `통합 자원 지시자(uniform resource locator, URL)`는 리소스 식별자의 가장 흔한 형태
* URL은 특정 서버의 한 리소스에 대한 구체적인 위치를 서술
* 대부분의 URL은 세 부분으로 이루어진 표준 포맷을 따름
    * URL의 첫 번째 부분은 스킴(scheme)이라고 불리는데, 리소스에 접근하기 위해 사용되는 프로토콜을 서술. ex) HTTP, FTP, WS ...
    * 두 번째 부분은 서버의 인터넷 주소를 제공
    * 마지막은 웹 서버의 리소스를 지정
* 오늘날 대부분의 URI는 URL임

#### **1.3.4 URN**
* `유니폼 리소스 이름(uniform resource name, URN)`은 콘텐츠를 이루는 한 리소스에 대해, 그 리소스의 위치에 영향 받지 않는 유일무이한 이름 역할을 함
* URN은 위치에 독립적이며, 리소스를 여기저기 옮기더라도 문제 없이 동작한다.

### **1.4 트랜잭션**
* HTTP 트랜잭션은 요청 명령과 응답 결과로 구성되어 있다

#### **1.4.1 메서드**
* HTTP는 `HTTP 메서드`라고 불리는 여러 종류의 요청 명령을 지원
* 모든 HTTP 요청은 한 개의 메서드를 가짐
    * `GET` : 서버에서 클라이언트로 지정한 리소스를 보내라
    * `PUT` : 클라이언트에서 서버로 보낸 데이터를 지정한 이름의 리소스로 저장하라
    * `DELETE` : 지정한 리소스를 서버에서 삭제하라
    * `POST` : 클라이언트 데이터를 서버 게이트웨이 애플리케이션으로 보내라
    * `HEAD` : 지정한 리소스에 대한 응답에서, HTTP 헤더 부분만 보내라

#### **1.4.2 상태 코드**
* 모든 HTTP 응답 메시지는 `상태 코드`와 함께 반환
* 상태 코드는 클라이언트에게 요청이 성공했는지 아니면 추가 조치가 필요한지 알려주는 세 자리 숫자
    * `200` : 문서가 올바르게 반환
    * `302` : 자원을 다른 곳에 가서 가져가라
    * `404` : 리소스 못 찾음
* HTTP는 숫자 상태 코드에 텍스트로 된 `사유 구절(reason phrase)`도 함께 보냄
    * `200 OK`
    * `200 DOcument attached`
    * `200 Success`
    * `200 All's cool, dude`

#### **1.4.3 웹페이지는 여러 객체로 이루어질 수 있다
* 애플리케이션은 보통 하나의 작업을 수행하기 위해 여러 HTTP 트랜잭션을 수행
* 웹페이지는 보통 하나의 리소스가 아닌 리소스의 모음이다

### **1.5 메시지**
* HTTP 메시지는 사람이 읽고 쓸 수 있는 단순한 줄 단위의 문자열이다.
* HTTP 메시지는 다음의 세 부분으로 이루어 짐
    * 시작줄 : 요청이라몃 무엇을 해야하는지, 응답이라면 무슨 일이 일어났는지 서술
    * 헤더 : 시작줄 다음에는 0개 이상의 헤더 필드가 이어짐. 콜론(:)으로 구분되어 키 밸류 형식으로 구성 
    * 본문 : 헤더 아래 빈줄 다음 어떤 종류으 데이터든 필요에 따라 들어갈 수 있다. 텍스트와 이진 데이터 포함 가능

### **1.6 TCP 커넥션**
* HTTP 메시지 전송에 사용

#### **1.6.1 TCP/IP**
* HTTP는 통신의 세부사항에 대해 신경쓰지 않음. 대중적이고 신뢰성 있는 인터넷 전송 프로토콜인 TCP/IP에게 맡긴다
* TCP가 제공하는 것
    * 오류 없는 데이터 전송
    * 순서에 맞는 전달
    * 조각나지 않는 데이터 스트림

#### **1.6.2 접속, IP 주소, 포트번호
* TCP/IP 커넥션에는 인터넷 프로토콜(IP) 주소와 포트번호가 필요

### **1.7 프로토콜 버전**
HTTP 프로토콜의 다양한 버전.

**HTTP/0.9**
* GET 메서드만 지원
* 멀티미디어 콘텐츠에 대한 MIME 타입이나 HTTP 헤더, 버전 번호를 지원하지 않음
* 금방 HTTP/1.0으로 대체

**HTTP/1.0**
* 버전 번호, HTTP 헤더, 추가 메서드, 멀티미디어 객체 처리 추가
* 웹페이지와 상호작용하는 폼을 실현

**HTTP/1.0+**
* 오래 지속되는 "keep-alive" 커넥션, 가상 호스팅 지원, 프락시 연결 지원을 포함한 많은 기능이 비공식적이지만 사실상 표준으로 HTTP에 추가

**HTTP/1.1**
* HTTP 설계의 구조적 결함 교정, 두드러진 성능 최적화, 잘못된 기능 제거에 집중
* 더 복잡한 웹 애플리케이션 베포 지원
* 현재 자주 사용하는 버전

**HTTP/2.0**
* HTTP/1.1 성능 문제를 개선하기 위해 구글의 SPDY 프로토콜을 기반으로 설계

### **1.8 웹의 구성요소**
다양한 웹의 구성요소들

**프락시**
* 클라이언트와 서버 사이에 위치한 HTTP 중개자

**캐시**
* 많이 찾는 웹페이지를 클라이언트 가까이에 보관하는 HTTP 창고

**게이트웨이**
* 다른 애플리케이션과 연결된 특별한 웹 서버

**터널**
* 단순히 HTTP 통신을 전달하기만 하는 특별한 프락시

**에이전트**
* 자동화된 HTTP 요청을 만드는 준지능적 웹클라이언트

#### **1.8.1 프락시**
* 웹 보안, 애플리케이션 통합, 성능 최적화를 위한 중요한 구성요소
* 클라이언트와 서버 사이에 위치하여 클라이언트의 모든 HTTP 요청을 받아 서버에 전달
* 주로 보안을 위해 사용
* 요청와 응답을 필터링

#### **1.8.2 캐시**
* 웹캐시와 캐시 프락시는 자신을 거쳐 가는 문서들 중 자주 찾는 것의 사본을 저장 해 두는 특별한 종류의 HTTP 프락시 서버

#### **1.8.3 캐시**
* 다른 서버들의 중개자로 동작하는 특별한 서버
* 주로 HTTP 트래픽을 다른 프로토콜로 변환하기 위해 사용

#### **1.8.4 터널**
* 터널은 두 커넥션 사이에서 날(raw) 데이터를 열어보지 않고 그대로 전달해주는 HTTP 애플리케이션
* 예, 암호화된 SSL 트래픽을 HTTP 커넥션으로 전송함으로써 웹 트래픽만 허용하는 사내 방화벽을 통과

#### **1.8.5 에이전트**
* 사용자를 위해 HTTP 요청을 만들어주는 클라이언트 프로그램
* 웹브라우저, 스파이더, 웹로봇 등


## **2장 URL과 리소스**
* URL은 인터넷의 리소스를 가리키는 표준이름.
    * 리소스: 텍스트, 이미지, 동영상 같이 웹에서 사용되는 식별을 할 수 있는 모든 자원을 가리킴
* URL은 전자정보 일부를 가리키고 그것이 어디에 있고 어떻게 접근할 수 있는지 알려줌

### **2.1 인터넷의 리소스 탐색하기**
* URL은 브라우저가 정보를 찾는데 필요한 리소스의 위치를 가리킴
* URL은 통합 자원 식별자(Uniform Resource Identifier) 혹은 URI라고 불리는 더 일반화된 부류의 부분집합
* `http://naver.com/cafe/index.html`
    * URL의 첫 부분인 `http`는 URL의 스킴이다. 어떤 프로토콜을 사용해 접근하는지 알려줌
    * URL의 두 번째 부분인 `naver.com`은 서버의 위치이다. 리소스가 어디에 호스팅 되어 있는지 알려준다
    * URL의 세 번째 부분인 `/cafe/index.html`은 리소의 경로이다. 경로는 서버에 존재하는 로컬 리소스들 중에서 요청받은 리소스가 무엇인지 알려줌

### **2.2 URL 문법**
* 대부분의 URL 스킴의 문법은 일반적으로 9개 부분으로 나뉨
* `<스킴>://<사용자이름>:<비밀번호>@<호스트>:<포트>/<경로>;<파라미터>?<질의>#<프래그먼트>`

| 컴포넌트 | 설명 | 기본값 |
|--------|-----|------|
스킴      | 서버 접근에 사용하는 프로토콜 | 없음
사용자 이름 | 리소스 접근에 필요한 사용자 이름 | anonymous
비밀번호   | 사용자의 비밀번호 |<이메일 주소>
호스트    | 리소스를 호스팅하는 서버의 호스트 명이나 IP 주소 | 없음
포트      | 리소스를 호스팅하는 서버가 열어놓은 포트번호 | 스킴에 따라 다름
경로    | 서버 내 리소스가 서버 어디에 있는지를 가리킴 | 없음
파라미터 | 특정 스킴들에서 입력 파라미터를 기술하는 용도로 사용 | 없음
질의    | 스킴에서 애플리케이션에 파라미터를 전달하는데 사용 | 없음
프래그먼트 | 리소스의 조각이나 일부분을 가리키는 이름 | 없음

#### **2.2.1 스킴: 사용할 프로토콜**
* URL을 해석하는 애플리케이션이 어떤 프로토콜을 사용하여 리소스를 요청해야 하는지 알려줌
* 대소문자 구분 안 함

#### **2.2.2 호스트와 포트**
* 리소스를 찾기 위해 리소스가 호스팅하고 있는 장비와 그 장비 내에서 리소스에 접근할 수 있는 서버가 어디에 있는지 알려줌

#### **2.2.3 사용자 이름과 비밀번호**
* 서버가 가지고 있는 데이터에 접근을 허용하기 전에 사용자 이름과 비밀번호를 요구하는데 그때 사용

#### **2.2.4 경로**
* 리소스가 서버의 어디에 있는지 알려줌
* `/`문자를 기준으로 경로조각으로 나뉨

#### **2.2.5 파라미터**
* 서버에 정확한 요청을 하기 위해 필요한 입력 파라미터를 받는데 사용
* 이름/값 쌍의 리스트로 `;`로 구분해서 URL에 기술

#### **2.2.6 질의 문자열**
* 데이터베이스 같은 서비스들은 요청받을 리소스 형식의 범위를 좁히기 위해 질의문이나 질의를 받음
* `&`로 나뉜 `이름=값` 쌍 형식의 질의 문자열을 사용

#### **2.2.7 프래그먼트**
* HTML 같은 리소스 형식들은 본래의 수준보다 더 작게 나뉠 수 있음
* 리소스의 특정 부분을 가리킬 수 있도록, URL은 리소스 내의 조각을 가리킬 수 있는 프래그먼트 컴포넌트를 제공
* 프래그먼트는 브라우저가 서버에서 전체 리소스를 내려받은 후, 프래그먼트를 사용하여 리소스의 일부를 보여줌

### **2.3 단축 URL**
* 웹 클라이언트는 몇몇 단축 URL을 인식하고 사용

#### **2.3.1 상대 URL**
* URL은 상대 URL과 절대 URL로 나뉨
* 절대 URL은 리소스 접근에 필요한 모든 정보를 담고 있지만 상대 URL은 모든 정보를 담고 있지 않다
* 상대 URL로 리소스에 접근하는데 필요한 모든 정보를 얻기 위해서는 `기저(base)`라고 하는 다른 URL을 사용해야 함
    * 기저 URL : `http://naver.com/first.html`
    * 상대 URL : `./second.html`
    * 기저 URL + 상대 URL : `http://naver.com/second.html`

* 기저 URL : 변환 과정의 첫 단계는 기저 URL을 찾는 것.
* 기저 URL을 가져오는 방법
    * 리소스에 명시적으로 제공
    * 리소스를 포함하고 있는 기저 URL : 상대 URL이 기저 URL이 명시되지 않은 리소스에 포함된 경우, 해당 리소스의 URL을 기저 URL로 쓸 수 있다.
    * 기저 URL이 없는 경우 : 절대 URL로만 이루어져 있거나 불완전하거나 깨진 것
    * 상대 참조 해석하기
    
#### **2.3.2 URL 확장**
* 브라우저는 URL을 입력하는 중에 URL을 자동으로 확장함.
* 확장의 2가지 방법
    * 호스트 명 확장 : 주소에 `yahoo`를 입력하면 브라우저가 `www.`와 `.com`을 붙여서 `www.yahoo.com`으로 만드는 방식
    * 히스토리 확장 : 과거에 사용자가 방문했던 URL 기록을 저장.

### **2.4 안전하지 않은 문자**
* URL은 일반적으로 안전한 알파벳 문자만 포함하도록 허락함
* 근데 URL에 이진데이터나 다른 문자도 포함할 때가 있음. 이때 이스케이프라는 기능을 이용해서 안전하지 않은 문자를 안전한 문자로 인코딩 할 수 있다

#### **2.4.1 URL 문자 집합**
* 컴퓨터의 기본 문자 집합은 보통 영어 중심임
* URL에 포함할 수없는 문자를 포함하기 위해 이스케이프 기능을 지원.
* 이스케이프 문자열은 US-ASCII에서 사용이 금지된 문자들로, 특정 문자나 데이터를 인코딩할 수 있게 함으로써 이동성과 완성도를 높임

#### **2.4.1 인코딩 체계**
* 안전하지 않은 문자들을 표현할 수 있는 인코딩 방식이 고안
* 퍼센티지 기호(%)로 시작해 ASCII 코드로 표현되는 두 개의 16진수 숫자로 이루어진 이스케이프 문자로 바꿈

| 문자 | ASCII 코드 |
|-----|-----------|
| ~ | 126(0x7E) |
| 빈 문자| 32(0x20) |
| % | 37(0x25) |

#### **2.4.3 문자 제한**
* 몇몇 문자는 URL 내에서 특별한 의미로 예약되어 있음
* 아래 표는 URL에서 예약된 문자들을 본래의 목적이 아닌 다른 용도로 사용하려면, 그 전에 반드시 인코딩 해야하는 문자

| 문자 | 선점 및 제한|
|-----|----------|
| % | 인코딩된 문자에 사용할 이스케이프 토큰으로 선점|
| / | 경로 컴포넌트에 있는 경로 세그먼트를 나누는 용도로 선점|
| . | 경로 컴포넌트에서 선점|
| .. | 경로 컴포넌트에서 선점|
| # | 프래그먼트의 구획 문자로 선점|
| ? | 질의 문자열의 구획 문자로 선점|
| ; | 파리미터의 구획 문자로 선점|
| : | 스킴, 사용자 이름/비밀번호, 호스트/포트의 구획 문자로 선점|
| $, + | 선점|
| @ & = | 특정 스킴에서 특별한 의미가 있기 때문에 선점|
| { } | \ ~ [ ] `} | 게이트웨이와 같은 여러 전송 에이전트에서 불안전하게 다루기 때문에 제한|
| < > " | 안전하지 않음|
| 0x00-0x1F, 0x7F | 제한됨, 이 16진수 범위에 속하는 문자는 인쇄되지 않는 US-ASCII 문자|
| > 0x7F | 제한됨, 이 16진수 범위에 속하는 문자는 7비트 US-ASCII 문자가 아님|

### **2.5 스킴의 바다**
* 웹에서 쓰이는 일반 스킴들의 포맷
    * `http` : 하이퍼텍스트 전송 프로토콜 스킴
    * `https` : HTTP 커넥션의 양 끝단에서 암호화하기 위해 넷스케이프에서 개발한 SSL을 사용
    * `mailto` : 이메일 주소를 가리킴
    * `ftp` : 파일 전송 프로토콜은 FTP 서버에서 파일을 내려 받거나 올리고, FTP 서버의 디렉터리에 있는 콘텐츠 목록을 가져오는 데 사용할 수 있다.
    * `rtsp`, `rtspu` : RTSP URL은 실시간 스트리밍 프로토콜을 통해서 읽을 수 있는 오디오 및 비디오와 같은 미디어 리소스 식별자
    * `file` : 주어진 호스트 기기에서 바로 접근할 수 있는 파일을 나타냄
    * `news` : RFC 1036에 정으된 특정 문서나 뉴스 그룹에 접근하는데 사용
    * `telnet` : 대화형 서비스에 접근하는데 사용

## **3장 HTTP 메시지**
* HTTP가 인터넷의 배달원이라면, HTTP 메시지는 소포와 같다.

### **3.1 메시지의 흐름**
* HTTP 메시지*는 HTTP 애플리케이션 간에 주고받은 데이터의 블록

#### **3.1.1 메시지는 원 서버 방향을 인바운드로 하여 송신된다**
* HTTP는 인바운드와 아웃바운드라는 용어를 트랜잭션 방향을 표현하기 위해 사용
* 메시지가 원 서버로 향하는 것은 인바운드
* 메시지가 사용자 에이전트로 돌아오는 것은 아웃바운드

#### **3.1.2 다운스트림으로 흐르는 메시지**
* HTTP의 모든 메시지는 다운스트림으로 흐른다

### **3.2 메시지의 각 부분**
* 메시지는 시작줄, 헤더 블록, 본문으로 나뉨

#### **3.2.1 메시지 문법**
* 요청과 응답 모두 구조가 같음
* 요청 구조
    ```
    <메서드> <요청 URL> <버전>
    <헤더>

    <엔터티 본문>
    ```
* 응답 구조
    ```
    <버전> <상태 코드> <사유 구절>
    <헤더>

    <엔터티 본문>
    ```
* 요청과 응답은 시작줄에서만 문법이 다름

* 메서드 : 클라이언트 측에서 서버가 리소스에 대해 수행해주길 바라는 동작
* 요청 URL : 요청 대상이 되는 리소스를 지칭하는 완전한 URL 혹은 URL의 경로 구성 요소
* 버전 : HTTP의 버전. `HTTP/<메이저>.<마이너>`
* 상태 코드 : 요청 중에 무엇이 일어났는지 설명하는 세자리 숫자
* 사유 구절 : 숫자로 된 상태 코드의 의미를 사람이 이해할 수 있게 설명해주는 짧은 문구
* 헤더들 : HTTP 메시지를 설명하는 헤더. 이름, 콜론, 선택적인 공백 값, CRLF가 순서대로 나타나는 0개 이상의 헤더들
* 엔터티 본문 : 임의이 데이터 블록. 모든 메시지가 엔터티 본문을 갖는 것은 아님

#### **3.2.2 시작줄**
* 모든 HTTP 메시지는 시작줄로 시작.
* 요청의 시작줄은 무엇을 해야하는지 말해줌
* 응답의 시작줄은 무슨 일이 일어났는지 말해줌

* 요청줄 : 요청 메시지는 서버에게 리소스에 대해 무언가를 해달라고 부탁
    * 서버에서 어떤 동작이 일어나야 하는지 설명해주는 `메서드`와 그 동작에 대한 대상을 지칭하는 `요청 URL`과 `HTTP 버전` 포함
    * 모든 필드는 공백으로 구분
* 응답줄 : 수행 결과에 대한 상태 정보와 결과 데이터를 클라이언트에게 돌려줌
    * 응답 메시지에서 쓰인 `HTTP의 버전`, 숫자로 된 `상태 코드`, `사유 구절`이 들어 있음
    * 모든 필드는 공백으로 구분
* 메서드 : 서버에게 무엇을 해야하는지 말해줌
    * `GET` : 어떤 문서를 가져옴
    * `HEAD` : 어떤 문서에 대한 헤더만 가져옴
    * `POST` : 처리해야 할 데이터를 보냄. 본문 있음
    * `PUT` : 요청 메시지의 본문을 저장. 본문 있음
    * `TRACE` : 메시지가 프락시를 거쳐 서버에 도달하는 과정을 추적
    * `OPTIONS` : 어떤 메서드를 수행할 수 있는지 확인
    * `DELETE` : 서버에서 문서를 제거
* 상태 코드: 클라이언트에게 무슨일이 일어났는지 설명
    * 100~199 : 정보
    * 200~299 : 성공
    * 300~399 : 리다이렉션
    * 400~499 : 클라이언트 에러
    * 500~599 : 서버에러
* 사유 구절: 상태 코드에 대한 글로 된 설명을 제공
* 버전 번호 : HTTP 애플리케이션들이 자신이 따르는 프로토콜의 버전을 상대방에게 알림

#### **3.2.3 헤더**
* 시작줄 다음에는 0개, 1개 혹은 여러개의 HTTP 헤더가 옴
* HTTP 헤더 필드는 요청과 응답 메시지에 추가 정보를 더한다
* 기본적으로 이름/값 쌍의 목록임

* 헤더 분류 : HTTP 헤더 명세는 여러 헤더 필드를 정의. 애플리케이션은 자유롭게 자신만의 헤더를 만들 수도 있음
    * 일반 헤더 : 요청과 응답 양쪽에 나타남
    * 요청 헤더 : 요청에 대한 부가 정보 제공
    * 응답 헤더 : 응답에 대한 부가 정보 제공
    * Entity 헤더 : 본문 크기와 콘텐츠, 혹은 리소스 그 자체를 서술
    * 확장 헤더 : 명세에 정의되지 않은 새로운 헤더

* 헤더를 여러 줄로 나누기
    * 긴 헤더 줄은 읽기 좋게 여러 줄로 쪼갤 수도 있다.
    * 추가 줄 앞에는 최소 하나의 스페이스 혹은 탭 문자가 와야됨
    ```
    HTTP/1.0 200 OK
    Content-Type: image/gif
    Content-Length: 8572
    Server: Test Server
        Version 1.0
    ```

#### **3.2.4 엔터티 본문**
* HTTP 메시지는 이미지, 비디오, HTML 문서, 소프트웨어 애플리케이션, 신용카드 트랜잭션, 전자우편 등 여러 종류의 디지털 데이터를 엔터티 본문에 실을 수 있다

### **3.3 메서드**
* 모든 서버가 모든 메서드를 구현하지는 않음

#### **3.3.1 안전한 메서드(Safe Method)**
* HTTP는 안전한 메서드라 부리는 메서드의 집합을 정의, ex) `GET`, `HEAD`
* GET이나 HEAD 메서드를 사용하는 HTTP 요청의 결과로 서버에 어떤 일도 일어나지 않음

#### **3.3.2 GET**
* 서버에게 리소스를 달라고 요청하기 위해 쓰임

#### **3.3.3 HEAD**
* GET 처럼 행동하지만, 응답으로 헤더만 돌려줌. 본문은 반환되지 안ㅇㅎ음
    * 리소스를 가져오지 않고도 무엇인지 알 수 있다
    * 상태 코드로 정보를 알 수 있다
    * 리소스가 변경되었는지 검사할 수 있다.


#### **3.3.4 PUT**
* 서버에 새 문서를 만들거나, 이미 URL이 존재한다면 본문을 사용해서 교체

#### **3.3.5 POST**
* 서버에 입력 데이터를 전송하기 위해 설계

#### **3.3.6 TRACE**
* 클라이언트가 요청을 보낼 때, 요청은 방화벽, 프락시, 게이트웨이 등의 애플리케이션을 통과함. 이때 HTTP 요청이 수정될 수 있음
* TRACE 메서드는 클라이언트에게 자신의 요청이 서버에 도달했을 때 어떻게 보이게 되는지 알려준다.
* 요청에 본문을 보낼 수 없음
* 응답의 본문에는 서버가 받은 요청이 그대로 들어있음

#### **3.3.7 OPTIONS**
* 웹 서버에게 특정 리소스에 대해 어떤 메서드가 지원되는지 물어봄

#### **3.3.8 DELETE**
* 서버에게 요청 URL로 지정한 리소스를 삭제할 것을 요청

#### **3.3.9 확장 메서드**
* HTTP는 필요에 따라 확장해도 문제가 없도록 설계


### **3.4 상태 코드**
* 상태 코드는 크게 5가지로 나뉨

#### **3.4.1 100-199 정보성 상태 코드**
* HTTP/1.1에서 도입

* `100 Continue` : 요청의 일부가 받아 들여짐. 클라이언트는 계속 이어서 보냄
* `101 Switcing Protocols` : 클라이언트가 Upgrade 헤더에 나열한 것 중 하나로 서버가 프로토콜을 바꿈

#### **3.4.2 200-299** 성공 상태 코드
* `200 OK` : 정상 요청
* `201 Created` : 서버에 개체를 생성하라는 요청에 대한 응답. 리소스에 대한 참조가 담긴 `Locataion` 헤더와 함께 여러 URL을 엔터티 본문에 포함
* `202 Accepted` : 요청은 받아들여졌으니 어떠한 동작도 수행하지 않음. 단지 요청이 받아들이기 적합해 보인다는 의미
* `203 Non-Authoritative Infomation` : 엔터티 헤더에 들어있는 정보가 원래 서버가 아닌 리소스 사본에서 옴
* `204 No Content` : 헤더와 상태줄을 포함하지만 본문을 포함하지 않음
* `205 Reset Content` : 브라우저용 코드. 브라우저에게 현재 페이지에 있는 HTML 폼에 채워진 모든 값을 비우라고 함
* `206 Parital Content` : 범위 요청이 성공, `Content-Range`와 `Date`헤더를 반드시 포함해야 함, `Etag`와 `Content-Location` 중 하나의 헤더도 반드시 포함

#### **3.4.3 300-399** 리다이렉션 상태 코드
* 클라이언트가 관심있어 하는 리소스에 대해 다른 위치를 사용하라고 알려주거나, 그 리소스의 내용 대신 다른 대안 응답을 제공
* 몇몇은 리소스에 대한 애플리케이션의 로컬 복사본이 원래 서버와 비교했을 때 유효한지 확인하기 위해 사용
* 클라이언트가 특정일 이후에 수정한 경우에만 문서를 가져오라고 `If-Modified-Since` 헤더에 담아 전송하면, 문서가 해당 날짜 이후에 변한 것이 없다면, 서버는 콘텐츠 대신 304 상태 코드로 응답
* `300 Multiple Choices` : 클라이언트가 동시에 여러 리소스를 가리키는 URL을 요청한 경우, 해당 리소스의 목록과 함께 반환. 사용자는 목록중 하나를 택할 수 있다.
* `301 Moved Permanently` : 요청한 URL이 옮겨졌을 때 사용. `Location` 헤더에 현재 리소스가 존재하고 있는 URL을 포함
* `302 Found` : `301` 상태 코드와 같음. 하지만 `Location` 헤더로 주어진 URL에 대한 리소스만 임시로 사용. 이후의 요청은 원래 URL 사용
* `303 See Other` : 리소스를 다른 URL에서 가져와야 한다고 알릴 때 사용. 새 URL은 응답 메시지의 Location 헤더에 들어 있음
* `304 Not Modified` : 클라이언트가 GET과 같은 조건부 요청을 보냈고 해당 리소스가 최근에 수정된 일이 없다면, 해당 리소스가 수정되지 않았음을 의미
* `305 Use Proxy` : 리소스가 반드시 프락시를 통해서 접근되어야 함을 알려줌. 프락시의 위치는 Location 헤더를 통해 주어짐
* `306` : 사용 안됨
* `307 Temporary Redirect` : 301 상태 코드와 비슷함. 클라이언트는 Location 헤더로 주어진 URL을 리소스를 임시로 가리키기 위한 목적으로 사용. 이후의 요청에서는 원래 URL을 사용

#### **3.4.4 400-499 클라이언트 에러 상태 코드**
* 클라이언트가 잘못 된 요청을 서버로 보냈을 때 사용하는 코드
* `400 Bad Request` : 클라이언트가 요청을 잘못 보냄
* `401 Unauthorized` : 리소스를 얻기 전에 스스로를 인증하라고 요구
* `402 Payment Required` : 사용 안됨. 미래를 위해 준비
* `403 Forbidden` : 요청이 거부됨.
* `404 Not Found` : 요청한 URL을 찾을 수 없음을 알려줌
* `405 Method Not Allowd` : 지원하지 않는 메소드로 요청을 받았을 때 사용
* `406 Not Acceptable` : 주어진 URL에 대한 리소스 중 클라이언트가 받아들일 수 있는 것이 없는 경우 사용
* `407 Proxy Authentication Required` : 401과 같으나, 리소스에 대해 인증을 요구하는 프락시 서버를 위해 사용
* `408 Request Timeout` : 클라이언트의 요청을 처기하기에 시간이 너무 많이 걸리는 경우, 서버가 요청을 취소하고 해당 코드로 응답
* `409 Conflict` : 요청이 충돌을 일으킬 염려가 있다고 생각될 때 사용
* `410 Gone` : 404와 비슷함. 하지만 서버가 한 때 리소스를 가지고 있었음
* `411 Length Required` : 요청 메시지에 Content-Length가 있어야 할 경우 사용
* `412 Precondition Failed` : 클라이언트가 조건부 요청을 했는데 그중 하나가 실패
* `413 Request Entity Too Large` : 서버가 처리할 수 있는 한계를 넘은 크기의 요청을 보냈을 때
* `414 Not Acceptable` : 요청 URL이 서버가 처리할 수 있는 한계의 길이를 넘었을 때 사용
* `415 Unsuproted Media Type` : 서버가 이해하거나 지원하지 못하는 내용 유형의 엔터티를 클라이언트가 전송했을 때 사용
* `416 Requested Range Not Satisfiable` : 요청이 리소스의 특정 범위를 요청했는데, 범위가 잘못 되었거나 맞지 않을 때 사용
* `417 Not Acceptable` : Expect 요청 헤더에 서버가 만족시킬 수 없는 기대가 담겨있는 경우 사용

#### **3.4.5 500-599 서버 에러 상태 코드**
* 서버 자체에서 발생한 에러
* `500 Internal Server Error` : 서버가 요청을 처리할 수 없게 만드는 에러를 만났을 때 사용
* `501 Not Implemented` : 클라이언트가 서버의 능력을 넘는 요청을 했을 때 사용
* `502 Bad Gateway` : 프락시나 게이트웨이 같은 서버가 해당 요청 응답 연쇄에 있는 다음 링크로부터 가짜 응답에 맞닥뜨렸을 때 사용
* `503 Service Unavailable` : 현재 서버가 요청을 처리 할 수 없을 때 사용. 추후에 가능
* `504 Gateway Timeout` : 408과 비슷하지만, 다른 서버에게 요청을 보내고 응답을 기다리다 타임아웃이 발생한 게이트웨이나 프락시에서 온 응답이라는 점이 다름
* `505 HTTP Version Not Supported` : 서버가 지원할 수 없는 버전의 프로토콜로 된 요청을 받았을 때 사용

### **3.5 헤더**
* 헤더와 메서드는 클라이언트와 서버가 무엇을 하는지 결정하가 위해 함께 사용
* 일반 헤더(General Headers) : 일반 헤더는 클라이언트와 서버 양쪽 모두 사용.
* 요청 헤더(Request Header) : 요청 메시지를 위한 헤더.
* 응답 헤더(Response Header) : 응답 메시지를 위한 헤더
* 엔터티 헤더(Entity Header) : 엔터티 본문에 대한 헤더
* 확장 헤더(Extension Headers) : 개발자들에 의해 만들어졌지만 아직 HTTP 명세에 추가되지 않은 비표준 헤더.

#### **3.5.1 일반 헤더**
* 아주 기본적인 정보 제공
* `Connection` : 클라이언트와 서버 간 연결에 대한 옵션을 정의
* `Date` : 메시지가 만들어진 날짜와 시간
* `MIME-Version` : 발송자가 사용한 MIME의 버전
* `Trailer chunked transfer` : 메시지 끝 부분에 위치한 헤더들의 목록
* `Transfer-Encoding` : 적용된 인코딩
* `Upgrade` : 업그레이드 하길 원하는 새 버전이나 프로토콜
* `Via` : 어떤 중개자를 거쳐왔는지 보여줌

#### **3.5.2 요청 헤더**
* 요청에서만 의미를 갖는 헤더. 요청이 발생한 곳, 무엇이 보냈는지, 클라이언트의 선호나 능력 등의 정보 제공
* `Client-IP` : 실행된 컴퓨터의 IP 제공
* `From` : 사용자의 메일 주소
* `Host` :  요청 대상이 되는 서버의 호스트 명과 포트
* `Referer` : 현재 요청의 URI가 있던 URL 정보
* `UA-Color` : 클라이언트 기기 디스플레이 색상 능력
* `UA-CPU` : 클라이언트 CPU의 종류나 제조사
* `UA-Disp` : 클라이언트의 디스플레이 능력
* `UA-OS` : 운영체제 이름과 버전
* `UA-Pixels` : 클라이언트 기기 디스플레이에 대한 픽셀 정보
* `User-Agent` : 요청을 보낸 애프릴케이션의 이름
* **Accept 관련 헤더** : 클라이언트가 서버에게 자신의 선호화 능력을 알릴 때 사용
    * `Accept` : 서버가 보내도 되는 미디어 종류
    * `Accept-Charset` : 서버가 보내도 되는 문자집합
    * `Accept-Encoding` : 서버가 보내도 되는 인코딩
    * `Accept-Language` : 서버가 보내도 되는 언어
    * `TE` : 서버가 보내도 되는 확장 전송 코딩
* **조건부 요청 헤더** : 클라이언트가 요청에 몇몇 제약을 넣기 위해 사용
    * `Expect` : 요청에 필요한 서버의 행동을 열거
    * `If-Match` : 문서의 엔터티 태그가 주어진 엔터티 태그와 일치하는 경우에만 가져옴
    * `If-Modified-Since` : 주어진 날짜 이후에 리소스가 변경되지 않았다면 요청을 제한
    * `If-None-Match` : 문서의 엔터티 태그가 주어진 엔터티 태그와 일치하지 않는 경우에만 가져옴
    * `If-Range` : 문서의 특정 범위에 대한 요청을 할 수 있게 해준다
    * `If-Unmodified-Since` : 주어진 날짜 이후에 리소스가 변경되었다면 요청을 제한한다
    * `Range` : 서버가 범위 요청을 지원한다면, 리소스에 대한 특정 범위를 요청
* **요청 보안 헤더** : HTTP가 자체적으로 요청을 위한 간단한 인증요구/응답 체계에 사용하는 헤더
    * `Authorization` : 인증 그 자체에 대한 정보
    * `Cookie` : 서버에게 토큰을 전달할 때 사용
    * `Cookie2` : 요청자가 지원하는 쿠키의 버전을 알려줄 때 사용
* **프락시 요청 헤더** : 프락시의 기능을 돕기 위해 정의된 헤더
    * `Max-Forwards` : 요청이 원 서버로 향하는 과정에서 다른 프락시나 게이트웨이로 전달될 수 있는 최대 횟수
    * `Proxy-Authorization` : `Authorization`과 같으나 프락시 인증에서 사용
    * `Proxy-Connection` : `Connection`과 같으나 프락시 연결에서 사용


#### **3.5.3 응답 헤더**
* 클라이언트에게 부가 정보를 제공
* `Age` : 응답이 얼머나 오래 되었는지
* `Public` : 특정 리소스에 대해 지원하는 요청 메서드의 목록
* `Retry-After` : 리소스가 사용 불가능한 상태일 때, 사용 가능해지는 날짜 혹은 시각
* `Server` : 서버 애플리케이션의 이름과 버전
* `Tile` : HTML 문서에 주어진 것과 같은 제목
* `Warning` : reason phrase에 있는 것 보다 더 자세한 경고 메시지
* **협상 헤더** : 서버가 협상 가능한 리소스에 대한 정보를 제공 할 때 사용
    * `Accept-Ranges` : 서버가 자원에 대해 받아들일 수 있는 범위의 형태
    * `Vary` : 응답에 영향을 줄 수 있는 헤더들의 목록
* **응답 보안 헤더**
    * `Proxy-Authenticate` : 프락시에서 클라이언트로 보낸 인증요구 목록
    * `Set-Cookie` : 서버가 클라이 언트를 인증할 수 있도록 클라이언트 측에 토큰을 설정하기 위해 사용
    * `Set-Cookie2` : Set-Cookie와 비슷하게 RFC 2965로 정의된 쿠키
    * `WWW-Authenticate` : 서버에서 클라이언트로 보낸 인증요구 목록

#### **3.5.4 엔터티 헤더**
* 엔터티에 대한 설명을 제공
* `Allow` : 엔터티에 대해 수행될 수 있는 요청 메서드 나열
* `Location` : 엔터티가 실제로 어디에 위치하고 있는지 말해줌
* **콘텐츠 헤더** : 엔터티의 콘텐츠에 대한 구체적인 정보 제공
    * `Content-Base` : 상대 URL을 계산하기 위한 기저 URL
    * `Content-Encoding` : 적용된 인코딩 타입
    * `Content-Language` : 본문을 이해하는데 적절한 자연어
    * `Content-Lenght` : 본문의 길이
    * `Content-Location` : 실제 리소스 위치
    * `Content-MD5` : 본문의 MD5 체크섬
    * `Content-Range` : 전체 리소스에서 이 엔터티가 해당하는 범위를 바이트 단위로 표현
    * `Content-Type` :  본문이 어떤 종류의 객체인지
* **엔터티 캐싱 헤더** : 엔터티 캐싱에 대한 정보 제공
    * `Etag` : 엔터티에 대한 엔터티 태그
    * `Expires` : 엔터티가 유효하지 않아 원본을 다시 받아와야 하느 일시
    * `Last-Modified` : 가장 최근 엔터티가 변경된 일시

## **4장 커넥션 관리**
* HTTP 애플리케이션을 개발한다면 HTTP 커넥션과 그것이 어떻게 사용되는지에 대해 잘 이해하고 있어야 한다

### **4.1 TCP 커넥션**
* 모든 HTTP 통신은 TCP/IP를 통해 이루어짐
* 커넥션이 맺어지면 클라이언트와 서버 간에 주고받는 메시지들은 손실 혹은 손상 되거나 순서가 바뀌지 않고 안전하게 전달됨

#### **4.1.1 신뢰할 수 있는 데이터 전송 통로인 TCP**
* TCP 커넥션은 인터넷을 안정적으로 연결해 줌. 신뢰성 보장

#### **4.1.2 TCP 스트림은 세그먼트로 나뉘어 IP 패킷을 통해 전송**
* TCP는 IP 패킷이라고 불리는 작은 조각을 통해 데이터를 전송
* TPC는 세그먼트라는 단위로 데이터 스트림을 잘게 나누고, 세그먼트를 IP 패킷에 담아 인터넷을 통해 전달

#### **4.1.3 TCP 커넥션 유지하기**
* 컴퓨터는 항상 여러개의 TCP 커넥션을 가지고 있음. TCP는 포트 번호를 통해서 이런 여러 개의 커넥션을 유지
* TCP 커넥션은 네 가지 값으로 식별
    * `<발신지 IP 주소, 발신지 포트, 수신지 IP 주소, 수신지 포트>`

#### **4.1.4 TCP 소켓 프로그래밍**
* 운영체제는 TCP 커넥션의 생성과 관련된 여러 기능을 제공
    * `s = socket(<parameters>)` : 연결 되지 않은 새로운 소켓 생성
    * `bind(s, <local IP:Port>)` : 로컬 포트 번호와 인터페이스 할당
    * `connect(s, <remote IP:port>)` : 로컬의 소켓과 원격의 호스트 및 포트 사이에 TCP 커넥션 생성
    * `listen(s, ...)` : 커넥션을 받아들이기 위해 로컬 소켓에 허용함을 표시
    * `s2 = accepts(s)` : 로컬 포트에 커넥션을 맺기를 기다림
    * `n = read(s, buffer, n)` : 소켓으로부터 버퍼에 읽기 시도
    * `n = write(s, buffer, n)` : 소켓으로부터 버퍼에 쓰기 시도
    * `close(s)` : TCP 커넥션을 완전히 끊음
    * `shutdown(s, <side>)` : TCP 커넥션의 입출력만 닫음
    * `getsockopt(s, ...)` : 내부 소켓 설정 옵션값을 읽음
    * `setsockopt(s, ...)` : 내부 소켓 설정 옵션값을 변경

### **4.2 TCP의 성능에 대한 고려**
* HTTP는 TCP 위에 있는 계층이기 때문에 HTTP 트랜잭션의 성능은 그 아래 계층인 TCP 성능에 영향을 받음

#### **4.2.1 HTTP 트랜잭션 지연**
* 대부분의 HTTP 지연은 TCP 네트워크 지연 때문에 발생
* HTTP 트랜잭션을 지연시키는 원인
    * 도메인을 DNS를 이용해 IP로 변환하는 시간
    * 클라이언트가 TCP 커넥션 요청을 보내고 서버가 커넥션 허가 응답을 회신하기를 기다리는 시간
    * 메시지가 서버에 전달되고 처리되는 시간
    * 웹 서버가 HTTP 응답을 보내는 시간

#### **4.2.2 성능 관련 중요 요소**
* 가장 일반적인 TCP 관련 지연
    * TCP 커넥션의 핸드셰이크 설정
    * 인터넷의 혼잡을 제어하기 위한 TCP의 느린 시작(slow-start)
    * 데이터를 한데 모아 한 번에 전송하가 위한 네이글(nagle) 알고리즘
    * TCP의 편승(piggyback) 확인응답(acknowledgment)을 위한 확인응답 지연 알고리즘
    * TIEE_WAIT 지연과 포트 고갈

#### **4.2.3 TCP 커넥션 핸드셰이크 지연**
* TCP는 커넥션을 맺기 위한 조건을 맞추기 위해 연속으로 IP 패킷을 교환
* TCP 3way-handshake
    * 클라이언트가 새로운 TCP 커넥션을 생성하기 위해 작은 TCP 패킷(40~60 바이트)을 서버에 보냄. 해당 패킷은 `SYN`라는 플래그를 가짐
    * 서버가 위의 커넥션을 받으면 몇 가지 커넥션 매개변수를 산출하고, 커넥션 요청이 받아들여졌음을 의미하는 `SYN`와 `ACK` 플래그를 포함한 TCP 패킷을 클라이언트에게 보낸다
    * 클라이언트는 커넥션이 잘 맺어졌음을 알리기 위해 서버에게 다시 `ACK` 신호를 보냄
* 크기가 작은 HTTP 트랜잭션은 50% 이상의 시간을 TCP를 구성하기 위해 씀

#### **4.2.4 확인응답 지연**
* TCP는 성공적인 데이터 전송을 보장하기 위해서 자체적인 확인 체계를 가짐
* 각 TCP 세그먼트는 순번과 데이터 무결성 체크섬을 가짐
* 세그먼트 수신자는 세그먼트를 온전히 받으면 작은 확인응답 패킷을 반환. 송신자가 못 받으면 데이터 다시 전송
* 확인응답은 크기가 작기 때문에 TCP는 같은 방향으로 송출되는 데이터 패킷에 확인응답을 `편승(piggyback)` 시킴
* TCP는 송출 데이터 패킷과 확인응답을 하나로 묶음으로써 네트워크를 좀 더 효율적으로 사용
* 확인응답 지연은 송출할 확인응답을 특정 시간 동안(0.1~0.2초) 버퍼에 저장해 두고, 확인응답을 편승시키기 위한 송출 데이터 패킷을 찾음
* HTTP 동작 방식 때문에 확인 응답 패킷이 송출 데이터 패킷에 편승할 기회가 적음. 때문에 확인응답 지연 알고리즘으로 인해 지연이 자주 발생

#### **4.2.5 느린 시작(slow start)**
* TCP 커넥션은 시간이 지나면서 자체적으로 `튜닝`되어서, 점점 속도 제한을 높여 나간다. 이런 조율을 TCP 느린 시작이라고 부름
* 새로운 커넥션은 이미 어느 정도 데이터를 주고 받은 튜닝된 커넥션보다 느림
* HTTP에서는 이미 존재하는 커넥션을 사용하는 기능이 있다 -> HTTP의 지속 커넥션

#### **4.2.6 네이글(Nagle) 알고리즘과 TCP_NODELAY**
* 네이글 알고리즘은 네트워크 효율을 위해서 패킷을 전송하기 전에 많은 양의 TCP 데이터를 한 개의 덩어리로 합침
* HTTP 메시지는 패킷을 다 채우지 못하기 때문에, 앞으로 생기지 않을 모르는 추가적인 데이터를 기다리며 지연됨
* 확인 응답과 같이 쓰면 지연이 더욱 발생함. 네이글 알고리즘이 확인 응답이 도착할 때까지 데이터 전송을 멈추고 있음
* HTTP 애플리케이션은 성능 향상을 위해서 HTTP 스택에 TCP_NODELAY 파라미터 값을 설정해서 네이글 알고리즘을 비활성화 함

#### **4.2.7 TIME_WAIT의 누적과 포트 고갈**
* TIME_WAIT 포트 고갈은 성능 측정 시에 심각한 성능 저하를 발생. 실제 상황에서는 문제를 발생시키지 않음
* TCP 커넥션의 종단에서 TCP 커넥션을 끊으면, 종단에서는 커넥션의 IP 주소와 포트 번호를 메모리의 작은 제어 영역에 기록
* 해당 영역 때문에 같은 커넥션이 생기는것을 일시적으로 방지
* 성능 측정시에는 부하를 발생시킬 컴퓨터 수가 적어서 순간순간 포트를 재활용하는 것이 불가능해짐

## **4.3 HTTP 커넥션 관리**
* 커넥션을 생성하고 최적화하는 HTTP 기술

### **4.3.1 흔히 잘못 이해하는 Connection 헤더**
* HTTP는 클라이언트와 서버 사이에 프락시 서버, 캐시 서버 등과 같은 중개 서버가 올 수 있음.
* 위의 경우, 두 개의 인접한 HTTP 애플리케이션이 현재 맺고 있는 커넥션에만 적용될 옵션을 지정해야 할 때가 있음
* HTTP Connection 헤더는 커넥션 토큰을 쉼표로 구분
* Connection 헤더에는 아래 세가지 종류의 토큰이 전달 될 수 있음
    * HTTP 헤더 필드 명은, 이 커넥션에만 해당되는 헤더들을 나열
    * 임시적인 토큰 값은, 커넥션에 대한 비표준 옵션을 의미
    * close 값은, 작업이 완료되면 커넥션이 종료되어야 함

### **4.3.2 순차적인 트랜잭션 처리에 의한 지연**
* 커넥션 관리가 제대로 이루어지지 않으면 TCP 성능이 매우 안좋아 질 수 있음
* 한 번의 요청에 여러 HTTP 트랜잭션이 만들어지면 커넥션이 계속 만들어짐
* HTTP 커넥션의 성능을 향상시킬 수 있는 기술
    * 병렬(parallel) 커넥션 : 여러 개의 TCP 커넥션을 통한 동시 요청
    * 지속(persistent) 커넥션 : TCP 커넥션의 재활용
    * 파이프라인(pipelined) 커넥션 : 공유 TCP 커넥션을 통한 병렬 요청
    * 다중(multiplexed) 커넥션 : 요청과 응답들에 대한 중재


## **4.4 병렬 커넥션**
* 클라이언트가 여러 개의 커넥션을 맺음으로써 여러 개의 HTTP 트랜잭션을 병렬로 처리할 수 있게 함.

### **4.4.1 병렬 커넥션은 페이지를 더 빠르게 내려받는다**
* 단일 커넥션의 대역폭 제한과 커넥션이 동작하지 않고 있는 시간을 활용하면, 객체가 여러개 있는 웹페이지를 더 빠르게 내려받을 수 있음

### **4.4.2 병렬 커넥션이 항상 더 빠르지는 않다**
* 네트워크 대역폭이 좁을 때는 대부분 시간을 데이터를 전송하는 데만 씀.
* 여러 개의 객체를 병렬로 내려받는 경우, 이 제한된 대역폭 내에서 각 객체를 전송받는 것은 느림
* 다수의 커넥션은 메모리를 많이 소모, 자체적인 성능 문제를 일으킴

### **4.4.3 병렬 커넥션은 더 빠르게 느껴질 수 있다**
* 실제로는 더 빠르지 안힞만, 여러 개의 객체가 동시에 보이면서 내려받고 있는 상황을 보면 사용자가 더 빠르게 내려받고 있는 것처럼 느낄 수 있음

## **4.5지속 커넥션**
* HTTP 서버에 요청을 하기 시작한 애플리케이션은 또 서버에 요청하게 될것. 사이트 지역성이라 부름
* 따라서 HTTP/1.1을 지원하는 기기는 처리가 완료된 후에도 TCP 커넥션을 유지하여 앞으로 있을 HTTP 요청에 재사용할 수 있다

### **4.5.1 지속 커넥션 vs 병렬 커넥션**
* 병렬 커넥션의 단점
    * 각 트랜잭션마다 새로운 커넥션을 맺고 끊기 때문에 시간과 대역폭이 소요
    * 각각의 새로운 커넥션은 TCP 느린 시작 때문에 성능이 떨어짐
    * 실제로 연결할 수 있는 병렬 커넥션의 수에는 제한이 있음
* 지속 커넥션의 장점
    * 커넥션을 맺기 위한 사전 작업과 지연을 줄여줌
    * 튜닝된 커넥션을 유지
    * 커넥션의 수 감소
* 병렬 + 지속 커넥션을 사용할 때 효율이 좋음

### **4.5.2 HTTP/1.0+의 Keep-Alive 커넥션**
* 커넥션을 맺고 끊는 데 필요한 작업이 없어서 시간이 단축

### **4.5.3 Keep-Alive 동작**
* HTTP/1.1 명세에서 빠짐
* 요청 헤더에 `Connection:Keep-Alive` 헤더 포함
* 응답에 `Connection:Keep-Alive` 헤더가 없으면, 클라이언트는 커넥션이 끊길 것이라 추정
### **4.5.4 Keep-Alive 옵션**
* 커넥션을 유지하기를 바라는 요청일 뿐. 무조건 따를 필요는 없음
* Keep-Alive 헤더의 쉼표로 구분된 옵션으로 제어
* timeout 파라미터는 커넥션이 얼마나 유지될 것인지를 의미
* max 파라미터는, 커넥션이 처리할 수 있는 최대 HTTP 트랜잭션 수

### **4.5.5 Keep-Alive 커넥션 제한과 규칙**
* 기본으로 사용되지 않음
* 커넥션을 계속 유지하려면 헤더를 유지해야 됨
* 정확한 Content-Length 값을 보내야 메시지의 끝과 새로운 메시지의 시작점을 정확히 알 수 있음

### **4.5.8 HTTP/1.1의 지속 커넥션**
* HTTP/1.1에서는 지속 커넥션을 지원
* 기본적으로 활성화
* 애플리케이션이 트랜잭션이 끝난 다음 커넥션을 끊으려면 Connection:close 헤더를 명시

### **4.5.9 지속 커넥션의 제한과 규칙**
* 클라이언트가 요청에 Connention: close 헤더를 포함했으면, 해당 커넥션으로 추가 요청 못함
* 커넥션을 종료하기 위해 명시적으로 표시해야 됨
* 모든 메시지가 자신의 길이 정보를 정확하게 가지고 있어야 됨
* 프락시가 별도로 지속 커넥션을 맺고 관리해야 됨

## **4.6 파이프라인 커넥션**
* 지속 커넥션을 통해 요청을 파이프라이닝 할 수 있음
* 커넥션이 지속 커넥션일 때만 파이프라인 가능
* 응답은 요청 순서와 같게 와야 함
* 처리되지 못한 요청이 있다면 다시 보낼 준비를 해야됨
* POST 같이 멱등하지 못한 요청은 파이프라인으로 보내면 위험함


## **4.7 커넥션 끊기에 대한 미스터리**
* 커넥션 관리에 대한 명확한 기준이 없음

### **4.7.1 마음대로 커넥션 끊기**
* HTTP 클라이언트, 서버, 프락시는 언제든 TCP 커넥션을 끊을 수 있음

### **4.7.2 Content-Length와 Truncation**
* 각 HTTP 응답은 본문의 정확한 크기 값을 가지는 Content-Lengh 헤더를 제공
* 일부 오래된 서버는 자신이 커넥션을 끊으면 데이터 전송이 끝났음을 의미하는 형태로 개발되어, Content-Length 헤더를 생략하는 경우도 있음

### **4.7.3 커넥션 끊기의 혀용, 재시도, 멱등성**
* HTTP 애플리케이션은 예상치 못하게 커넥션이 끊어졌을 때에 적절히 대응할 수 있는 준비가 되어 있어야 함
* 클라이언트가 트랜잭션 수행 중에 커넥션이 끊기면, 문제가 없다면 재시도 수행
* POST 부류의 멱등하지 못한 것들은 재시도를 피해야 함

## **4.7.4 우아한 커넥션 끊기**
* TCP는 양방향임
* 전체 끊기와 절반 끊기
    * 애플리케이션은 TCP 입력 채널과 출력 채널 중 한 개만 끊거나 둘 다 끊을 수 있음
* TCP 끊기와 리셋 에러
    * 단순한 HTTP 애플리케이션은 전체 끊기만 할 수 있음
    * 보통 출력 채널을 끊는게 안전함
* 우아하게 커넥션 끊기
    * 일반적으로 우아하게 커넥션을 끊는 방법은 애플리케이션이 자신의 출력 채널을 먼저 끊고 다른 쪽에 있는 기기의 출력 채널이 끊기는 것을 기다리는 것
    
# HTTP 아키텍처
* HTTP 서버, 프락시, 캐시, 게이트웨이, 로봇 애플리케이션에 대해 중점적으로 설명

## 5장 웹서버
* 5장에서 다룰 내용
    * 여러 종류의 소프트웨어 및 하드웨어
    * HTTP 통신을 진단해주는 간단한 웹 서버를 펄로 작성
    * 웹 서버가 HTTP 트랜잭션을 처리하는 단계 설명

## 5.1 다채로운 웹 서버
* 웹 서버는 HTTP 요청을 처리하고 응답을 제공
* 웝 서버는 기능, 형태, 크기가 다양함

### 5.1.1 웹 서버 구현
* 웹 서버는 HTTP 및 그와 관련된 TCP 처리를 구현한 것
* HTTP 프로토콜 구현, 웹 리소스 관리, 웹 서버 관리 기능 제공

### 5.1.2 다목적 소프트웨어 웹 서버
* 네트워크에 연결된 표준 컴퓨터 시스템에서 동작
* 종류가 수만가지지만 실제로 사용되는건 소수

### 5.1.3 임베디드 웹 서버
* 일반 소비자용 제품에 내장될 목적으로 만들어진 작은 웹 서버

### 5.3 진짜 웹 서버가 하는 일
* 커넥션을 맺음
* 요청을 받음
* 요청을 처리
* 리소스에 접근
* 응답을 만듬
* 응답을 보냄
* 트랜잭션을 로깅

### 5.4 단계 1: 클라이언트 커넥션 수락
* 클라이언트는 서버에 대한 새 커넥션을 열 수 있음

#### 5.4.1 새 커넥션 다루기
* 클라이언트가 웹 서버에 TCP 커넥션을 요청하면, 웹 서버는 그 커넥션을 맺고 TCP 커넥션에서 IP 주소를 추출하여 커넥션 맞은편에 어떤 클라이언트가 있는지 확인

#### 5.4.2 클라이언트 호스트 명 식별
* 대부분의 웹 서버는 `역방향 DNS`를 사용해서 클라이언트의 IP 주소를 클라이언트의 호스트 명으로 변환하도록 설정되어 있음.
* hostname lookup 작업은 시간이 많이 걸릴 수 있음

#### 5.4.3 ident를 통해 클라이언트 사용자 알아내기
* IETF ident 프로토콜은 서버에게 어떤 사용자 이름이 HTTP 커넥션을 초기화했는지 찾아낼 수 있게 해준다.
* 웹 서버 로깅에서 유용
* 아래 이유로 잘 사용하진 않음
    * 많은 클라이언트 PC가 identd를 실행 안 함
    * ident 프로토콜은 HTTP 트랜잭션을 유의미하게 지연시킴
    * 방화벽이 ident 트래픽이 들어오는 것을 막는 경우가 많음
    * 안전하지 않고 조작하기 쉬움
    * 가상 IP 주소를 잘 지원하지 않음
    * 프라이버시 침해의 우려가 있음

### 5.5 단계 2: 요청 메시지 수신
* 커넥션에 데이터가 도착하면, 데이터를 읽어 들이고 파싱하여 요청 메시지를 구성
* 요청 메시지를 파싱할 때 웹 서버가 하는 일
    * 요청주을 파싱하여 요청 메서드, 지정된 리소스의 식별자, 버전 번호를 찾음
    * 메시지 헤더들을 읽음
    * 헤더의 끝을 의미하는 CRLF로 끝나는 빈 줄을 찾음
    * 요청 본문이 있다면, 읽어 들임

#### 5.5.1 메시지의 내부 표현
* 몇몇 웹 서버는 요청 메시지를 쉽게 다룰 수 있도록 내부의 자료 구조에 저장

#### 5.5.2 커넥션 입력/출력 처리 아키텍처
* 고성능 웹 서버는 수천 개의 커넥션을 동시에 열 수 있도록 지원
* 웹 서버들을 항상 새 요청을 주시하고 있음

**단일 스레드 웹 서버**
* 한 번에 하나씩 요청을 처리
* 처리 도중 다른 모든 커넥션 무시

**멀티프로세스와 멀티스레드 웹 서버**
* 여러 요청을 동시에 처리하기 위해 여러 개의 프로세스 혹은 고효율 스레드를 할당

**다중 I/O 서버**
* 모든 커넥션이 동시에 활동을 감시 당함
* 커넥션의 상태가 바뀌면, 해당 커넥션에 대해 작은 양의 처리가 수행
* 어떤 커넥션에 대해 실제로 해야 할 일이 있을 때만 처리 됨
* 스레드와 프로세스는 유휴 상태의 커넥션 때문에 리소스를 낭비하지 않는다

**다중 멀티스레드 웹 서버**
* 멀티스레딩과 다중화를 결합한 형태
* 여러 개의 스레드는 각각 열려있는 커넥션을 감시하고 각 커넥션에 대해 조금씩 작업을 수행

## 5.6 단계3: 요청 처리
* 웹 서버가 요청을 받으면, 서버는 요청으로부터 메서드, 리소스, 헤더, 본문을 얻어내어 처리

## 5.7 단계 4: 리소스의 매핑과 접근
* 웹 서버는 리소스 서버
* 웹 서버가 콘텐츠를 전달하려면, 요청 메시지의 URI에 대응하는 콘텐츠의 원천을 식별해야 함

### 5.7.1 Docroot
* 가장 단순하게 요청 URI를 웹 서버의 파일 시스템 안에 있는 파일 이름으로 사용하는 방식
* 웹 서버 파일 시스템의 특별한 폴더를 웹 콘텐츠를 위해 예약 해둠. 이를 문서 루트 or docroot로 불림

### 5.7.2 디렉터리 목록
* 웹 서버는 디렉터리를 가리키는 URL에 대한 요청을 받을 수 있음
* 해당 요청에 대해서 아래와 같은 행동을 취할 수 있음
    * 에러 반환
    * 특별한 `색인 파일`을 반환
    * 디렉터리를 탐색해서 HTML 페이지를 반환
* 대부분 요청한 URL에 대응되는 디렉터리 안에서 index.html 혹은 index.htm으로 이름 붙는 파일을 찾음

### 5.7.3 동적 콘텐츠 리소스 매핑
* URI를 동적 리소스에 매핑할 수도 있음

### 5.7.5 접근 제어
* 각각의 리소스에 접근 제어 할당 가능

## 5.8 단계 5: 응답 만들기
* 서버가 리소스를 식별하면, 서버는 요청 메서드로 서술되는 동작을 수행한 뒤 응답 메시지를 반환

### 5.8.1 응답 엔터티
* 본문이 있다면 다음을 포함
    * 응담 본문의 MIME 타입을 서술하는 Content-Type 헤더
    * 응답 본문의 길이를 서술하는 Content-Length 헤더
    * 실제 응답 본문의 내용

### 5.8.2 MIME 타입 결정하기
* 웹 서버는 응답 본문의 MIME 타입을 결정해야 하는 책임이 있음

### 5.8.3 리다이렉션
* 웹 서버는 종종 성공 메시지 대신 리다이렉션을 반환
* 3xx 상태 코드 지칭
* Location 응답 헤더에 콘텐츠의 새로운 혹은 선호하는 위치에 대한 URI 포함

**영구히 리소스가 옮겨진 경우**
* 리소스에 새 URL이 부여되어 새로운 위치로 옮겨졌거나 이름이 바뀐 경우
* 301 Moved Permanently

**임시로 리소스가 옮겨진 경우**
* 리소스가 임시로 옮겨지거나 이름이 변경된 경우
* 임시적이기 때문에 클라이언트가 나중에는 원래 URL로 찾아와야 함
* 303 See Other와 307 Temporary Redirect

**URL 증강**
* 문맥 정보를 포함시키기 위해 재 작성된 URL로 리다이렉트
* 클라이언트는 리다이렉트를 따라가서, 상태정보가 추가된 완전한 URL을 포함한 요청을 다시 보냄
* 트랜잭션 간 상태를 유지하는 유용한 바업ㅂ
* 303 See Other or 307 Temporary Redirect

**부하 균형**
* 과부하된 서버가 요청을 받으면, 부하가 덜 걸린 서버로 리다이렉트
* 303 See other or 307 Temporary Redirect

**친밀한 다른 서버가 있을 때**
* 서버는 클라이언트를 그 클라이언트에 대한 정보를 갖고 있는 다른 서버로 리다이렉트
* 303 See other or 307 Temporary Redirect

**디렉터리 이름 졍규화**
* 클라이언트가 디렉터리 이름에 대한 URI를 요청하는데 끝에 빗금(/)을 빠뜨렸다면, 대부분의 웹 서버는 상대경로가 정상적으로 동작할 수 있도록 클라이언트를 슬래시를 추가한 URI로 리다이렉트 함

# 6장 프락시
* 클라이언트와 서버 사이에 위치하여 그들 사이의 HTTP 메시지를 정리하는 중개인처럼 동작한다.

## 6.1 웹 중개자
* 웹 프락시 서버는 클라이언트의 입장에서 트랜잭션을 수행하는 중개인
* HTTP 프락시는 서버이기도 하고 클라이언트이기도 함

### 6.1.1 개인 프락시와 공유 프락시
* 프락시 서버는 하나의 클라이언트가 독점적으로 사용할 수도 있고, 여러 클라이언트가 공유할 수도 있음

**공용 프락시**
* 대부분의 프락시는 공용임
* 중앙 집중형 프락시를 관리하는 게 더 비용효율이 높고 쉬움

**개인 프락시**
* 어떤 브라우저 보조 제품들은 몇몇 ISP 서비스와 마찬가지로 브라우저의 기능을 확장하거나 성능을 개선하거나 무료 ISP 서비스를 위한 광고를 운영하기 위해 작은 프락시를 사용자의 컴퓨터에서 직접 실행한다

### 6.1.2 프락시 대 게이트웨이
* 프락시는 같은 프로토콜을 사용하는 둘 이상의 애플리케이션을 연결
* 게이트웨이는 서로 다른 프로토콜을 사용하는 둘 이상을 연결

## 6.2 왜 프락시를 사용하는가?
* 실용적이고 유용한 것이라면 무슨 일이든 한다
* 보안을 개선, 성능을 높여줌, 비용 절약, 트래픽 감시 및 수정

**어린이 필터**
* 교육 사이트를 제공하면서 동시에 성인 콘텐츠를 차단하기 위해 필터링 프락시를 사용

**문서 접근 제어자**
* 중앙 프락시 서버에서 접근 제어를 설정

**보안 방화벽**
* 네트워크 보안 엔지니어가 종종 보안 강화를 위해 사용

**웹 캐시**
* 자주 요청되는 문서의 로컬 사본을 관리하고 해당 문서에 대한 요청이 오면 빠르게 제공

**대리 프락시**
* 웹 서버인것 처럼 위장
* 대리 혹은 리버스 프락시로 불리는 이들은 진짜 웹 서버 요청을 받지만 웹 서버와는 달리 요청 받은 콘텐츠의 위치를 찾아내기 위해 다른 서버와 통신

**콘텐츠 라우터**
* 인터넷 트래픽 조건과 콘텐츠의 종류에 따라 요청을 특정 웹 서버로 유도하는 콘텐츠 라우터로 동작할 수 있다.

**트랜스코더**
* 프락시 서버는 콘텐츠를 클라이언트에게 전달하기 전에 본문 포맷을 수정할 수 있음

**익명화 프락시**
* HTTP 메시지에서 신원을 식별할 수 있는 특성들(IP 주소, From 헤더, Referer 헤더, 쿠키, URI 세션 아이디)을 적극적으로 제거함으로써 개인 정보 보호와 익명성 보장에 기여

## 6.3 프락시는 어디에 있는가?
* 어떻게 프락시가 네트워크에 배치되는가
* 어떻게 프락시의 연쇄가 계층을 이루는가
* 어떻게 트래픽이 올바르게 프락시를 찾아가는가

### 6.3.1 프락시 서버 배치
**출구(Egress) 프락시**
* 로컬 네트워크와 인터넷 사이를 오가는 트래픽 제어 목적을 위해 로컬 네트워크 출구에 배치

**접근(입구) 프락시**
* 모든 요청을 종합적으로 처리하기 위해 ISP 접근 지접에 배치

**대리(리버스) 프락시**
* 네트워크 가장 끝, 웹 서버들의 바로 앞에 위치
* 웹 서버로 향하는 모든 요청을 처리

**네트워크 교환 프락시**
* 혼잡 완화 및 트래픽 흐름 감시

### 6.3.2 프락시 계층
* 프락시 계층이라고 불리는 연쇄를 구성할 수 있음

**프락시 계층 콘텐츠 라우딩**
* 프락시 서버는 여러 가지 판단 근거에 의해 메시지를 다양하고 유동적인 프락시 서버와 원 서버들의 집합에게 보낼 수 있다

**부하 균형**
* 자식 프락시가 부하 분산을 위해 부모들의 작업량 수준에 근거해서 부모 프락시를 고름

**지리적 인접성에 근거한 라우팅**
* 원 서버의 지역을 담당하는 부모를 선택할 수도 있음

**프로토콜/타입 라우팅**
* URI에 근거하여 다른 부모나 원 서버로 라우팅 할 수 있음

**유료 서비스 가입자를 위한 라우팅**
* 빠른 서비스를 위해 추가금을 지불했다면, 대형 캐시나 성능 개선을 위한 압축 엔진으로 라우팅 될 수 있음

### 6.3.3 어떻게 프락시가 트래픽을 처리하는가
* 클라이언트 트래픽이 프락시로 가도록 만드는 방법

    1. 클라이언트를 수정
        * 웹 클라이언트들은 수동 혹은 자동 프락시 지원
    2. 네트워크 수정
        * 네트워크 인프라를 가로채서 웹 트래픽을 프락시로 가도록 조정
    3. DNS 이름공간을 수정
        * 웹 서버 앞에 위치하는 리버스 프락시는 웹 서버의 이름과 IP 주소를 직접 사용
    4. 웹 서버를 수정
        * HTTP 리다이렉션 명령을 클라이언트에게 돌려줌으로써 클라이언트의 요청을 프락시로 리다이렉트 하도록 설정
    
## 6.4 클라이언트 프락시 설정
* 많은 브라우저가 프락시를 설정하는 여러 가지 방법을 제공

1. 수동 설정
    * 프락시를 사용하겠다고 명시적으로 설정
2. 브라우저 기본 설정
    * 브라우저를 소비자에게 전달 하기 전에 프락시를 미리 설정
3. 프락시 자동 설정(PAC)
    * 자바스크립트 프락시 자동 설정 파일에 대한 URI를 제공
4. WPAD 프락시 발견
    * 자동설정 파일을 다운받을 수 있는 설정 서버를 자동으로 찾아주는, 웹 프락시 자동발견 프로토콜(WPAD)을 제공

## 6.5 프락시 요청의 미묘한 특징들
* 프락시 요청의 URI는 서버 요청과 어떻게 다른가
* 인터셉트 프락시와 리버스 프락시는 어떻게 서버 호스트 정보를 알아내기 어렵게 만드는가
* URI 수정에 대한 규칙
* 프락시는 브라우저의 URI 자동완성이나 호스트 명 확장 기능에 어떻게 영향을 주는가

### 6.5.1 프락시 URI는 서버 URI와 다르다
* 웹서버로 보낼때는 요청줄은 URI 부분에서 경로만 가짐
* 프락시로 보낼때는 완전한 URI를 가짐

### 6.5.2 가상 호스팅에서 일어나는 같은 문제
* 가상으로 호스팅 되는 웹 서버는 그 요청이 접근하고자 하는 웹 사이트의 호스트 명을 알 필요가 있음
* 가상으로 호스팅 되는 웹 서버는 호스트와 포트에 대한 정보가 담겨져 있는 Host 헤더를 요구함

### 6.5.3 인터셉트 프락시는 부분 URI를 받는다
* 인터셉트 프락시는 네트워크 흐름 자체는 변경되지 않음
* 클라이언트에서 서버로 가는 트래픽을 가로채 캐시된 응답을 돌려주는 일 등을 함

### 6.5.4 프락시는 프락시 요청과 서버 요청을 모두 다룰 수 있다
* 다목적 프락시는 완전한 URI와 부분 URI를 모두 지원
* 완전 URI와 부분 URI를 사용하는 규칙
    * 완전한 URI가 주어졌다면 그대로 사용
    * 부분 URI가 주어졌고 Host 헤더가 있다면, Host 헤더를 이용해 원 서버의 이름과 포트 번호를 알아냄
    * 부분 URI가 주어졌으나 Host 헤더가 없다면, 아래 방법으로 알아냄
        * 대리(리버스) 프락시라면, 프락시에 실제 서버의 주소와 포트 번호가 설정되어 있을 수 있다.
        * 이전에 어떤 인터셉트 프락시가 가로챘던 트래픽을 받았고, 해당 프락시가 원 IP 주소와 포트번호를 사용할 수 있도록 해두었다면, 그 IP 주소와 포트번호를 사용할 수 있다.
        * 모두 실패하면 에러

### 6.5.5 전송 중 URI 변경
* 사소한 URI 변경이라도 다운스트림 서버와 상호운용성 문제를 일으킬 수 있다

### 6.5.6 URI 클라이언트 자동확장과 호스트 명 분석
* 브라우저는 프락시의 존재 여부에 따라 요청 URI를 다르게 분석
* 사용자가 타이핑한 URI를 가지고 그에 대응하는 IP 주소를 찾으면 연결에 성공할 때까지 시도
* 호스트가 발견되지 않으면, 호스트 명의 짧은 약어를 타이핑한 것으로 보고 자동화된 호스트 명의 확장을 제공

## 6.6. 메시지 추적
* 프락시가 흔해지면서, 프락시를 넘나드는 메시지의 흐름을 추적하고 문제점을 찾아내는 것도 필요한 일이 됨

### 6.6.1 Via 헤더
* 메시지가 지나는 각 중간 노드의 정보를 나열
* 메시지의 전달을 추적하고, 메시지 루프를 진단하고, 요청을 보내고 그에 대한 응답을 돌려주는 과정에 관여하는 모든 메시지 발송자들의 프로토콜을 다루는 능력을 알아보기 위해 사용

#### Via 문법
* 쉼표로 구분된 경유지의 목록
    * 경유지 : 개별 프락시 서버, 게이트웨이 홉
* Via: 1.1 proxy-62.irense-isp.net, 1.0 cache.jose.hardware.com
* 형식 구문
```
Via                 = "Via" ":" ( waypoint ) [", " ( waypoint)...]
waypoint            = (received-protocol received-by [ comment ] )
received-protocal   = [ protocol-name "/" ] protocol-version
recevied-by         = (host [ ":" prot ] ) | pseudonym
```

**프로토콜 이름**
* 중개자가 받은 프로토콜

**프로토콜 버전**
* 수신한 메시지의 버전

**노드 이름**
* 중개자의 호스트와 포트번호

**노드 코멘트**
* 중개자 노드를 서술하는 선택적인 코멘트

**Via 요청과 응답 경로**
* 요청 메시지와 응답 메시지 모두 프락시를 지나므로 둘 모두 Via 헤더를 가짐

**Via와 게이트웨이**
* 몇몇 프락시는 서버에게 비 HTTP 프로토콜을 사용할 수 있는 게이트웨이 기능을 제공

**Server 헤더와 Via 헤더**
* Server 응답 헤더 필드는 원 서버에 의해 사용되는 소프트웨어를 알려줌

**Via가 개인정보 보호와 보안에 미치는 영향**
* 프락시는 방화벽 뒤에 숨어있는 호스트의 이름과 포트를 전달해서는 안됨

### 6.6.2 TRACE 메서드
* 프락시 서버는 메시지가 전달될 때 메시지를 수정할 수 있음
* 요청 메시지를 프락시의 연쇄를 따라가면서 어떤 프락시를 지나가고 어떻게 각 프락시가 요청 메시지를 수정하는지 관찰/추적할 수 있도록 해줌

**Max-Forwards**
* TRACE 메시지는 중간에 프락시들이 몇 개나 있든 신경 쓰지 않고 목적지 서버로의 모든 경로를 여행
* 홉 개수를 제한하기 위해 사용

## 6.7 프락시 인증
* 프락시는 접근 제어 장치로서 제공될 수 있음

## 6.8 프락시 상호운용성
* 프락시 서버는 서로 다른 프로토콜을 구현했을 수도 있고 골치 아프게 이상한 동작을 할 수도 있는 클라이언트와 서버 사이를 중개해야 한다.

### 6.8.1 지원하지 않는 헤더와 메서드 다루기
* 프록시는 이해할 수 없는 헤더 필드는 반드시 그대로 전달
* 지원하지 않는 메서드라도 다음 홉으로 전달하려 시도해야 됨
* HTTP/1.1은 메서드 확장을 허용

### 6.8.2 OPTIONS: 어떤 기능을 지원하는지 알아보기
* HTTP OPTIONS 메서드는 서버나 웹 서버의 특정 리소스가 어떤 기능을 지원하는지 알 수 있게 해줌

### 6.8.3 Allow 헤더
* 요청 URI에 의해 식별되는 자원에 대해 지원되는 메서드들이나 서버가 지원하는 모든 메서드를 열거
* Allow: GET, HEAD, PUT

# 7장. 캐시
* 웹 캐시는 자주 쓰이는 문서의 사본을 자동으로 보관하는 HTTP 장치
* 캐시의 장점
    * 불필요한 데이터 전송을 줄여줌
    * 네트워크 병목을 줄여줌
    * 원 서버에 대한 요청을 줄여줌
    * 거리로 인한 지연을 줄여줌

## 7.1 불필요한 데이터 전송
* 여러 클라이언트들이 하나의 자원에 대해 요청하면 각각 처리하게 됨.
* 똑같은 바이트들이 네트워크를 통해 반복해서 이동하기 때문에 불필요함
* 캐시는 첫 번째 서버 응답을 캐시에 보관. 캐시된 사본들이 이후 요청에 대한 응답으로 사용

## 7.2 대역폭 병목
* 클라이언트들이 서버에 접근할 때의 속도는, 그 경로에 있는 가장 느린 네트워크의 속도와 같음.
* 클라이언트가 빠른 LAN에 있는 캐시로부터 사본을 가져오면 성능을 대폭 개선할 수 있음

## 7.3 갑작스런 요청 쇄도(Flash Crowds)
* 갑작스런 사건으로 인해 많은 사람들이 거의 동시에 웹 문서에 접근할 때 문제가 발생
* 이럴 때 캐싱을 사용하면 대처 가능

## 7.4 거리로 인한 지연
* 거리가 길 수록 네트워크 지연이 생김
* 노드 근처에 캐시를 설치해서 문서가 전송되는 거리를 줄이면 성능을 개선 할 수 있음

## 7.5 적중과 부적중
* 캐시 적중(cache hit) : 캐시에 요청이 도착했을 때, 그에 대응하는 사본이 있다면 해당 요청으로 처리
* 캐시 부적중(cache miss) : 캐시에 요청이 도착했을 때, 그에 대응하는 사본이 없어 원 서버로 전달

## 7.5.1 재검사(Revalidation)
* 원 서버 콘텐츠는 변경될 수 있음.
* 캐시는 사본이 최신인지 서버를 통해 확인해야 함. 이러한 '신선도 검사'를 HTTP 재검사라 부름
* 캐시가 원 서버에 재검사 요청을 보내고, 콘텐츠가 변경되지 않았다면 304 Not Modified 응답을 보냄. 이를 재검사 적중, 느린 적중이라 부름
* HTTP는 캐시된 객체를 재확인하기 위한 몇가지 도구를 제공. If-Modified-Since 헤더가 많이 쓰임

**재검사 적중**
* 만약 서버 객체가 변경되지 않았다면, 서버는 클라이언트에게 HTTP 304 Not Modified 응답을 보냄

**재검사 부적중**
* 서버 객체가 캐시된 사본과 다르다면, 서버는 콘텐츠 전체와 함께 HTTP 200 OK 응답을 보냄

**객체 삭제**
* 서버 객체가 삭제되었다면, 서버는 404 Not Found 응답을 보내고, 캐시는 사본을 삭제함

### 7.5.2 적중률
* 캐시가 요청을 처리하는 비율을 캐시 적중률, 문서 적중률이라고도 부름
* 0% = 캐시 부적중, 100% 캐시 적중

### 7.5.3 바이트 적중률
* 문서들의 크기가 모두 같지 않기 때문에, 문서 적중률이 모든 것을 말해주지는 않음
* 큰 객체는 덜 접근되더라도 크기 때문에 전체 트래픽에는 더 크게 기여함. 이런 이유로 바이트 단위 적중률 측정값을 선호하는 사람들이 있음
* 바이트 단위 적중률은 캐시를 통해 제공된 모든 바이트의 비율을 표현

### 7.5.4 적중과 부적중의 구별
* HTTP는 클라이언트에게 응답이 캐시 적중이였는지 부적중이였는지 말해줄 수 있는 방법이 없음
* Via 헤더에 추가 정보를 붙이는 프락시 캐시
* Date 헤더를 현재 시간과 비교해 캐시인지 아닌지 확인
* 응답이 얼마나 오래되었는지 말해주는 Age 헤더를 이용

### 7.6 캐시 토폴로지
* 캐시는 한 명의 사용자에게만 할당될 수도 있고, 수천 명의 사용자들 간에 공유될 수도 있음

### 7.6.1 개인 전용 캐시
* 웹브라우저는 개인 전용 캐시를 내장
* 자주 쓰이는 문서를 개인용 컴퓨터의 디스크와 메모리에 캐시

### 7.6.2 공용 프락시 캐시
* 공용 캐시는 캐시 프락시 서버 or 프락시 캐시라 불리는 공유된 프락시 서버
* 프락시 캐시는 로컬 캐시에서 문서를 제공하거나, 사용자의 입장에서 서버에 접근

### 7.6.3 프락시 캐시 계층들
* 작은 캐시에서 캐시 부적중이 발생했을 때 더 큰 부모 캐시가 그 트래픽을 처리하도록 하는 계층을 만드는 방식이 합리적인 경우가 많음

### 7.6.4 캐시망, 콘텐츠 라우팅, 피어링
* 복잡한 캐시망을 만드는 경우도 있음
* 캐시망의 프락시 캐시는 서로 대화하며, 어떤 부모 캐시와 대화할 것인지, 요청이 캐시를 완전히 우회해서 원 서버로 바로 가도록 할 것인지에 대한 캐시 커뮤니케이션 결정을 동적으로 내림

## 7.7 캐시 처리 단계
* HTTP GET 메시지 하나를 처리하는 기본적인 캐시 처리 절차는 일곱 단계로 이루어져 있음
    1. 요청 받기 - 네트워크로부터 도착한 요청 메시지를 읽음
    2. 파싱 - 메시지를 파싱하여 URL과 헤더들을 추출
    3. 검색 - 캐시는 로컬 복사본이 있는지 검사하고, 사본이 없다면 사본을 받아옴
    4. 신선도 검사 - 캐시된 사본이 신선한지 검사. 신선하지 않다면 변경사항이 있는지 서버에게 물어봄
    5. 응답 생성 - 새로운 헤더와 캐시된 본문으로 응답 메시지를 만듬
    6. 발송 - 네트워크를 통해 응답을 클라이언트로 전송
    7. 로깅 - 로그파일에 트랜잭션에 대해 서술한 로그 하나를 남김

### 7.7.1 단계 1: 요청 받기
* 네트워크 커넥션에서 활동을 감지하고, 들어오는 데이터를 읽어들임

### 7.7.2 단계 2: 파싱
* 요청 메시지를 여러 부분으로 파싱하여, 조작하기 쉬운 자료 구조에 담음

### 7.7.3 단계 3: 검색
* URL을 알아내고 그에 해당하는 로컬 사본이 있는지 검사
* 캐시된 객체는 얼마나 오랫동안 머물렀는지, 얼마나 자주 사용되었는지에 대한 메타데이터 제공

### 단계 4: 신선도 검사
* HTTP는 캐시가 일정 기간 동안 서버 문서의 사본을 보유할 수 있도록 해줌
* 이 기간 동안, 문서는 '신선'한 것으로 간주. 
* 캐시된 사본을 신선도 한계를 넘을 정도로 오래 갖고 있었다면 '신선하지 않은'것으로 간주. 문서를 제공하기 전 어떤 변경이 있었는지 검사하기 위해 서버에 재검사를 요청

### 단계 5: 응답 생성
* 캐시는 캐시된 서버 응답 헤더를 톹대로 응답 헤더 생성
* 캐시는 클라이언트에 맞게 이 헤더를 조정

### 단계 6: 전송
* 응답 헤더가 준비되면, 응답을 클라이언트에게 전달

### 단계 7: 로깅
* 캐시는 로그 파일과 캐시 사용에 대한 통계를 유지

## 7.8 사본을 신선하게 유지하기
* 캐시된 사본이 항상 서버의 문서와 일치하는 것은 아님
* 캐시된 데이터는 서버의 데이터와 일치하도록 관리되어야 함

### 7.8.1 문서 만료
* HTTP는 Cache-Control과 Expires라는 특별한 헤더를 이용해서 원 서버가 각 문서에 유효기간을 붙일 수 있게 해줌
* 이 헤더들은 콘텐츠가 얼마나 오랫동안 신선한 상태로 보일 수 있는지 좌우함

### 7.8.2 유효기간과 나이
* 서버는 응답 본문과 함께, HTTP/1.0+ Expires나 HTTP/1.1 Cache-Control: max-age 응답 헤더를 이용해서 유효기간을 명시
* 절대 시간은 컴퓨터의 시계가 올바르게 맞추어져 있는 것을 요구
* `Cache-Control: max-age` : 문서의 최대 나이를 정의. 문서가 생성된 이후부터 경과된 초단위의 시간
* `Expires`: 절대 유효기간을 명시

### 7.8.3 서버 재검사
* 문서가 만료되었다고 원 서버에 존재하는 것과 실제로 다르다는 것을 의미하지는 않음
* 다만 변경되었는지 검사를 해야한다는 것을 의미. 이를 `서버 재검사`라 부름

### 7.8.4 조건부 메서드와 재검사
* HTTP의 조건부 메서드는 재검사를 효율적으로 만들어줌
* HTTP는 다섯 가지 조건부 요청 헤더를 정의. 그 중 둘은 캐시 재검사를 할 때 유용한 `If-Modified-Since`와 `If-None-Match`이다.
* `If-Modified-Since: <date>`: 문서가 주어진 날짜 이후로 수정되었다면 요청 메서드를 처리. 캐시된 버전으로부터 콘텐츠가 변경된 경우에만 콘텐츠를 가져오기 위해 `Last-Modified` 서버 응답 헤더와 함께 사용
* `If-None-Match: <tags>`: 마지막 변경된 날짜를 맞춰보는 대신, 문서에 대한 일련번호와 같이 동작하는 특별한 태그를 제공할 수 있음. `If-None-Match` 헤더는 캐시된 태그가 서버에 있는 문서의 태그와 다를 때만 요청을 처리

### 7.8.5 If-Modified-Since: 날짜 재검사
* 리소스가 특정 날짜 이후로 변경된 경우에만 요청한 본문을 보내달라고 함
* 만약 문서가 주어진 날짜 이후에 변경되었다면, IMS 조건은 참이되고 GET 요청은 평범하게 처리됨.
* 만약 문서가 주어진 날짜 이후에 변경되지 않았다면 조건은 거짓이고, 서버는 304 Not Modified 응답 메시지를 클라이언트에게 돌려줌

### 7.8.6 If-None-Match: 엔터티 태그 재검사
* 아래와 같이 최근 변경 일시 재검사가 어려운 상황이 있음
    * 어떤 문서는 일정 시간 간격으로 다시 쓰여짐. 실제로는 같은 데이터를 포함. 내용에 변화가 없더라도 변경시각은 바뀔 수 있음
    * 어떤 문서들의 변경은 전 세계의 캐시들이 그 데이터를 다시 읽어들이기엔 사소한 것일 수 있음(철자나 주석의 변경)
    * 어떤 서버들은 갖고 있는 페이지에 대한 최근 변경 일시를 정확하게 판별 할 수 없음
    * 1초보다 작은 간격으로 갱신되는 문서들을 제공하는 서버들에게는 변경일에 대한 1초의 정밀도는 충분하지 않을 수 있음
* 퍼블리셔가 문서를 변경했을 때, 그는 문서의 엔터티 태그를 새로운 버전으로 표현할 수 있음. 엔터티 태그가 변경되었다면, 캐시는 새 문서의 사본을 얻기 위해 `If-None-Match` 조건부 헤더를 사용
* 캐시는 엔터티 태그 `v2.6`인 문서를 가지고 서버에 해당 태그가 아닌 경우에만 새 객체를 달라고 요청하는 방법으로 재검사

### 7.8.7 약한 검사기와 강한 검사기
* 캐시된 버전이 서버가 갖고 있는 것에 대해 최신인지 확인하기 위해 엔터티 태그를 사용. 이 경우, 엔터티 태그와 최근 변경일시는 둘 다 캐시 검사기
* 서버는 모든 캐시된 사본을 무효화시키지 않고 문서를 살짝 고칠 수 있도록 허용하고 싶은 경우가 있음. HTTP/1.1은, 콘텐츠가 조금 변경되었더라도, "그 정도면 같은 것"이라고 서버가 주장할 수 있도록 해주는 `약한 검사기`를 지원
* 강한 검사기는 콘텐츠가 바뀔 때마다 바뀜
* `W/` 접두사로 약한 검사기를 구분
    ```http
    ETag: W/"v2.6"
    If-None-Match: W/"v2.6"
    ```

### 7.8.8 언제 엔터티 태그를 사용하고 언제 Last-Modified 일시를 사용하는가
* 클라이언트는 서버가 엔터티 태그를 반환했다면, 반드시 엔터티 태그 검사기를 사용.
* 서버가 Last-Modified 값만을 반환했다면, 클라이언트는 IMS 검사를 사용

## 7.9 캐시 제어
* HTTP는 캐시된 문서의 만료 기간을 설정할 수 있는 방법을 정의
    * Cache-Control: no-store 헤더를 응답에 첨부
    * Cache-Control: no-cache 헤더를 응답에 첨부
    * Cache-Control: must-revalidate 헤더를 응답에 첨부
    * Cache-Control: max-age 헤더를 응답에 첨부
    * Expires 날짜 헤더를 응답에 첨부
    * 캐시가 스스로 체험적인(휴리스틱) 방버으로 결정

### 7.9.1 no-cache와 no-store 응답 헤더
* 캐시가 검증되지 않은 캐시된 객체로 응답하는 것을 막음
* `no-store` : 캐시가 그 응답의 사본을 만드는 것을 금지
* `no-cache` : 로컬 캐시 저장소에 저장될 수 있음. 서버와 재검사를 하지 않고서는 캐시에서 클라이언트로 제공될 수 없음

### 7.9.2 Max-Age 응답 헤더
* 신선하다고 간주되었던 문서가 서버로 온 이후로 흐른 시간을 초로 나타낸 것

### 7.9.3 Expires 응답 헤더
* 실제 만료 날짜를 명시

### 7.9.4 Must-Revalidate 응답 헤더
* 캐시가 신선하지 않은(만료된) 객체를 제공하도록 설정될 수 있다
* 캐시가 만료 정보를 엄격하게 따르길 원한다면 `Cache-Control: must-revalidate` 헤더를 붙임

### 7.9.5 휴리스틱 만료
* 응답이 캐시 관련 헤더가 없으면, 캐시가 경험적인 방법(heuristic)으로 만료 시점을 계산

### 7.9.6 클라이언트 신선도 제약
* 웹브라우저는 신선하지 않은 콘텐츠를 강제로 갱신시켜주는 리프레시 버튼을 갖고 있음
* 이 버튼은 Cache-Control 요청 헤더가 추가된 GET 요청을 발생시켜, 강제로 재검사 하거나 서버로부터 콘텐츠를 무조건 가져온다

### 7.9.7 주의할 점
* 퍼블리셔가 유효기간을 까마득한 미래로 설정해버린다면, 문서의 변경이 캐시에 반영되지 않음

## 7.12 캐시와 광고
* 캐시는 사용자를 도와 더 좋은 경험을 제공하고, 또한 네트워크 사업자들이 트래픽을 줄일 수 있도록 도와줌

### 7.12.1 광고 회사의 딜레마
* 캐시를 쓰면 원 서버의 실제 접근 횟수를 알수 없게 된다. 그래서 조회수를 기준으로 광고비를 측정하면 문제가 됨

### 7.12.2 퍼블리셔의 응답
* 콘텐츠 제공다는 캐시가 트래픽을 흡수하도록 내버려 두고, 캐시는 서버에 얼마나 접근 되었는지 알려야 됨
* 재검사를 강제하도록 하면 모든 요청마다 재검사를 하니까 알 수 있지만, 느림
### 7.12.3 로그 마이그레이션
* 서버로 가는 요청을 막고 로그 데이터로 측정

### 7.12.4 적중 측정과 사용량 제한
* 특정 URL에 대한 캐시 적중 횟수를 정기적으로 서버에게 돌려주는 Meter라고 하는 새 헤더를 사용
* 서버는 캐시로부터 문서의 적중한 횟수를 받을 수 있음





