# HTTP: 웹의 기초

## **1장 HTTP 개관**
이번 장에서 다루게 될 것
* 얼마나 많은 클라이언트와 서버가 통신하는지
* 리소스가(웹 콘텐츠) 어디서 오는지
* 웹 트랜잭션이 어떻게 동작하는지
* HTTP 통신을 위해 사용하는 메시지의 형식
* HTTP 기저의 TCP 네트워크 전송
* 여러 종류의 HTTP 프로토콜
* 인터넷 곳곳에 설치된 다양한 HTTP 구성요소

### **1.1 HTTP: 인터넷의 멀티미디어 배달부**
* HTTP는 전 세계의 웹 서버로부터 대량의 정보를 빠르고, 간편하고 정확하게 사람들의 PC에 설치 된 웹브라우저로 옮겨준다.
* HTTP는 `신뢰성 있는 데이터 전송 프로토콜을 사용`하기 때문에, 전송 중 손상되지 않음을 보장한다.

### **1.2 웹 클라이언트와 서버**
* 웹 콘텐츠는 웹 서버에 존재
* 웹 서버는 데이터를 저장하고 HTTP 클라이언트가 요청한 데이터를 제공
* 웹브라우저 같은 것들을 HTTP 클라이언트라고 함

### **1.3 리소스**
* 웹 서버는 웹 리소스를 관리하고 제공
* `정적 리소스` - 이미지, HTML 파일, 텍스트 파일, 워드 파일 등
* `동적 리소스` - 요청에 따라 달라짐. 카메라 라이브 영상, 주식 거래, 부동산 데이터베이스 등
* 어떤 종류의 콘텐츠 소스도 리소스가 될 수 있음

#### **1.3.1 미디어 타입**
* 인터넷은 수천 가지 데이터 타입을 다루기 때문에, HTTP는 웹에서 전송되는 객체 각각에 MIME 타입이라는 데이터 포맷 라벨을 붙인다.
    * `MIME` : Multipurpose Internet Mail Extensions
* MIME는 원래 각기 다른 전자메일 시스템 사이에서 메시지가 오갈 때 겪는 문제점을 해결하기 위해 설계
* MIME가 이메일에서 잘 동작해서, HTTP에서도 멀티미디어 콘텐츠를 기술하고 라벨을 붙이기 위해 채택
* MIME 타입은 사선(/)으로 구분된 주 타입과 부 타입으로 이루어진 문자열 라벨.
    * HTML로 작성된 텍스트 문서 : `text/html`
    * plain ASCII 텍스트 문서 : `text/plain`
    * JPEG 이미지 : `image/jpeg`
    * GIF 이미지 : `image/gif`

#### **1.3.2 URI**
* 웹 서버 리소스는 각자 이름을 갖고 있음. 클라이언트는 관심 있는 리소스 지목 가능
* 서버 리소스 이름은 `통합 자원 식별자, 혹은 URI(uniform resource identifier)`로 불림
* URI는 정보 리소스를 고유하게 식별하고 위치를 지정할 수 있다.

#### **1.3.3 URL**
* `통합 자원 지시자(uniform resource locator, URL)`는 리소스 식별자의 가장 흔한 형태
* URL은 특정 서버의 한 리소스에 대한 구체적인 위치를 서술
* 대부분의 URL은 세 부분으로 이루어진 표준 포맷을 따름
    * URL의 첫 번째 부분은 스킴(scheme)이라고 불리는데, 리소스에 접근하기 위해 사용되는 프로토콜을 서술. ex) HTTP, FTP, WS ...
    * 두 번째 부분은 서버의 인터넷 주소를 제공
    * 마지막은 웹 서버의 리소스를 지정
* 오늘날 대부분의 URI는 URL임

#### **1.3.4 URN**
* `유니폼 리소스 이름(uniform resource name, URN)`은 콘텐츠를 이루는 한 리소스에 대해, 그 리소스의 위치에 영향 받지 않는 유일무이한 이름 역할을 함
* URN은 위치에 독립적이며, 리소스를 여기저기 옮기더라도 문제 없이 동작한다.

### **1.4 트랜잭션**
* HTTP 트랜잭션은 요청 명령과 응답 결과로 구성되어 있다

#### **1.4.1 메서드**
* HTTP는 `HTTP 메서드`라고 불리는 여러 종류의 요청 명령을 지원
* 모든 HTTP 요청은 한 개의 메서드를 가짐
    * `GET` : 서버에서 클라이언트로 지정한 리소스를 보내라
    * `PUT` : 클라이언트에서 서버로 보낸 데이터를 지정한 이름의 리소스로 저장하라
    * `DELETE` : 지정한 리소스를 서버에서 삭제하라
    * `POST` : 클라이언트 데이터를 서버 게이트웨이 애플리케이션으로 보내라
    * `HEAD` : 지정한 리소스에 대한 응답에서, HTTP 헤더 부분만 보내라

#### **1.4.2 상태 코드**
* 모든 HTTP 응답 메시지는 `상태 코드`와 함께 반환
* 상태 코드는 클라이언트에게 요청이 성공했는지 아니면 추가 조치가 필요한지 알려주는 세 자리 숫자
    * `200` : 문서가 올바르게 반환
    * `302` : 자원을 다른 곳에 가서 가져가라
    * `404` : 리소스 못 찾음
* HTTP는 숫자 상태 코드에 텍스트로 된 `사유 구절(reason phrase)`도 함께 보냄
    * `200 OK`
    * `200 DOcument attached`
    * `200 Success`
    * `200 All's cool, dude`

#### **1.4.3 웹페이지는 여러 객체로 이루어질 수 있다
* 애플리케이션은 보통 하나의 작업을 수행하기 위해 여러 HTTP 트랜잭션을 수행
* 웹페이지는 보통 하나의 리소스가 아닌 리소스의 모음이다

### **1.5 메시지**
* HTTP 메시지는 사람이 읽고 쓸 수 있는 단순한 줄 단위의 문자열이다.
* HTTP 메시지는 다음의 세 부분으로 이루어 짐
    * 시작줄 : 요청이라몃 무엇을 해야하는지, 응답이라면 무슨 일이 일어났는지 서술
    * 헤더 : 시작줄 다음에는 0개 이상의 헤더 필드가 이어짐. 콜론(:)으로 구분되어 키 밸류 형식으로 구성 
    * 본문 : 헤더 아래 빈줄 다음 어떤 종류으 데이터든 필요에 따라 들어갈 수 있다. 텍스트와 이진 데이터 포함 가능

### **1.6 TCP 커넥션**
* HTTP 메시지 전송에 사용

#### **1.6.1 TCP/IP**
* HTTP는 통신의 세부사항에 대해 신경쓰지 않음. 대중적이고 신뢰성 있는 인터넷 전송 프로토콜인 TCP/IP에게 맡긴다
* TCP가 제공하는 것
    * 오류 없는 데이터 전송
    * 순서에 맞는 전달
    * 조각나지 않는 데이터 스트림

#### **1.6.2 접속, IP 주소, 포트번호
* TCP/IP 커넥션에는 인터넷 프로토콜(IP) 주소와 포트번호가 필요

### **1.7 프로토콜 버전**
HTTP 프로토콜의 다양한 버전.

**HTTP/0.9**
* GET 메서드만 지원
* 멀티미디어 콘텐츠에 대한 MIME 타입이나 HTTP 헤더, 버전 번호를 지원하지 않음
* 금방 HTTP/1.0으로 대체

**HTTP/1.0**
* 버전 번호, HTTP 헤더, 추가 메서드, 멀티미디어 객체 처리 추가
* 웹페이지와 상호작용하는 폼을 실현

**HTTP/1.0+**
* 오래 지속되는 "keep-alive" 커넥션, 가상 호스팅 지원, 프락시 연결 지원을 포함한 많은 기능이 비공식적이지만 사실상 표준으로 HTTP에 추가

**HTTP/1.1**
* HTTP 설계의 구조적 결함 교정, 두드러진 성능 최적화, 잘못된 기능 제거에 집중
* 더 복잡한 웹 애플리케이션 베포 지원
* 현재 자주 사용하는 버전

**HTTP/2.0**
* HTTP/1.1 성능 문제를 개선하기 위해 구글의 SPDY 프로토콜을 기반으로 설계

### **1.8 웹의 구성요소**
다양한 웹의 구성요소들

**프락시**
* 클라이언트와 서버 사이에 위치한 HTTP 중개자

**캐시**
* 많이 찾는 웹페이지를 클라이언트 가까이에 보관하는 HTTP 창고

**게이트웨이**
* 다른 애플리케이션과 연결된 특별한 웹 서버

**터널**
* 단순히 HTTP 통신을 전달하기만 하는 특별한 프락시

**에이전트**
* 자동화된 HTTP 요청을 만드는 준지능적 웹클라이언트

#### **1.8.1 프락시**
* 웹 보안, 애플리케이션 통합, 성능 최적화를 위한 중요한 구성요소
* 클라이언트와 서버 사이에 위치하여 클라이언트의 모든 HTTP 요청을 받아 서버에 전달
* 주로 보안을 위해 사용
* 요청와 응답을 필터링

#### **1.8.2 캐시**
* 웹캐시와 캐시 프락시는 자신을 거쳐 가는 문서들 중 자주 찾는 것의 사본을 저장 해 두는 특별한 종류의 HTTP 프락시 서버

#### **1.8.3 캐시**
* 다른 서버들의 중개자로 동작하는 특별한 서버
* 주로 HTTP 트래픽을 다른 프로토콜로 변환하기 위해 사용

#### **1.8.4 터널**
* 터널은 두 커넥션 사이에서 날(raw) 데이터를 열어보지 않고 그대로 전달해주는 HTTP 애플리케이션
* 예, 암호화된 SSL 트래픽을 HTTP 커넥션으로 전송함으로써 웹 트래픽만 허용하는 사내 방화벽을 통과

#### **1.8.5 에이전트**
* 사용자를 위해 HTTP 요청을 만들어주는 클라이언트 프로그램
* 웹브라우저, 스파이더, 웹로봇 등


## **2장 URL과 리소스**
* URL은 인터넷의 리소스를 가리키는 표준이름.
    * 리소스: 텍스트, 이미지, 동영상 같이 웹에서 사용되는 식별을 할 수 있는 모든 자원을 가리킴
* URL은 전자정보 일부를 가리키고 그것이 어디에 있고 어떻게 접근할 수 있는지 알려줌

### **2.1 인터넷의 리소스 탐색하기**
* URL은 브라우저가 정보를 찾는데 필요한 리소스의 위치를 가리킴
* URL은 통합 자원 식별자(Uniform Resource Identifier) 혹은 URI라고 불리는 더 일반화된 부류의 부분집합
* `http://naver.com/cafe/index.html`
    * URL의 첫 부분인 `http`는 URL의 스킴이다. 어떤 프로토콜을 사용해 접근하는지 알려줌
    * URL의 두 번째 부분인 `naver.com`은 서버의 위치이다. 리소스가 어디에 호스팅 되어 있는지 알려준다
    * URL의 세 번째 부분인 `/cafe/index.html`은 리소의 경로이다. 경로는 서버에 존재하는 로컬 리소스들 중에서 요청받은 리소스가 무엇인지 알려줌

### **2.2 URL 문법**
* 대부분의 URL 스킴의 문법은 일반적으로 9개 부분으로 나뉨
* `<스킴>://<사용자이름>:<비밀번호>@<호스트>:<포트>/<경로>;<파라미터>?<질의>#<프래그먼트>`

| 컴포넌트 | 설명 | 기본값 |
|--------|-----|------|
스킴      | 서버 접근에 사용하는 프로토콜 | 없음
사용자 이름 | 리소스 접근에 필요한 사용자 이름 | anonymous
비밀번호   | 사용자의 비밀번호 |<이메일 주소>
호스트    | 리소스를 호스팅하는 서버의 호스트 명이나 IP 주소 | 없음
포트      | 리소스를 호스팅하는 서버가 열어놓은 포트번호 | 스킴에 따라 다름
경로    | 서버 내 리소스가 서버 어디에 있는지를 가리킴 | 없음
파라미터 | 특정 스킴들에서 입력 파라미터를 기술하는 용도로 사용 | 없음
질의    | 스킴에서 애플리케이션에 파라미터를 전달하는데 사용 | 없음
프래그먼트 | 리소스의 조각이나 일부분을 가리키는 이름 | 없음

#### **2.2.1 스킴: 사용할 프로토콜**
* URL을 해석하는 애플리케이션이 어떤 프로토콜을 사용하여 리소스를 요청해야 하는지 알려줌
* 대소문자 구분 안 함

#### **2.2.2 호스트와 포트**
* 리소스를 찾기 위해 리소스가 호스팅하고 있는 장비와 그 장비 내에서 리소스에 접근할 수 있는 서버가 어디에 있는지 알려줌

#### **2.2.3 사용자 이름과 비밀번호**
* 서버가 가지고 있는 데이터에 접근을 허용하기 전에 사용자 이름과 비밀번호를 요구하는데 그때 사용

#### **2.2.4 경로**
* 리소스가 서버의 어디에 있는지 알려줌
* `/`문자를 기준으로 경로조각으로 나뉨

#### **2.2.5 파라미터**
* 서버에 정확한 요청을 하기 위해 필요한 입력 파라미터를 받는데 사용
* 이름/값 쌍의 리스트로 `;`로 구분해서 URL에 기술

#### **2.2.6 질의 문자열**
* 데이터베이스 같은 서비스들은 요청받을 리소스 형식의 범위를 좁히기 위해 질의문이나 질의를 받음
* `&`로 나뉜 `이름=값` 쌍 형식의 질의 문자열을 사용

#### **2.2.7 프래그먼트**
* HTML 같은 리소스 형식들은 본래의 수준보다 더 작게 나뉠 수 있음
* 리소스의 특정 부분을 가리킬 수 있도록, URL은 리소스 내의 조각을 가리킬 수 있는 프래그먼트 컴포넌트를 제공
* 프래그먼트는 브라우저가 서버에서 전체 리소스를 내려받은 후, 프래그먼트를 사용하여 리소스의 일부를 보여줌

### **2.3 단축 URL**
* 웹 클라이언트는 몇몇 단축 URL을 인식하고 사용

#### **2.3.1 상대 URL**
* URL은 상대 URL과 절대 URL로 나뉨
* 절대 URL은 리소스 접근에 필요한 모든 정보를 담고 있지만 상대 URL은 모든 정보를 담고 있지 않다
* 상대 URL로 리소스에 접근하는데 필요한 모든 정보를 얻기 위해서는 `기저(base)`라고 하는 다른 URL을 사용해야 함
    * 기저 URL : `http://naver.com/first.html`
    * 상대 URL : `./second.html`
    * 기저 URL + 상대 URL : `http://naver.com/second.html`

* 기저 URL : 변환 과정의 첫 단계는 기저 URL을 찾는 것.
* 기저 URL을 가져오는 방법
    * 리소스에 명시적으로 제공
    * 리소스를 포함하고 있는 기저 URL : 상대 URL이 기저 URL이 명시되지 않은 리소스에 포함된 경우, 해당 리소스의 URL을 기저 URL로 쓸 수 있다.
    * 기저 URL이 없는 경우 : 절대 URL로만 이루어져 있거나 불완전하거나 깨진 것
    * 상대 참조 해석하기
    
#### **2.3.2 URL 확장**
* 브라우저는 URL을 입력하는 중에 URL을 자동으로 확장함.
* 확장의 2가지 방법
    * 호스트 명 확장 : 주소에 `yahoo`를 입력하면 브라우저가 `www.`와 `.com`을 붙여서 `www.yahoo.com`으로 만드는 방식
    * 히스토리 확장 : 과거에 사용자가 방문했던 URL 기록을 저장.

### **2.4 안전하지 않은 문자**
* URL은 일반적으로 안전한 알파벳 문자만 포함하도록 허락함
* 근데 URL에 이진데이터나 다른 문자도 포함할 때가 있음. 이때 이스케이프라는 기능을 이용해서 안전하지 않은 문자를 안전한 문자로 인코딩 할 수 있다

#### **2.4.1 URL 문자 집합**
* 컴퓨터의 기본 문자 집합은 보통 영어 중심임
* URL에 포함할 수없는 문자를 포함하기 위해 이스케이프 기능을 지원.
* 이스케이프 문자열은 US-ASCII에서 사용이 금지된 문자들로, 특정 문자나 데이터를 인코딩할 수 있게 함으로써 이동성과 완성도를 높임

#### **2.4.1 인코딩 체계**
* 안전하지 않은 문자들을 표현할 수 있는 인코딩 방식이 고안
* 퍼센티지 기호(%)로 시작해 ASCII 코드로 표현되는 두 개의 16진수 숫자로 이루어진 이스케이프 문자로 바꿈

| 문자 | ASCII 코드 |
|-----|-----------|
| ~ | 126(0x7E) |
| 빈 문자| 32(0x20) |
| % | 37(0x25) |

#### **2.4.3 문자 제한**
* 몇몇 문자는 URL 내에서 특별한 의미로 예약되어 있음
* 아래 표는 URL에서 예약된 문자들을 본래의 목적이 아닌 다른 용도로 사용하려면, 그 전에 반드시 인코딩 해야하는 문자

| 문자 | 선점 및 제한|
|-----|----------|
| % | 인코딩된 문자에 사용할 이스케이프 토큰으로 선점|
| / | 경로 컴포넌트에 있는 경로 세그먼트를 나누는 용도로 선점|
| . | 경로 컴포넌트에서 선점|
| .. | 경로 컴포넌트에서 선점|
| # | 프래그먼트의 구획 문자로 선점|
| ? | 질의 문자열의 구획 문자로 선점|
| ; | 파리미터의 구획 문자로 선점|
| : | 스킴, 사용자 이름/비밀번호, 호스트/포트의 구획 문자로 선점|
| $, + | 선점|
| @ & = | 특정 스킴에서 특별한 의미가 있기 때문에 선점|
| { } | \ ~ [ ] `} | 게이트웨이와 같은 여러 전송 에이전트에서 불안전하게 다루기 때문에 제한|
| < > " | 안전하지 않음|
| 0x00-0x1F, 0x7F | 제한됨, 이 16진수 범위에 속하는 문자는 인쇄되지 않는 US-ASCII 문자|
| > 0x7F | 제한됨, 이 16진수 범위에 속하는 문자는 7비트 US-ASCII 문자가 아님|

### **2.5 스킴의 바다**
* 웹에서 쓰이는 일반 스킴들의 포맷
    * `http` : 하이퍼텍스트 전송 프로토콜 스킴
    * `https` : HTTP 커넥션의 양 끝단에서 암호화하기 위해 넷스케이프에서 개발한 SSL을 사용
    * `mailto` : 이메일 주소를 가리킴
    * `ftp` : 파일 전송 프로토콜은 FTP 서버에서 파일을 내려 받거나 올리고, FTP 서버의 디렉터리에 있는 콘텐츠 목록을 가져오는 데 사용할 수 있다.
    * `rtsp`, `rtspu` : RTSP URL은 실시간 스트리밍 프로토콜을 통해서 읽을 수 있는 오디오 및 비디오와 같은 미디어 리소스 식별자
    * `file` : 주어진 호스트 기기에서 바로 접근할 수 있는 파일을 나타냄
    * `news` : RFC 1036에 정으된 특정 문서나 뉴스 그룹에 접근하는데 사용
    * `telnet` : 대화형 서비스에 접근하는데 사용

## **3장 HTTP 메시지**
* HTTP가 인터넷의 배달원이라면, HTTP 메시지는 소포와 같다.

### **3.1 메시지의 흐름**
* HTTP 메시지*는 HTTP 애플리케이션 간에 주고받은 데이터의 블록

#### **3.1.1 메시지는 원 서버 방향을 인바운드로 하여 송신된다**
* HTTP는 인바운드와 아웃바운드라는 용어를 트랜잭션 방향을 표현하기 위해 사용
* 메시지가 원 서버로 향하는 것은 인바운드
* 메시지가 사용자 에이전트로 돌아오는 것은 아웃바운드

#### **3.1.2 다운스트림으로 흐르는 메시지**
* HTTP의 모든 메시지는 다운스트림으로 흐른다

### **3.2 메시지의 각 부분**
* 메시지는 시작줄, 헤더 블록, 본문으로 나뉨

#### **3.2.1 메시지 문법**
* 요청과 응답 모두 구조가 같음
* 요청 구조
    ```
    <메서드> <요청 URL> <버전>
    <헤더>

    <엔터티 본문>
    ```
* 응답 구조
    ```
    <버전> <상태 코드> <사유 구절>
    <헤더>

    <엔터티 본문>
    ```
* 요청과 응답은 시작줄에서만 문법이 다름

* 메서드 : 클라이언트 측에서 서버가 리소스에 대해 수행해주길 바라는 동작
* 요청 URL : 요청 대상이 되는 리소스를 지칭하는 완전한 URL 혹은 URL의 경로 구성 요소
* 버전 : HTTP의 버전. `HTTP/<메이저>.<마이너>`
* 상태 코드 : 요청 중에 무엇이 일어났는지 설명하는 세자리 숫자
* 사유 구절 : 숫자로 된 상태 코드의 의미를 사람이 이해할 수 있게 설명해주는 짧은 문구
* 헤더들 : HTTP 메시지를 설명하는 헤더. 이름, 콜론, 선택적인 공백 값, CRLF가 순서대로 나타나는 0개 이상의 헤더들
* 엔터티 본문 : 임의이 데이터 블록. 모든 메시지가 엔터티 본문을 갖는 것은 아님

#### **3.2.2 시작줄**
* 모든 HTTP 메시지는 시작줄로 시작.
* 요청의 시작줄은 무엇을 해야하는지 말해줌
* 응답의 시작줄은 무슨 일이 일어났는지 말해줌

* 요청줄 : 요청 메시지는 서버에게 리소스에 대해 무언가를 해달라고 부탁
    * 서버에서 어떤 동작이 일어나야 하는지 설명해주는 `메서드`와 그 동작에 대한 대상을 지칭하는 `요청 URL`과 `HTTP 버전` 포함
    * 모든 필드는 공백으로 구분
* 응답줄 : 수행 결과에 대한 상태 정보와 결과 데이터를 클라이언트에게 돌려줌
    * 응답 메시지에서 쓰인 `HTTP의 버전`, 숫자로 된 `상태 코드`, `사유 구절`이 들어 있음
    * 모든 필드는 공백으로 구분
* 메서드 : 서버에게 무엇을 해야하는지 말해줌
    * `GET` : 어떤 문서를 가져옴
    * `HEAD` : 어떤 문서에 대한 헤더만 가져옴
    * `POST` : 처리해야 할 데이터를 보냄. 본문 있음
    * `PUT` : 요청 메시지의 본문을 저장. 본문 있음
    * `TRACE` : 메시지가 프락시를 거쳐 서버에 도달하는 과정을 추적
    * `OPTIONS` : 어떤 메서드를 수행할 수 있는지 확인
    * `DELETE` : 서버에서 문서를 제거
* 상태 코드: 클라이언트에게 무슨일이 일어났는지 설명
    * 100~199 : 정보
    * 200~299 : 성공
    * 300~399 : 리다이렉션
    * 400~499 : 클라이언트 에러
    * 500~599 : 서버에러
* 사유 구절: 상태 코드에 대한 글로 된 설명을 제공
* 버전 번호 : HTTP 애플리케이션들이 자신이 따르는 프로토콜의 버전을 상대방에게 알림

#### **3.2.3 헤더**
* 시작줄 다음에는 0개, 1개 혹은 여러개의 HTTP 헤더가 옴
* HTTP 헤더 필드는 요청과 응답 메시지에 추가 정보를 더한다
* 기본적으로 이름/값 쌍의 목록임

* 헤더 분류 : HTTP 헤더 명세는 여러 헤더 필드를 정의. 애플리케이션은 자유롭게 자신만의 헤더를 만들 수도 있음
    * 일반 헤더 : 요청과 응답 양쪽에 나타남
    * 요청 헤더 : 요청에 대한 부가 정보 제공
    * 응답 헤더 : 응답에 대한 부가 정보 제공
    * Entity 헤더 : 본문 크기와 콘텐츠, 혹은 리소스 그 자체를 서술
    * 확장 헤더 : 명세에 정의되지 않은 새로운 헤더

* 헤더를 여러 줄로 나누기
    * 긴 헤더 줄은 읽기 좋게 여러 줄로 쪼갤 수도 있다.
    * 추가 줄 앞에는 최소 하나의 스페이스 혹은 탭 문자가 와야됨
    ```
    HTTP/1.0 200 OK
    Content-Type: image/gif
    Content-Length: 8572
    Server: Test Server
        Version 1.0
    ```

#### **3.2.4 엔터티 본문**
* HTTP 메시지는 이미지, 비디오, HTML 문서, 소프트웨어 애플리케이션, 신용카드 트랜잭션, 전자우편 등 여러 종류의 디지털 데이터를 엔터티 본문에 실을 수 있다

### **3.3 메서드**
* 모든 서버가 모든 메서드를 구현하지는 않음

#### **3.3.1 안전한 메서드(Safe Method)**
* HTTP는 안전한 메서드라 부리는 메서드의 집합을 정의, ex) `GET`, `HEAD`
* GET이나 HEAD 메서드를 사용하는 HTTP 요청의 결과로 서버에 어떤 일도 일어나지 않음

#### **3.3.2 GET**
* 서버에게 리소스를 달라고 요청하기 위해 쓰임

#### **3.3.3 HEAD**
* GET 처럼 행동하지만, 응답으로 헤더만 돌려줌. 본문은 반환되지 안ㅇㅎ음
    * 리소스를 가져오지 않고도 무엇인지 알 수 있다
    * 상태 코드로 정보를 알 수 있다
    * 리소스가 변경되었는지 검사할 수 있다.


#### **3.3.4 PUT**
* 서버에 새 문서를 만들거나, 이미 URL이 존재한다면 본문을 사용해서 교체

#### **3.3.5 POST**
* 서버에 입력 데이터를 전송하기 위해 설계

#### **3.3.6 TRACE**
* 클라이언트가 요청을 보낼 때, 요청은 방화벽, 프락시, 게이트웨이 등의 애플리케이션을 통과함. 이때 HTTP 요청이 수정될 수 있음
* TRACE 메서드는 클라이언트에게 자신의 요청이 서버에 도달했을 때 어떻게 보이게 되는지 알려준다.
* 요청에 본문을 보낼 수 없음
* 응답의 본문에는 서버가 받은 요청이 그대로 들어있음

#### **3.3.7 OPTIONS**
* 웹 서버에게 특정 리소스에 대해 어떤 메서드가 지원되는지 물어봄

#### **3.3.8 DELETE**
* 서버에게 요청 URL로 지정한 리소스를 삭제할 것을 요청

#### **3.3.9 확장 메서드**
* HTTP는 필요에 따라 확장해도 문제가 없도록 설계


### **3.4 상태 코드**
* 상태 코드는 크게 5가지로 나뉨

#### **3.4.1 100-199 정보성 상태 코드**
* HTTP/1.1에서 도입

* `100 Continue` : 요청의 일부가 받아 들여짐. 클라이언트는 계속 이어서 보냄
* `101 Switcing Protocols` : 클라이언트가 Upgrade 헤더에 나열한 것 중 하나로 서버가 프로토콜을 바꿈

#### **3.4.2 200-299** 성공 상태 코드
* `200 OK` : 정상 요청
* `201 Created` : 서버에 개체를 생성하라는 요청에 대한 응답. 리소스에 대한 참조가 담긴 `Locataion` 헤더와 함께 여러 URL을 엔터티 본문에 포함
* `202 Accepted` : 요청은 받아들여졌으니 어떠한 동작도 수행하지 않음. 단지 요청이 받아들이기 적합해 보인다는 의미
* `203 Non-Authoritative Infomation` : 엔터티 헤더에 들어있는 정보가 원래 서버가 아닌 리소스 사본에서 옴
* `204 No Content` : 헤더와 상태줄을 포함하지만 본문을 포함하지 않음
* `205 Reset Content` : 브라우저용 코드. 브라우저에게 현재 페이지에 있는 HTML 폼에 채워진 모든 값을 비우라고 함
* `206 Parital Content` : 범위 요청이 성공, `Content-Range`와 `Date`헤더를 반드시 포함해야 함, `Etag`와 `Content-Location` 중 하나의 헤더도 반드시 포함

#### **3.4.3 300-399** 리다이렉션 상태 코드
* 클라이언트가 관심있어 하는 리소스에 대해 다른 위치를 사용하라고 알려주거나, 그 리소스의 내용 대신 다른 대안 응답을 제공
* 몇몇은 리소스에 대한 애플리케이션의 로컬 복사본이 원래 서버와 비교했을 때 유효한지 확인하기 위해 사용
* 클라이언트가 특정일 이후에 수정한 경우에만 문서를 가져오라고 `If-Modified-Since` 헤더에 담아 전송하면, 문서가 해당 날짜 이후에 변한 것이 없다면, 서버는 콘텐츠 대신 304 상태 코드로 응답
* `300 Multiple Choices` : 클라이언트가 동시에 여러 리소스를 가리키는 URL을 요청한 경우, 해당 리소스의 목록과 함께 반환. 사용자는 목록중 하나를 택할 수 있다.
* `301 Moved Permanently` : 요청한 URL이 옮겨졌을 때 사용. `Location` 헤더에 현재 리소스가 존재하고 있는 URL을 포함
* `302 Found` : `301` 상태 코드와 같음. 하지만 `Location` 헤더로 주어진 URL에 대한 리소스만 임시로 사용. 이후의 요청은 원래 URL 사용
* `303 See Other` : 리소스를 다른 URL에서 가져와야 한다고 알릴 때 사용. 새 URL은 응답 메시지의 Location 헤더에 들어 있음
* `304 Not Modified` : 클라이언트가 GET과 같은 조건부 요청을 보냈고 해당 리소스가 최근에 수정된 일이 없다면, 해당 리소스가 수정되지 않았음을 의미
* `305 Use Proxy` : 리소스가 반드시 프락시를 통해서 접근되어야 함을 알려줌. 프락시의 위치는 Location 헤더를 통해 주어짐
* `306` : 사용 안됨
* `307 Temporary Redirect` : 301 상태 코드와 비슷함. 클라이언트는 Location 헤더로 주어진 URL을 리소스를 임시로 가리키기 위한 목적으로 사용. 이후의 요청에서는 원래 URL을 사용

#### **3.4.4 400-499 클라이언트 에러 상태 코드**
* 클라이언트가 잘못 된 요청을 서버로 보냈을 때 사용하는 코드
* `400 Bad Request` : 클라이언트가 요청을 잘못 보냄
* `401 Unauthorized` : 리소스를 얻기 전에 스스로를 인증하라고 요구
* `402 Payment Required` : 사용 안됨. 미래를 위해 준비
* `403 Forbidden` : 요청이 거부됨.
* `404 Not Found` : 요청한 URL을 찾을 수 없음을 알려줌
* `405 Method Not Allowd` : 지원하지 않는 메소드로 요청을 받았을 때 사용
* `406 Not Acceptable` : 주어진 URL에 대한 리소스 중 클라이언트가 받아들일 수 있는 것이 없는 경우 사용
* `407 Proxy Authentication Required` : 401과 같으나, 리소스에 대해 인증을 요구하는 프락시 서버를 위해 사용
* `408 Request Timeout` : 클라이언트의 요청을 처기하기에 시간이 너무 많이 걸리는 경우, 서버가 요청을 취소하고 해당 코드로 응답
* `409 Conflict` : 요청이 충돌을 일으킬 염려가 있다고 생각될 때 사용
* `410 Gone` : 404와 비슷함. 하지만 서버가 한 때 리소스를 가지고 있었음
* `411 Length Required` : 요청 메시지에 Content-Length가 있어야 할 경우 사용
* `412 Precondition Failed` : 클라이언트가 조건부 요청을 했는데 그중 하나가 실패
* `413 Request Entity Too Large` : 서버가 처리할 수 있는 한계를 넘은 크기의 요청을 보냈을 때
* `414 Not Acceptable` : 요청 URL이 서버가 처리할 수 있는 한계의 길이를 넘었을 때 사용
* `415 Unsuproted Media Type` : 서버가 이해하거나 지원하지 못하는 내용 유형의 엔터티를 클라이언트가 전송했을 때 사용
* `416 Requested Range Not Satisfiable` : 요청이 리소스의 특정 범위를 요청했는데, 범위가 잘못 되었거나 맞지 않을 때 사용
* `417 Not Acceptable` : Expect 요청 헤더에 서버가 만족시킬 수 없는 기대가 담겨있는 경우 사용

#### **3.4.5 500-599 서버 에러 상태 코드**
* 서버 자체에서 발생한 에러
* `500 Internal Server Error` : 서버가 요청을 처리할 수 없게 만드는 에러를 만났을 때 사용
* `501 Not Implemented` : 클라이언트가 서버의 능력을 넘는 요청을 했을 때 사용
* `502 Bad Gateway` : 프락시나 게이트웨이 같은 서버가 해당 요청 응답 연쇄에 있는 다음 링크로부터 가짜 응답에 맞닥뜨렸을 때 사용
* `503 Service Unavailable` : 현재 서버가 요청을 처리 할 수 없을 때 사용. 추후에 가능
* `504 Gateway Timeout` : 408과 비슷하지만, 다른 서버에게 요청을 보내고 응답을 기다리다 타임아웃이 발생한 게이트웨이나 프락시에서 온 응답이라는 점이 다름
* `505 HTTP Version Not Supported` : 서버가 지원할 수 없는 버전의 프로토콜로 된 요청을 받았을 때 사용

### **3.5 헤더**
* 헤더와 메서드는 클라이언트와 서버가 무엇을 하는지 결정하가 위해 함께 사용
* 일반 헤더(General Headers) : 일반 헤더는 클라이언트와 서버 양쪽 모두 사용.
* 요청 헤더(Request Header) : 요청 메시지를 위한 헤더.
* 응답 헤더(Response Header) : 응답 메시지를 위한 헤더
* 엔터티 헤더(Entity Header) : 엔터티 본문에 대한 헤더
* 확장 헤더(Extension Headers) : 개발자들에 의해 만들어졌지만 아직 HTTP 명세에 추가되지 않은 비표준 헤더.

#### **3.5.1 일반 헤더**
* 아주 기본적인 정보 제공
* `Connection` : 클라이언트와 서버 간 연결에 대한 옵션을 정의
* `Date` : 메시지가 만들어진 날짜와 시간
* `MIME-Version` : 발송자가 사용한 MIME의 버전
* `Trailer chunked transfer` : 메시지 끝 부분에 위치한 헤더들의 목록
* `Transfer-Encoding` : 적용된 인코딩
* `Upgrade` : 업그레이드 하길 원하는 새 버전이나 프로토콜
* `Via` : 어떤 중개자를 거쳐왔는지 보여줌

#### **3.5.2 요청 헤더**
* 요청에서만 의미를 갖는 헤더. 요청이 발생한 곳, 무엇이 보냈는지, 클라이언트의 선호나 능력 등의 정보 제공
* `Client-IP` : 실행된 컴퓨터의 IP 제공
* `From` : 사용자의 메일 주소
* `Host` :  요청 대상이 되는 서버의 호스트 명과 포트
* `Referer` : 현재 요청의 URI가 있던 URL 정보
* `UA-Color` : 클라이언트 기기 디스플레이 색상 능력
* `UA-CPU` : 클라이언트 CPU의 종류나 제조사
* `UA-Disp` : 클라이언트의 디스플레이 능력
* `UA-OS` : 운영체제 이름과 버전
* `UA-Pixels` : 클라이언트 기기 디스플레이에 대한 픽셀 정보
* `User-Agent` : 요청을 보낸 애프릴케이션의 이름
* **Accept 관련 헤더** : 클라이언트가 서버에게 자신의 선호화 능력을 알릴 때 사용
    * `Accept` : 서버가 보내도 되는 미디어 종류
    * `Accept-Charset` : 서버가 보내도 되는 문자집합
    * `Accept-Encoding` : 서버가 보내도 되는 인코딩
    * `Accept-Language` : 서버가 보내도 되는 언어
    * `TE` : 서버가 보내도 되는 확장 전송 코딩
* **조건부 요청 헤더** : 클라이언트가 요청에 몇몇 제약을 넣기 위해 사용
    * `Expect` : 요청에 필요한 서버의 행동을 열거
    * `If-Match` : 문서의 엔터티 태그가 주어진 엔터티 태그와 일치하는 경우에만 가져옴
    * `If-Modified-Since` : 주어진 날짜 이후에 리소스가 변경되지 않았다면 요청을 제한
    * `If-None-Match` : 문서의 엔터티 태그가 주어진 엔터티 태그와 일치하지 않는 경우에만 가져옴
    * `If-Range` : 문서의 특정 범위에 대한 요청을 할 수 있게 해준다
    * `If-Unmodified-Since` : 주어진 날짜 이후에 리소스가 변경되었다면 요청을 제한한다
    * `Range` : 서버가 범위 요청을 지원한다면, 리소스에 대한 특정 범위를 요청
* **요청 보안 헤더** : HTTP가 자체적으로 요청을 위한 간단한 인증요구/응답 체계에 사용하는 헤더
    * `Authorization` : 인증 그 자체에 대한 정보
    * `Cookie` : 서버에게 토큰을 전달할 때 사용
    * `Cookie2` : 요청자가 지원하는 쿠키의 버전을 알려줄 때 사용
* **프락시 요청 헤더** : 프락시의 기능을 돕기 위해 정의된 헤더
    * `Max-Forwards` : 요청이 원 서버로 향하는 과정에서 다른 프락시나 게이트웨이로 전달될 수 있는 최대 횟수
    * `Proxy-Authorization` : `Authorization`과 같으나 프락시 인증에서 사용
    * `Proxy-Connection` : `Connection`과 같으나 프락시 연결에서 사용


#### **3.5.3 응답 헤더**
* 클라이언트에게 부가 정보를 제공
* `Age` : 응답이 얼머나 오래 되었는지
* `Public` : 특정 리소스에 대해 지원하는 요청 메서드의 목록
* `Retry-After` : 리소스가 사용 불가능한 상태일 때, 사용 가능해지는 날짜 혹은 시각
* `Server` : 서버 애플리케이션의 이름과 버전
* `Tile` : HTML 문서에 주어진 것과 같은 제목
* `Warning` : reason phrase에 있는 것 보다 더 자세한 경고 메시지
* **협상 헤더** : 서버가 협상 가능한 리소스에 대한 정보를 제공 할 때 사용
    * `Accept-Ranges` : 서버가 자원에 대해 받아들일 수 있는 범위의 형태
    * `Vary` : 응답에 영향을 줄 수 있는 헤더들의 목록
* **응답 보안 헤더**
    * `Proxy-Authenticate` : 프락시에서 클라이언트로 보낸 인증요구 목록
    * `Set-Cookie` : 서버가 클라이 언트를 인증할 수 있도록 클라이언트 측에 토큰을 설정하기 위해 사용
    * `Set-Cookie2` : Set-Cookie와 비슷하게 RFC 2965로 정의된 쿠키
    * `WWW-Authenticate` : 서버에서 클라이언트로 보낸 인증요구 목록

#### **3.5.4 엔터티 헤더**
* 엔터티에 대한 설명을 제공
* `Allow` : 엔터티에 대해 수행될 수 있는 요청 메서드 나열
* `Location` : 엔터티가 실제로 어디에 위치하고 있는지 말해줌
* **콘텐츠 헤더** : 엔터티의 콘텐츠에 대한 구체적인 정보 제공
    * `Content-Base` : 상대 URL을 계산하기 위한 기저 URL
    * `Content-Encoding` : 적용된 인코딩 타입
    * `Content-Language` : 본문을 이해하는데 적절한 자연어
    * `Content-Lenght` : 본문의 길이
    * `Content-Location` : 실제 리소스 위치
    * `Content-MD5` : 본문의 MD5 체크섬
    * `Content-Range` : 전체 리소스에서 이 엔터티가 해당하는 범위를 바이트 단위로 표현
    * `Content-Type` :  본문이 어떤 종류의 객체인지
* **엔터티 캐싱 헤더** : 엔터티 캐싱에 대한 정보 제공
    * `Etag` : 엔터티에 대한 엔터티 태그
    * `Expires` : 엔터티가 유효하지 않아 원본을 다시 받아와야 하느 일시
    * `Last-Modified` : 가장 최근 엔터티가 변경된 일시

## **4장 커넥션 관리**
* HTTP 애플리케이션을 개발한다면 HTTP 커넥션과 그것이 어떻게 사용되는지에 대해 잘 이해하고 있어야 한다

### **4.1 TCP 커넥션**
* 모든 HTTP 통신은 TCP/IP를 통해 이루어짐
* 커넥션이 맺어지면 클라이언트와 서버 간에 주고받는 메시지들은 손실 혹은 손상 되거나 순서가 바뀌지 않고 안전하게 전달됨

#### **4.1.1 신뢰할 수 있는 데이터 전송 통로인 TCP**
* TCP 커넥션은 인터넷을 안정적으로 연결해 줌. 신뢰성 보장

#### **4.1.2 TCP 스트림은 세그먼트로 나뉘어 IP 패킷을 통해 전송**
* TCP는 IP 패킷이라고 불리는 작은 조각을 통해 데이터를 전송
* TPC는 세그먼트라는 단위로 데이터 스트림을 잘게 나누고, 세그먼트를 IP 패킷에 담아 인터넷을 통해 전달

#### **4.1.3 TCP 커넥션 유지하기**
* 컴퓨터는 항상 여러개의 TCP 커넥션을 가지고 있음. TCP는 포트 번호를 통해서 이런 여러 개의 커넥션을 유지
* TCP 커넥션은 네 가지 값으로 식별
    * `<발신지 IP 주소, 발신지 포트, 수신지 IP 주소, 수신지 포트>`

#### **4.1.4 TCP 소켓 프로그래밍**
* 운영체제는 TCP 커넥션의 생성과 관련된 여러 기능을 제공
    * `s = socket(<parameters>)` : 연결 되지 않은 새로운 소켓 생성
    * `bind(s, <local IP:Port>)` : 로컬 포트 번호와 인터페이스 할당
    * `connect(s, <remote IP:port>)` : 로컬의 소켓과 원격의 호스트 및 포트 사이에 TCP 커넥션 생성
    * `listen(s, ...)` : 커넥션을 받아들이기 위해 로컬 소켓에 허용함을 표시
    * `s2 = accepts(s)` : 로컬 포트에 커넥션을 맺기를 기다림
    * `n = read(s, buffer, n)` : 소켓으로부터 버퍼에 읽기 시도
    * `n = write(s, buffer, n)` : 소켓으로부터 버퍼에 쓰기 시도
    * `close(s)` : TCP 커넥션을 완전히 끊음
    * `shutdown(s, <side>)` : TCP 커넥션의 입출력만 닫음
    * `getsockopt(s, ...)` : 내부 소켓 설정 옵션값을 읽음
    * `setsockopt(s, ...)` : 내부 소켓 설정 옵션값을 변경

### **4.2 TCP의 성능에 대한 고려**
* HTTP는 TCP 위에 있는 계층이기 때문에 HTTP 트랜잭션의 성능은 그 아래 계층인 TCP 성능에 영향을 받음

#### **4.2.1 HTTP 트랜잭션 지연**
* 대부분의 HTTP 지연은 TCP 네트워크 지연 때문에 발생
* HTTP 트랜잭션을 지연시키는 원인
    * 도메인을 DNS를 이용해 IP로 변환하는 시간
    * 클라이언트가 TCP 커넥션 요청을 보내고 서버가 커넥션 허가 응답을 회신하기를 기다리는 시간
    * 메시지가 서버에 전달되고 처리되는 시간
    * 웹 서버가 HTTP 응답을 보내는 시간

#### **4.2.2 성능 관련 중요 요소**
* 가장 일반적인 TCP 관련 지연
    * TCP 커넥션의 핸드셰이크 설정
    * 인터넷의 혼잡을 제어하기 위한 TCP의 느린 시작(slow-start)
    * 데이터를 한데 모아 한 번에 전송하가 위한 네이글(nagle) 알고리즘
    * TCP의 편승(piggyback) 확인응답(acknowledgment)을 위한 확인응답 지연 알고리즘
    * TIEE_WAIT 지연과 포트 고갈

#### **4.2.3 TCP 커넥션 핸드셰이크 지연**
* TCP는 커넥션을 맺기 위한 조건을 맞추기 위해 연속으로 IP 패킷을 교환
* TCP 3way-handshake
    * 클라이언트가 새로운 TCP 커넥션을 생성하기 위해 작은 TCP 패킷(40~60 바이트)을 서버에 보냄. 해당 패킷은 `SYN`라는 플래그를 가짐
    * 서버가 위의 커넥션을 받으면 몇 가지 커넥션 매개변수를 산출하고, 커넥션 요청이 받아들여졌음을 의미하는 `SYN`와 `ACK` 플래그를 포함한 TCP 패킷을 클라이언트에게 보낸다
    * 클라이언트는 커넥션이 잘 맺어졌음을 알리기 위해 서버에게 다시 `ACK` 신호를 보냄
* 크기가 작은 HTTP 트랜잭션은 50% 이상의 시간을 TCP를 구성하기 위해 씀

#### **4.2.4 확인응답 지연**
* TCP는 성공적인 데이터 전송을 보장하기 위해서 자체적인 확인 체계를 가짐
* 각 TCP 세그먼트는 순번과 데이터 무결성 체크섬을 가짐
* 세그먼트 수신자는 세그먼트를 온전히 받으면 작은 확인응답 패킷을 반환. 송신자가 못 받으면 데이터 다시 전송
* 확인응답은 크기가 작기 때문에 TCP는 같은 방향으로 송출되는 데이터 패킷에 확인응답을 `편승(piggyback)` 시킴
* TCP는 송출 데이터 패킷과 확인응답을 하나로 묶음으로써 네트워크를 좀 더 효율적으로 사용
* 확인응답 지연은 송출할 확인응답을 특정 시간 동안(0.1~0.2초) 버퍼에 저장해 두고, 확인응답을 편승시키기 위한 송출 데이터 패킷을 찾음
* HTTP 동작 방식 때문에 확인 응답 패킷이 송출 데이터 패킷에 편승할 기회가 적음. 때문에 확인응답 지연 알고리즘으로 인해 지연이 자주 발생

#### **4.2.5 느린 시작(slow start)**
* TCP 커넥션은 시간이 지나면서 자체적으로 `튜닝`되어서, 점점 속도 제한을 높여 나간다. 이런 조율을 TCP 느린 시작이라고 부름
* 새로운 커넥션은 이미 어느 정도 데이터를 주고 받은 튜닝된 커넥션보다 느림
* HTTP에서는 이미 존재하는 커넥션을 사용하는 기능이 있다 -> HTTP의 지속 커넥션

#### **4.2.6 네이글(Nagle) 알고리즘과 TCP_NODELAY**
* 네이글 알고리즘은 네트워크 효율을 위해서 패킷을 전송하기 전에 많은 양의 TCP 데이터를 한 개의 덩어리로 합침
* HTTP 메시지는 패킷을 다 채우지 못하기 때문에, 앞으로 생기지 않을 모르는 추가적인 데이터를 기다리며 지연됨
* 확인 응답과 같이 쓰면 지연이 더욱 발생함. 네이글 알고리즘이 확인 응답이 도착할 때까지 데이터 전송을 멈추고 있음
* HTTP 애플리케이션은 성능 향상을 위해서 HTTP 스택에 TCP_NODELAY 파라미터 값을 설정해서 네이글 알고리즘을 비활성화 함

#### **4.2.7 TIME_WAIT의 누적과 포트 고갈**
* TIME_WAIT 포트 고갈은 성능 측정 시에 심각한 성능 저하를 발생. 실제 상황에서는 문제를 발생시키지 않음
* TCP 커넥션의 종단에서 TCP 커넥션을 끊으면, 종단에서는 커넥션의 IP 주소와 포트 번호를 메모리의 작은 제어 영역에 기록
* 해당 영역 때문에 같은 커넥션이 생기는것을 일시적으로 방지
* 성능 측정시에는 부하를 발생시킬 컴퓨터 수가 적어서 순간순간 포트를 재활용하는 것이 불가능해짐

## **4.3 HTTP 커넥션 관리**
* 커넥션을 생성하고 최적화하는 HTTP 기술

### **4.3.1 흔히 잘못 이해하는 Connection 헤더**
* HTTP는 클라이언트와 서버 사이에 프락시 서버, 캐시 서버 등과 같은 중개 서버가 올 수 있음.
* 위의 경우, 두 개의 인접한 HTTP 애플리케이션이 현재 맺고 있는 커넥션에만 적용될 옵션을 지정해야 할 때가 있음
* HTTP Connection 헤더는 커넥션 토큰을 쉼표로 구분
* Connection 헤더에는 아래 세가지 종류의 토큰이 전달 될 수 있음
    * HTTP 헤더 필드 명은, 이 커넥션에만 해당되는 헤더들을 나열
    * 임시적인 토큰 값은, 커넥션에 대한 비표준 옵션을 의미
    * close 값은, 작업이 완료되면 커넥션이 종료되어야 함

### **4.3.2 순차적인 트랜잭션 처리에 의한 지연**
* 커넥션 관리가 제대로 이루어지지 않으면 TCP 성능이 매우 안좋아 질 수 있음
* 한 번의 요청에 여러 HTTP 트랜잭션이 만들어지면 커넥션이 계속 만들어짐
* HTTP 커넥션의 성능을 향상시킬 수 있는 기술
    * 병렬(parallel) 커넥션 : 여러 개의 TCP 커넥션을 통한 동시 요청
    * 지속(persistent) 커넥션 : TCP 커넥션의 재활용
    * 파이프라인(pipelined) 커넥션 : 공유 TCP 커넥션을 통한 병렬 요청
    * 다중(multiplexed) 커넥션 : 요청과 응답들에 대한 중재


## **4.4 병렬 커넥션**
* 클라이언트가 여러 개의 커넥션을 맺음으로써 여러 개의 HTTP 트랜잭션을 병렬로 처리할 수 있게 함.

### **4.4.1 병렬 커넥션은 페이지를 더 빠르게 내려받는다**
* 단일 커넥션의 대역폭 제한과 커넥션이 동작하지 않고 있는 시간을 활용하면, 객체가 여러개 있는 웹페이지를 더 빠르게 내려받을 수 있음

### **4.4.2 병렬 커넥션이 항상 더 빠르지는 않다**
* 네트워크 대역폭이 좁을 때는 대부분 시간을 데이터를 전송하는 데만 씀.
* 여러 개의 객체를 병렬로 내려받는 경우, 이 제한된 대역폭 내에서 각 객체를 전송받는 것은 느림
* 다수의 커넥션은 메모리를 많이 소모, 자체적인 성능 문제를 일으킴

### **4.4.3 병렬 커넥션은 더 빠르게 느껴질 수 있다**
* 실제로는 더 빠르지 안힞만, 여러 개의 객체가 동시에 보이면서 내려받고 있는 상황을 보면 사용자가 더 빠르게 내려받고 있는 것처럼 느낄 수 있음

## **4.5지속 커넥션**
* HTTP 서버에 요청을 하기 시작한 애플리케이션은 또 서버에 요청하게 될것. 사이트 지역성이라 부름
* 따라서 HTTP/1.1을 지원하는 기기는 처리가 완료된 후에도 TCP 커넥션을 유지하여 앞으로 있을 HTTP 요청에 재사용할 수 있다

### **4.5.1 지속 커넥션 vs 병렬 커넥션**
* 병렬 커넥션의 단점
    * 각 트랜잭션마다 새로운 커넥션을 맺고 끊기 때문에 시간과 대역폭이 소요
    * 각각의 새로운 커넥션은 TCP 느린 시작 때문에 성능이 떨어짐
    * 실제로 연결할 수 있는 병렬 커넥션의 수에는 제한이 있음
* 지속 커넥션의 장점
    * 커넥션을 맺기 위한 사전 작업과 지연을 줄여줌
    * 튜닝된 커넥션을 유지
    * 커넥션의 수 감소
* 병렬 + 지속 커넥션을 사용할 때 효율이 좋음

### **4.5.2 HTTP/1.0+의 Keep-Alive 커넥션**
* 커넥션을 맺고 끊는 데 필요한 작업이 없어서 시간이 단축

### **4.5.3 Keep-Alive 동작**
* HTTP/1.1 명세에서 빠짐
* 요청 헤더에 `Connection:Keep-Alive` 헤더 포함
* 응답에 `Connection:Keep-Alive` 헤더가 없으면, 클라이언트는 커넥션이 끊길 것이라 추정
### **4.5.4 Keep-Alive 옵션**
* 커넥션을 유지하기를 바라는 요청일 뿐. 무조건 따를 필요는 없음
* Keep-Alive 헤더의 쉼표로 구분된 옵션으로 제어
* timeout 파라미터는 커넥션이 얼마나 유지될 것인지를 의미
* max 파라미터는, 커넥션이 처리할 수 있는 최대 HTTP 트랜잭션 수

### **4.5.5 Keep-Alive 커넥션 제한과 규칙**
* 기본으로 사용되지 않음
* 커넥션을 계속 유지하려면 헤더를 유지해야 됨
* 정확한 Content-Length 값을 보내야 메시지의 끝과 새로운 메시지의 시작점을 정확히 알 수 있음

### **4.5.8 HTTP/1.1의 지속 커넥션**
* HTTP/1.1에서는 지속 커넥션을 지원
* 기본적으로 활성화
* 애플리케이션이 트랜잭션이 끝난 다음 커넥션을 끊으려면 Connection:close 헤더를 명시

### **4.5.9 지속 커넥션의 제한과 규칙**
* 클라이언트가 요청에 Connention: close 헤더를 포함했으면, 해당 커넥션으로 추가 요청 못함
* 커넥션을 종료하기 위해 명시적으로 표시해야 됨
* 모든 메시지가 자신의 길이 정보를 정확하게 가지고 있어야 됨
* 프락시가 별도로 지속 커넥션을 맺고 관리해야 됨

## **4.6 파이프라인 커넥션**
* 지속 커넥션을 통해 요청을 파이프라이닝 할 수 있음
* 커넥션이 지속 커넥션일 때만 파이프라인 가능
* 응답은 요청 순서와 같게 와야 함
* 처리되지 못한 요청이 있다면 다시 보낼 준비를 해야됨
* POST 같이 멱등하지 못한 요청은 파이프라인으로 보내면 위험함


## **4.7 커넥션 끊기에 대한 미스터리**
* 커넥션 관리에 대한 명확한 기준이 없음

### **4.7.1 마음대로 커넥션 끊기**
* HTTP 클라이언트, 서버, 프락시는 언제든 TCP 커넥션을 끊을 수 있음

### **4.7.2 Content-Length와 Truncation**
* 각 HTTP 응답은 본문의 정확한 크기 값을 가지는 Content-Lengh 헤더를 제공
* 일부 오래된 서버는 자신이 커넥션을 끊으면 데이터 전송이 끝났음을 의미하는 형태로 개발되어, Content-Length 헤더를 생략하는 경우도 있음

### **4.7.3 커넥션 끊기의 혀용, 재시도, 멱등성**
* HTTP 애플리케이션은 예상치 못하게 커넥션이 끊어졌을 때에 적절히 대응할 수 있는 준비가 되어 있어야 함
* 클라이언트가 트랜잭션 수행 중에 커넥션이 끊기면, 문제가 없다면 재시도 수행
* POST 부류의 멱등하지 못한 것들은 재시도를 피해야 함

## **4.7.4 우아한 커넥션 끊기**
* TCP는 양방향임
* 전체 끊기와 절반 끊기
    * 애플리케이션은 TCP 입력 채널과 출력 채널 중 한 개만 끊거나 둘 다 끊을 수 있음
* TCP 끊기와 리셋 에러
    * 단순한 HTTP 애플리케이션은 전체 끊기만 할 수 있음
    * 보통 출력 채널을 끊는게 안전함
* 우아하게 커넥션 끊기
    * 일반적으로 우아하게 커넥션을 끊는 방법은 애플리케이션이 자신의 출력 채널을 먼저 끊고 다른 쪽에 있는 기기의 출력 채널이 끊기는 것을 기다리는 것
    
# HTTP 아키텍처
* HTTP 서버, 프락시, 캐시, 게이트웨이, 로봇 애플리케이션에 대해 중점적으로 설명

## 5장 웹서버
* 5장에서 다룰 내용
    * 여러 종류의 소프트웨어 및 하드웨어
    * HTTP 통신을 진단해주는 간단한 웹 서버를 펄로 작성
    * 웹 서버가 HTTP 트랜잭션을 처리하는 단계 설명

## 5.1 다채로운 웹 서버
* 웹 서버는 HTTP 요청을 처리하고 응답을 제공
* 웝 서버는 기능, 형태, 크기가 다양함

### 5.1.1 웹 서버 구현
* 웹 서버는 HTTP 및 그와 관련된 TCP 처리를 구현한 것
* HTTP 프로토콜 구현, 웹 리소스 관리, 웹 서버 관리 기능 제공

### 5.1.2 다목적 소프트웨어 웹 서버
* 네트워크에 연결된 표준 컴퓨터 시스템에서 동작
* 종류가 수만가지지만 실제로 사용되는건 소수

### 5.1.3 임베디드 웹 서버
* 일반 소비자용 제품에 내장될 목적으로 만들어진 작은 웹 서버

### 5.3 진짜 웹 서버가 하는 일
* 커넥션을 맺음
* 요청을 받음
* 요청을 처리
* 리소스에 접근
* 응답을 만듬
* 응답을 보냄
* 트랜잭션을 로깅

### 5.4 단계 1: 클라이언트 커넥션 수락
* 클라이언트는 서버에 대한 새 커넥션을 열 수 있음

#### 5.4.1 새 커넥션 다루기
* 클라이언트가 웹 서버에 TCP 커넥션을 요청하면, 웹 서버는 그 커넥션을 맺고 TCP 커넥션에서 IP 주소를 추출하여 커넥션 맞은편에 어떤 클라이언트가 있는지 확인

#### 5.4.2 클라이언트 호스트 명 식별
* 대부분의 웹 서버는 `역방향 DNS`를 사용해서 클라이언트의 IP 주소를 클라이언트의 호스트 명으로 변환하도록 설정되어 있음.
* hostname lookup 작업은 시간이 많이 걸릴 수 있음

#### 5.4.3 ident를 통해 클라이언트 사용자 알아내기
* IETF ident 프로토콜은 서버에게 어떤 사용자 이름이 HTTP 커넥션을 초기화했는지 찾아낼 수 있게 해준다.
* 웹 서버 로깅에서 유용
* 아래 이유로 잘 사용하진 않음
    * 많은 클라이언트 PC가 identd를 실행 안 함
    * ident 프로토콜은 HTTP 트랜잭션을 유의미하게 지연시킴
    * 방화벽이 ident 트래픽이 들어오는 것을 막는 경우가 많음
    * 안전하지 않고 조작하기 쉬움
    * 가상 IP 주소를 잘 지원하지 않음
    * 프라이버시 침해의 우려가 있음

### 5.5 단계 2: 요청 메시지 수신
* 커넥션에 데이터가 도착하면, 데이터를 읽어 들이고 파싱하여 요청 메시지를 구성
* 요청 메시지를 파싱할 때 웹 서버가 하는 일
    * 요청주을 파싱하여 요청 메서드, 지정된 리소스의 식별자, 버전 번호를 찾음
    * 메시지 헤더들을 읽음
    * 헤더의 끝을 의미하는 CRLF로 끝나는 빈 줄을 찾음
    * 요청 본문이 있다면, 읽어 들임

#### 5.5.1 메시지의 내부 표현
* 몇몇 웹 서버는 요청 메시지를 쉽게 다룰 수 있도록 내부의 자료 구조에 저장

#### 5.5.2 커넥션 입력/출력 처리 아키텍처
* 고성능 웹 서버는 수천 개의 커넥션을 동시에 열 수 있도록 지원
* 웹 서버들을 항상 새 요청을 주시하고 있음

**단일 스레드 웹 서버**
* 한 번에 하나씩 요청을 처리
* 처리 도중 다른 모든 커넥션 무시

**멀티프로세스와 멀티스레드 웹 서버**
* 여러 요청을 동시에 처리하기 위해 여러 개의 프로세스 혹은 고효율 스레드를 할당

**다중 I/O 서버**
* 모든 커넥션이 동시에 활동을 감시 당함
* 커넥션의 상태가 바뀌면, 해당 커넥션에 대해 작은 양의 처리가 수행
* 어떤 커넥션에 대해 실제로 해야 할 일이 있을 때만 처리 됨
* 스레드와 프로세스는 유휴 상태의 커넥션 때문에 리소스를 낭비하지 않는다

**다중 멀티스레드 웹 서버**
* 멀티스레딩과 다중화를 결합한 형태
* 여러 개의 스레드는 각각 열려있는 커넥션을 감시하고 각 커넥션에 대해 조금씩 작업을 수행

## 5.6 단계3: 요청 처리
* 웹 서버가 요청을 받으면, 서버는 요청으로부터 메서드, 리소스, 헤더, 본문을 얻어내어 처리

## 5.7 단계 4: 리소스의 매핑과 접근
* 웹 서버는 리소스 서버
* 웹 서버가 콘텐츠를 전달하려면, 요청 메시지의 URI에 대응하는 콘텐츠의 원천을 식별해야 함

### 5.7.1 Docroot
* 가장 단순하게 요청 URI를 웹 서버의 파일 시스템 안에 있는 파일 이름으로 사용하는 방식
* 웹 서버 파일 시스템의 특별한 폴더를 웹 콘텐츠를 위해 예약 해둠. 이를 문서 루트 or docroot로 불림

### 5.7.2 디렉터리 목록
* 웹 서버는 디렉터리를 가리키는 URL에 대한 요청을 받을 수 있음
* 해당 요청에 대해서 아래와 같은 행동을 취할 수 있음
    * 에러 반환
    * 특별한 `색인 파일`을 반환
    * 디렉터리를 탐색해서 HTML 페이지를 반환
* 대부분 요청한 URL에 대응되는 디렉터리 안에서 index.html 혹은 index.htm으로 이름 붙는 파일을 찾음

### 5.7.3 동적 콘텐츠 리소스 매핑
* URI를 동적 리소스에 매핑할 수도 있음

### 5.7.5 접근 제어
* 각각의 리소스에 접근 제어 할당 가능

## 5.8 단계 5: 응답 만들기
* 서버가 리소스를 식별하면, 서버는 요청 메서드로 서술되는 동작을 수행한 뒤 응답 메시지를 반환

### 5.8.1 응답 엔터티
* 본문이 있다면 다음을 포함
    * 응담 본문의 MIME 타입을 서술하는 Content-Type 헤더
    * 응답 본문의 길이를 서술하는 Content-Length 헤더
    * 실제 응답 본문의 내용

### 5.8.2 MIME 타입 결정하기
* 웹 서버는 응답 본문의 MIME 타입을 결정해야 하는 책임이 있음

### 5.8.3 리다이렉션
* 웹 서버는 종종 성공 메시지 대신 리다이렉션을 반환
* 3xx 상태 코드 지칭
* Location 응답 헤더에 콘텐츠의 새로운 혹은 선호하는 위치에 대한 URI 포함

**영구히 리소스가 옮겨진 경우**
* 리소스에 새 URL이 부여되어 새로운 위치로 옮겨졌거나 이름이 바뀐 경우
* 301 Moved Permanently

**임시로 리소스가 옮겨진 경우**
* 리소스가 임시로 옮겨지거나 이름이 변경된 경우
* 임시적이기 때문에 클라이언트가 나중에는 원래 URL로 찾아와야 함
* 303 See Other와 307 Temporary Redirect

**URL 증강**
* 문맥 정보를 포함시키기 위해 재 작성된 URL로 리다이렉트
* 클라이언트는 리다이렉트를 따라가서, 상태정보가 추가된 완전한 URL을 포함한 요청을 다시 보냄
* 트랜잭션 간 상태를 유지하는 유용한 바업ㅂ
* 303 See Other or 307 Temporary Redirect

**부하 균형**
* 과부하된 서버가 요청을 받으면, 부하가 덜 걸린 서버로 리다이렉트
* 303 See other or 307 Temporary Redirect

**친밀한 다른 서버가 있을 때**
* 서버는 클라이언트를 그 클라이언트에 대한 정보를 갖고 있는 다른 서버로 리다이렉트
* 303 See other or 307 Temporary Redirect

**디렉터리 이름 졍규화**
* 클라이언트가 디렉터리 이름에 대한 URI를 요청하는데 끝에 빗금(/)을 빠뜨렸다면, 대부분의 웹 서버는 상대경로가 정상적으로 동작할 수 있도록 클라이언트를 슬래시를 추가한 URI로 리다이렉트 함

# 6장 프락시
* 클라이언트와 서버 사이에 위치하여 그들 사이의 HTTP 메시지를 정리하는 중개인처럼 동작한다.

## 6.1 웹 중개자
* 웹 프락시 서버는 클라이언트의 입장에서 트랜잭션을 수행하는 중개인
* HTTP 프락시는 서버이기도 하고 클라이언트이기도 함

### 6.1.1 개인 프락시와 공유 프락시
* 프락시 서버는 하나의 클라이언트가 독점적으로 사용할 수도 있고, 여러 클라이언트가 공유할 수도 있음

**공용 프락시**
* 대부분의 프락시는 공용임
* 중앙 집중형 프락시를 관리하는 게 더 비용효율이 높고 쉬움

**개인 프락시**
* 어떤 브라우저 보조 제품들은 몇몇 ISP 서비스와 마찬가지로 브라우저의 기능을 확장하거나 성능을 개선하거나 무료 ISP 서비스를 위한 광고를 운영하기 위해 작은 프락시를 사용자의 컴퓨터에서 직접 실행한다

### 6.1.2 프락시 대 게이트웨이
* 프락시는 같은 프로토콜을 사용하는 둘 이상의 애플리케이션을 연결
* 게이트웨이는 서로 다른 프로토콜을 사용하는 둘 이상을 연결

## 6.2 왜 프락시를 사용하는가?
* 실용적이고 유용한 것이라면 무슨 일이든 한다
* 보안을 개선, 성능을 높여줌, 비용 절약, 트래픽 감시 및 수정

**어린이 필터**
* 교육 사이트를 제공하면서 동시에 성인 콘텐츠를 차단하기 위해 필터링 프락시를 사용

**문서 접근 제어자**
* 중앙 프락시 서버에서 접근 제어를 설정

**보안 방화벽**
* 네트워크 보안 엔지니어가 종종 보안 강화를 위해 사용

**웹 캐시**
* 자주 요청되는 문서의 로컬 사본을 관리하고 해당 문서에 대한 요청이 오면 빠르게 제공

**대리 프락시**
* 웹 서버인것 처럼 위장
* 대리 혹은 리버스 프락시로 불리는 이들은 진짜 웹 서버 요청을 받지만 웹 서버와는 달리 요청 받은 콘텐츠의 위치를 찾아내기 위해 다른 서버와 통신

**콘텐츠 라우터**
* 인터넷 트래픽 조건과 콘텐츠의 종류에 따라 요청을 특정 웹 서버로 유도하는 콘텐츠 라우터로 동작할 수 있다.

**트랜스코더**
* 프락시 서버는 콘텐츠를 클라이언트에게 전달하기 전에 본문 포맷을 수정할 수 있음

**익명화 프락시**
* HTTP 메시지에서 신원을 식별할 수 있는 특성들(IP 주소, From 헤더, Referer 헤더, 쿠키, URI 세션 아이디)을 적극적으로 제거함으로써 개인 정보 보호와 익명성 보장에 기여

## 6.3 프락시는 어디에 있는가?
* 어떻게 프락시가 네트워크에 배치되는가
* 어떻게 프락시의 연쇄가 계층을 이루는가
* 어떻게 트래픽이 올바르게 프락시를 찾아가는가

### 6.3.1 프락시 서버 배치
**출구(Egress) 프락시**
* 로컬 네트워크와 인터넷 사이를 오가는 트래픽 제어 목적을 위해 로컬 네트워크 출구에 배치

**접근(입구) 프락시**
* 모든 요청을 종합적으로 처리하기 위해 ISP 접근 지접에 배치

**대리(리버스) 프락시**
* 네트워크 가장 끝, 웹 서버들의 바로 앞에 위치
* 웹 서버로 향하는 모든 요청을 처리

**네트워크 교환 프락시**
* 혼잡 완화 및 트래픽 흐름 감시

### 6.3.2 프락시 계층
* 프락시 계층이라고 불리는 연쇄를 구성할 수 있음

**프락시 계층 콘텐츠 라우딩**
* 프락시 서버는 여러 가지 판단 근거에 의해 메시지를 다양하고 유동적인 프락시 서버와 원 서버들의 집합에게 보낼 수 있다

**부하 균형**
* 자식 프락시가 부하 분산을 위해 부모들의 작업량 수준에 근거해서 부모 프락시를 고름

**지리적 인접성에 근거한 라우팅**
* 원 서버의 지역을 담당하는 부모를 선택할 수도 있음

**프로토콜/타입 라우팅**
* URI에 근거하여 다른 부모나 원 서버로 라우팅 할 수 있음

**유료 서비스 가입자를 위한 라우팅**
* 빠른 서비스를 위해 추가금을 지불했다면, 대형 캐시나 성능 개선을 위한 압축 엔진으로 라우팅 될 수 있음

### 6.3.3 어떻게 프락시가 트래픽을 처리하는가
* 클라이언트 트래픽이 프락시로 가도록 만드는 방법

    1. 클라이언트를 수정
        * 웹 클라이언트들은 수동 혹은 자동 프락시 지원
    2. 네트워크 수정
        * 네트워크 인프라를 가로채서 웹 트래픽을 프락시로 가도록 조정
    3. DNS 이름공간을 수정
        * 웹 서버 앞에 위치하는 리버스 프락시는 웹 서버의 이름과 IP 주소를 직접 사용
    4. 웹 서버를 수정
        * HTTP 리다이렉션 명령을 클라이언트에게 돌려줌으로써 클라이언트의 요청을 프락시로 리다이렉트 하도록 설정
    
## 6.4 클라이언트 프락시 설정
* 많은 브라우저가 프락시를 설정하는 여러 가지 방법을 제공

1. 수동 설정
    * 프락시를 사용하겠다고 명시적으로 설정
2. 브라우저 기본 설정
    * 브라우저를 소비자에게 전달 하기 전에 프락시를 미리 설정
3. 프락시 자동 설정(PAC)
    * 자바스크립트 프락시 자동 설정 파일에 대한 URI를 제공
4. WPAD 프락시 발견
    * 자동설정 파일을 다운받을 수 있는 설정 서버를 자동으로 찾아주는, 웹 프락시 자동발견 프로토콜(WPAD)을 제공

## 6.5 프락시 요청의 미묘한 특징들
* 프락시 요청의 URI는 서버 요청과 어떻게 다른가
* 인터셉트 프락시와 리버스 프락시는 어떻게 서버 호스트 정보를 알아내기 어렵게 만드는가
* URI 수정에 대한 규칙
* 프락시는 브라우저의 URI 자동완성이나 호스트 명 확장 기능에 어떻게 영향을 주는가

### 6.5.1 프락시 URI는 서버 URI와 다르다
* 웹서버로 보낼때는 요청줄은 URI 부분에서 경로만 가짐
* 프락시로 보낼때는 완전한 URI를 가짐

### 6.5.2 가상 호스팅에서 일어나는 같은 문제
* 가상으로 호스팅 되는 웹 서버는 그 요청이 접근하고자 하는 웹 사이트의 호스트 명을 알 필요가 있음
* 가상으로 호스팅 되는 웹 서버는 호스트와 포트에 대한 정보가 담겨져 있는 Host 헤더를 요구함

### 6.5.3 인터셉트 프락시는 부분 URI를 받는다
* 인터셉트 프락시는 네트워크 흐름 자체는 변경되지 않음
* 클라이언트에서 서버로 가는 트래픽을 가로채 캐시된 응답을 돌려주는 일 등을 함

### 6.5.4 프락시는 프락시 요청과 서버 요청을 모두 다룰 수 있다
* 다목적 프락시는 완전한 URI와 부분 URI를 모두 지원
* 완전 URI와 부분 URI를 사용하는 규칙
    * 완전한 URI가 주어졌다면 그대로 사용
    * 부분 URI가 주어졌고 Host 헤더가 있다면, Host 헤더를 이용해 원 서버의 이름과 포트 번호를 알아냄
    * 부분 URI가 주어졌으나 Host 헤더가 없다면, 아래 방법으로 알아냄
        * 대리(리버스) 프락시라면, 프락시에 실제 서버의 주소와 포트 번호가 설정되어 있을 수 있다.
        * 이전에 어떤 인터셉트 프락시가 가로챘던 트래픽을 받았고, 해당 프락시가 원 IP 주소와 포트번호를 사용할 수 있도록 해두었다면, 그 IP 주소와 포트번호를 사용할 수 있다.
        * 모두 실패하면 에러

### 6.5.5 전송 중 URI 변경
* 사소한 URI 변경이라도 다운스트림 서버와 상호운용성 문제를 일으킬 수 있다

### 6.5.6 URI 클라이언트 자동확장과 호스트 명 분석
* 브라우저는 프락시의 존재 여부에 따라 요청 URI를 다르게 분석
* 사용자가 타이핑한 URI를 가지고 그에 대응하는 IP 주소를 찾으면 연결에 성공할 때까지 시도
* 호스트가 발견되지 않으면, 호스트 명의 짧은 약어를 타이핑한 것으로 보고 자동화된 호스트 명의 확장을 제공

## 6.6. 메시지 추적
* 프락시가 흔해지면서, 프락시를 넘나드는 메시지의 흐름을 추적하고 문제점을 찾아내는 것도 필요한 일이 됨

### 6.6.1 Via 헤더
* 메시지가 지나는 각 중간 노드의 정보를 나열
* 메시지의 전달을 추적하고, 메시지 루프를 진단하고, 요청을 보내고 그에 대한 응답을 돌려주는 과정에 관여하는 모든 메시지 발송자들의 프로토콜을 다루는 능력을 알아보기 위해 사용

#### Via 문법
* 쉼표로 구분된 경유지의 목록
    * 경유지 : 개별 프락시 서버, 게이트웨이 홉
* Via: 1.1 proxy-62.irense-isp.net, 1.0 cache.jose.hardware.com
* 형식 구문
```
Via                 = "Via" ":" ( waypoint ) [", " ( waypoint)...]
waypoint            = (received-protocol received-by [ comment ] )
received-protocal   = [ protocol-name "/" ] protocol-version
recevied-by         = (host [ ":" prot ] ) | pseudonym
```

**프로토콜 이름**
* 중개자가 받은 프로토콜

**프로토콜 버전**
* 수신한 메시지의 버전

**노드 이름**
* 중개자의 호스트와 포트번호

**노드 코멘트**
* 중개자 노드를 서술하는 선택적인 코멘트

**Via 요청과 응답 경로**
* 요청 메시지와 응답 메시지 모두 프락시를 지나므로 둘 모두 Via 헤더를 가짐

**Via와 게이트웨이**
* 몇몇 프락시는 서버에게 비 HTTP 프로토콜을 사용할 수 있는 게이트웨이 기능을 제공

**Server 헤더와 Via 헤더**
* Server 응답 헤더 필드는 원 서버에 의해 사용되는 소프트웨어를 알려줌

**Via가 개인정보 보호와 보안에 미치는 영향**
* 프락시는 방화벽 뒤에 숨어있는 호스트의 이름과 포트를 전달해서는 안됨

### 6.6.2 TRACE 메서드
* 프락시 서버는 메시지가 전달될 때 메시지를 수정할 수 있음
* 요청 메시지를 프락시의 연쇄를 따라가면서 어떤 프락시를 지나가고 어떻게 각 프락시가 요청 메시지를 수정하는지 관찰/추적할 수 있도록 해줌

**Max-Forwards**
* TRACE 메시지는 중간에 프락시들이 몇 개나 있든 신경 쓰지 않고 목적지 서버로의 모든 경로를 여행
* 홉 개수를 제한하기 위해 사용

## 6.7 프락시 인증
* 프락시는 접근 제어 장치로서 제공될 수 있음

## 6.8 프락시 상호운용성
* 프락시 서버는 서로 다른 프로토콜을 구현했을 수도 있고 골치 아프게 이상한 동작을 할 수도 있는 클라이언트와 서버 사이를 중개해야 한다.

### 6.8.1 지원하지 않는 헤더와 메서드 다루기
* 프록시는 이해할 수 없는 헤더 필드는 반드시 그대로 전달
* 지원하지 않는 메서드라도 다음 홉으로 전달하려 시도해야 됨
* HTTP/1.1은 메서드 확장을 허용

### 6.8.2 OPTIONS: 어떤 기능을 지원하는지 알아보기
* HTTP OPTIONS 메서드는 서버나 웹 서버의 특정 리소스가 어떤 기능을 지원하는지 알 수 있게 해줌

### 6.8.3 Allow 헤더
* 요청 URI에 의해 식별되는 자원에 대해 지원되는 메서드들이나 서버가 지원하는 모든 메서드를 열거
* Allow: GET, HEAD, PUT

# 7장. 캐시
* 웹 캐시는 자주 쓰이는 문서의 사본을 자동으로 보관하는 HTTP 장치
* 캐시의 장점
    * 불필요한 데이터 전송을 줄여줌
    * 네트워크 병목을 줄여줌
    * 원 서버에 대한 요청을 줄여줌
    * 거리로 인한 지연을 줄여줌

## 7.1 불필요한 데이터 전송
* 여러 클라이언트들이 하나의 자원에 대해 요청하면 각각 처리하게 됨.
* 똑같은 바이트들이 네트워크를 통해 반복해서 이동하기 때문에 불필요함
* 캐시는 첫 번째 서버 응답을 캐시에 보관. 캐시된 사본들이 이후 요청에 대한 응답으로 사용

## 7.2 대역폭 병목
* 클라이언트들이 서버에 접근할 때의 속도는, 그 경로에 있는 가장 느린 네트워크의 속도와 같음.
* 클라이언트가 빠른 LAN에 있는 캐시로부터 사본을 가져오면 성능을 대폭 개선할 수 있음

## 7.3 갑작스런 요청 쇄도(Flash Crowds)
* 갑작스런 사건으로 인해 많은 사람들이 거의 동시에 웹 문서에 접근할 때 문제가 발생
* 이럴 때 캐싱을 사용하면 대처 가능

## 7.4 거리로 인한 지연
* 거리가 길 수록 네트워크 지연이 생김
* 노드 근처에 캐시를 설치해서 문서가 전송되는 거리를 줄이면 성능을 개선 할 수 있음

## 7.5 적중과 부적중
* 캐시 적중(cache hit) : 캐시에 요청이 도착했을 때, 그에 대응하는 사본이 있다면 해당 요청으로 처리
* 캐시 부적중(cache miss) : 캐시에 요청이 도착했을 때, 그에 대응하는 사본이 없어 원 서버로 전달

## 7.5.1 재검사(Revalidation)
* 원 서버 콘텐츠는 변경될 수 있음.
* 캐시는 사본이 최신인지 서버를 통해 확인해야 함. 이러한 '신선도 검사'를 HTTP 재검사라 부름
* 캐시가 원 서버에 재검사 요청을 보내고, 콘텐츠가 변경되지 않았다면 304 Not Modified 응답을 보냄. 이를 재검사 적중, 느린 적중이라 부름
* HTTP는 캐시된 객체를 재확인하기 위한 몇가지 도구를 제공. If-Modified-Since 헤더가 많이 쓰임

**재검사 적중**
* 만약 서버 객체가 변경되지 않았다면, 서버는 클라이언트에게 HTTP 304 Not Modified 응답을 보냄

**재검사 부적중**
* 서버 객체가 캐시된 사본과 다르다면, 서버는 콘텐츠 전체와 함께 HTTP 200 OK 응답을 보냄

**객체 삭제**
* 서버 객체가 삭제되었다면, 서버는 404 Not Found 응답을 보내고, 캐시는 사본을 삭제함

### 7.5.2 적중률
* 캐시가 요청을 처리하는 비율을 캐시 적중률, 문서 적중률이라고도 부름
* 0% = 캐시 부적중, 100% 캐시 적중

### 7.5.3 바이트 적중률
* 문서들의 크기가 모두 같지 않기 때문에, 문서 적중률이 모든 것을 말해주지는 않음
* 큰 객체는 덜 접근되더라도 크기 때문에 전체 트래픽에는 더 크게 기여함. 이런 이유로 바이트 단위 적중률 측정값을 선호하는 사람들이 있음
* 바이트 단위 적중률은 캐시를 통해 제공된 모든 바이트의 비율을 표현

### 7.5.4 적중과 부적중의 구별
* HTTP는 클라이언트에게 응답이 캐시 적중이였는지 부적중이였는지 말해줄 수 있는 방법이 없음
* Via 헤더에 추가 정보를 붙이는 프락시 캐시
* Date 헤더를 현재 시간과 비교해 캐시인지 아닌지 확인
* 응답이 얼마나 오래되었는지 말해주는 Age 헤더를 이용

### 7.6 캐시 토폴로지
* 캐시는 한 명의 사용자에게만 할당될 수도 있고, 수천 명의 사용자들 간에 공유될 수도 있음

### 7.6.1 개인 전용 캐시
* 웹브라우저는 개인 전용 캐시를 내장
* 자주 쓰이는 문서를 개인용 컴퓨터의 디스크와 메모리에 캐시

### 7.6.2 공용 프락시 캐시
* 공용 캐시는 캐시 프락시 서버 or 프락시 캐시라 불리는 공유된 프락시 서버
* 프락시 캐시는 로컬 캐시에서 문서를 제공하거나, 사용자의 입장에서 서버에 접근

### 7.6.3 프락시 캐시 계층들
* 작은 캐시에서 캐시 부적중이 발생했을 때 더 큰 부모 캐시가 그 트래픽을 처리하도록 하는 계층을 만드는 방식이 합리적인 경우가 많음

### 7.6.4 캐시망, 콘텐츠 라우팅, 피어링
* 복잡한 캐시망을 만드는 경우도 있음
* 캐시망의 프락시 캐시는 서로 대화하며, 어떤 부모 캐시와 대화할 것인지, 요청이 캐시를 완전히 우회해서 원 서버로 바로 가도록 할 것인지에 대한 캐시 커뮤니케이션 결정을 동적으로 내림

## 7.7 캐시 처리 단계
* HTTP GET 메시지 하나를 처리하는 기본적인 캐시 처리 절차는 일곱 단계로 이루어져 있음
    1. 요청 받기 - 네트워크로부터 도착한 요청 메시지를 읽음
    2. 파싱 - 메시지를 파싱하여 URL과 헤더들을 추출
    3. 검색 - 캐시는 로컬 복사본이 있는지 검사하고, 사본이 없다면 사본을 받아옴
    4. 신선도 검사 - 캐시된 사본이 신선한지 검사. 신선하지 않다면 변경사항이 있는지 서버에게 물어봄
    5. 응답 생성 - 새로운 헤더와 캐시된 본문으로 응답 메시지를 만듬
    6. 발송 - 네트워크를 통해 응답을 클라이언트로 전송
    7. 로깅 - 로그파일에 트랜잭션에 대해 서술한 로그 하나를 남김

### 7.7.1 단계 1: 요청 받기
* 네트워크 커넥션에서 활동을 감지하고, 들어오는 데이터를 읽어들임

### 7.7.2 단계 2: 파싱
* 요청 메시지를 여러 부분으로 파싱하여, 조작하기 쉬운 자료 구조에 담음

### 7.7.3 단계 3: 검색
* URL을 알아내고 그에 해당하는 로컬 사본이 있는지 검사
* 캐시된 객체는 얼마나 오랫동안 머물렀는지, 얼마나 자주 사용되었는지에 대한 메타데이터 제공

### 단계 4: 신선도 검사
* HTTP는 캐시가 일정 기간 동안 서버 문서의 사본을 보유할 수 있도록 해줌
* 이 기간 동안, 문서는 '신선'한 것으로 간주. 
* 캐시된 사본을 신선도 한계를 넘을 정도로 오래 갖고 있었다면 '신선하지 않은'것으로 간주. 문서를 제공하기 전 어떤 변경이 있었는지 검사하기 위해 서버에 재검사를 요청

### 단계 5: 응답 생성
* 캐시는 캐시된 서버 응답 헤더를 톹대로 응답 헤더 생성
* 캐시는 클라이언트에 맞게 이 헤더를 조정

### 단계 6: 전송
* 응답 헤더가 준비되면, 응답을 클라이언트에게 전달

### 단계 7: 로깅
* 캐시는 로그 파일과 캐시 사용에 대한 통계를 유지

## 7.8 사본을 신선하게 유지하기
* 캐시된 사본이 항상 서버의 문서와 일치하는 것은 아님
* 캐시된 데이터는 서버의 데이터와 일치하도록 관리되어야 함

### 7.8.1 문서 만료
* HTTP는 Cache-Control과 Expires라는 특별한 헤더를 이용해서 원 서버가 각 문서에 유효기간을 붙일 수 있게 해줌
* 이 헤더들은 콘텐츠가 얼마나 오랫동안 신선한 상태로 보일 수 있는지 좌우함

### 7.8.2 유효기간과 나이
* 서버는 응답 본문과 함께, HTTP/1.0+ Expires나 HTTP/1.1 Cache-Control: max-age 응답 헤더를 이용해서 유효기간을 명시
* 절대 시간은 컴퓨터의 시계가 올바르게 맞추어져 있는 것을 요구
* `Cache-Control: max-age` : 문서의 최대 나이를 정의. 문서가 생성된 이후부터 경과된 초단위의 시간
* `Expires`: 절대 유효기간을 명시

### 7.8.3 서버 재검사
* 문서가 만료되었다고 원 서버에 존재하는 것과 실제로 다르다는 것을 의미하지는 않음
* 다만 변경되었는지 검사를 해야한다는 것을 의미. 이를 `서버 재검사`라 부름

### 7.8.4 조건부 메서드와 재검사
* HTTP의 조건부 메서드는 재검사를 효율적으로 만들어줌
* HTTP는 다섯 가지 조건부 요청 헤더를 정의. 그 중 둘은 캐시 재검사를 할 때 유용한 `If-Modified-Since`와 `If-None-Match`이다.
* `If-Modified-Since: <date>`: 문서가 주어진 날짜 이후로 수정되었다면 요청 메서드를 처리. 캐시된 버전으로부터 콘텐츠가 변경된 경우에만 콘텐츠를 가져오기 위해 `Last-Modified` 서버 응답 헤더와 함께 사용
* `If-None-Match: <tags>`: 마지막 변경된 날짜를 맞춰보는 대신, 문서에 대한 일련번호와 같이 동작하는 특별한 태그를 제공할 수 있음. `If-None-Match` 헤더는 캐시된 태그가 서버에 있는 문서의 태그와 다를 때만 요청을 처리

### 7.8.5 If-Modified-Since: 날짜 재검사
* 리소스가 특정 날짜 이후로 변경된 경우에만 요청한 본문을 보내달라고 함
* 만약 문서가 주어진 날짜 이후에 변경되었다면, IMS 조건은 참이되고 GET 요청은 평범하게 처리됨.
* 만약 문서가 주어진 날짜 이후에 변경되지 않았다면 조건은 거짓이고, 서버는 304 Not Modified 응답 메시지를 클라이언트에게 돌려줌

### 7.8.6 If-None-Match: 엔터티 태그 재검사
* 아래와 같이 최근 변경 일시 재검사가 어려운 상황이 있음
    * 어떤 문서는 일정 시간 간격으로 다시 쓰여짐. 실제로는 같은 데이터를 포함. 내용에 변화가 없더라도 변경시각은 바뀔 수 있음
    * 어떤 문서들의 변경은 전 세계의 캐시들이 그 데이터를 다시 읽어들이기엔 사소한 것일 수 있음(철자나 주석의 변경)
    * 어떤 서버들은 갖고 있는 페이지에 대한 최근 변경 일시를 정확하게 판별 할 수 없음
    * 1초보다 작은 간격으로 갱신되는 문서들을 제공하는 서버들에게는 변경일에 대한 1초의 정밀도는 충분하지 않을 수 있음
* 퍼블리셔가 문서를 변경했을 때, 그는 문서의 엔터티 태그를 새로운 버전으로 표현할 수 있음. 엔터티 태그가 변경되었다면, 캐시는 새 문서의 사본을 얻기 위해 `If-None-Match` 조건부 헤더를 사용
* 캐시는 엔터티 태그 `v2.6`인 문서를 가지고 서버에 해당 태그가 아닌 경우에만 새 객체를 달라고 요청하는 방법으로 재검사

### 7.8.7 약한 검사기와 강한 검사기
* 캐시된 버전이 서버가 갖고 있는 것에 대해 최신인지 확인하기 위해 엔터티 태그를 사용. 이 경우, 엔터티 태그와 최근 변경일시는 둘 다 캐시 검사기
* 서버는 모든 캐시된 사본을 무효화시키지 않고 문서를 살짝 고칠 수 있도록 허용하고 싶은 경우가 있음. HTTP/1.1은, 콘텐츠가 조금 변경되었더라도, "그 정도면 같은 것"이라고 서버가 주장할 수 있도록 해주는 `약한 검사기`를 지원
* 강한 검사기는 콘텐츠가 바뀔 때마다 바뀜
* `W/` 접두사로 약한 검사기를 구분
    ```http
    ETag: W/"v2.6"
    If-None-Match: W/"v2.6"
    ```

### 7.8.8 언제 엔터티 태그를 사용하고 언제 Last-Modified 일시를 사용하는가
* 클라이언트는 서버가 엔터티 태그를 반환했다면, 반드시 엔터티 태그 검사기를 사용.
* 서버가 Last-Modified 값만을 반환했다면, 클라이언트는 IMS 검사를 사용

## 7.9 캐시 제어
* HTTP는 캐시된 문서의 만료 기간을 설정할 수 있는 방법을 정의
    * Cache-Control: no-store 헤더를 응답에 첨부
    * Cache-Control: no-cache 헤더를 응답에 첨부
    * Cache-Control: must-revalidate 헤더를 응답에 첨부
    * Cache-Control: max-age 헤더를 응답에 첨부
    * Expires 날짜 헤더를 응답에 첨부
    * 캐시가 스스로 체험적인(휴리스틱) 방버으로 결정

### 7.9.1 no-cache와 no-store 응답 헤더
* 캐시가 검증되지 않은 캐시된 객체로 응답하는 것을 막음
* `no-store` : 캐시가 그 응답의 사본을 만드는 것을 금지
* `no-cache` : 로컬 캐시 저장소에 저장될 수 있음. 서버와 재검사를 하지 않고서는 캐시에서 클라이언트로 제공될 수 없음

### 7.9.2 Max-Age 응답 헤더
* 신선하다고 간주되었던 문서가 서버로 온 이후로 흐른 시간을 초로 나타낸 것

### 7.9.3 Expires 응답 헤더
* 실제 만료 날짜를 명시

### 7.9.4 Must-Revalidate 응답 헤더
* 캐시가 신선하지 않은(만료된) 객체를 제공하도록 설정될 수 있다
* 캐시가 만료 정보를 엄격하게 따르길 원한다면 `Cache-Control: must-revalidate` 헤더를 붙임

### 7.9.5 휴리스틱 만료
* 응답이 캐시 관련 헤더가 없으면, 캐시가 경험적인 방법(heuristic)으로 만료 시점을 계산

### 7.9.6 클라이언트 신선도 제약
* 웹브라우저는 신선하지 않은 콘텐츠를 강제로 갱신시켜주는 리프레시 버튼을 갖고 있음
* 이 버튼은 Cache-Control 요청 헤더가 추가된 GET 요청을 발생시켜, 강제로 재검사 하거나 서버로부터 콘텐츠를 무조건 가져온다

### 7.9.7 주의할 점
* 퍼블리셔가 유효기간을 까마득한 미래로 설정해버린다면, 문서의 변경이 캐시에 반영되지 않음

## 7.12 캐시와 광고
* 캐시는 사용자를 도와 더 좋은 경험을 제공하고, 또한 네트워크 사업자들이 트래픽을 줄일 수 있도록 도와줌

### 7.12.1 광고 회사의 딜레마
* 캐시를 쓰면 원 서버의 실제 접근 횟수를 알수 없게 된다. 그래서 조회수를 기준으로 광고비를 측정하면 문제가 됨

### 7.12.2 퍼블리셔의 응답
* 콘텐츠 제공다는 캐시가 트래픽을 흡수하도록 내버려 두고, 캐시는 서버에 얼마나 접근 되었는지 알려야 됨
* 재검사를 강제하도록 하면 모든 요청마다 재검사를 하니까 알 수 있지만, 느림
### 7.12.3 로그 마이그레이션
* 서버로 가는 요청을 막고 로그 데이터로 측정

### 7.12.4 적중 측정과 사용량 제한
* 특정 URL에 대한 캐시 적중 횟수를 정기적으로 서버에게 돌려주는 Meter라고 하는 새 헤더를 사용
* 서버는 캐시로부터 문서의 적중한 횟수를 받을 수 있음

# 8장. 통합점: 게이트웨이, 터널, 릴레이
* HTTP는 웹에 있는 모든 리소스에 대한 프로토콜로 사용됐으며, 애플리케이션 간에 서로 다른 프로토콜을 상호 운용하는 용도로 사용하기도 함

* 게이트웨이: 서로 다른 프로토콜과 애플리케이션 간의 HTTP 인터페이스
* 애플리케이션 인터페이스: 서로 다른 형식의 웹 애플리케이션이 통신하는 데 사용
* 터널: HTTP 커넥션을 통해서 HTTP가 아닌 트래픽을 전송하는 데 사용
* 릴레이: 일종의 단순한 HTTP 프락시로, 한 번에 한 개의 홉에 데이터를 전달하는데 사용

## 8.1장 게이트웨이
* 리소스와 애플리케이션을 연결하는 역할을 함

### 8.1.1 클라이언트 측 게이트웨이와 서버 측 게이트웨이
* 웹 게이트웨이는 한쪽에서는 HTTP로 통신하고 다른 한쪽에서는 HTTP가 아닌 다른 프로토콜로 통신
* 서버 측 게이트웨이는 클라이언트와 HTTP로 통신하고, 서버와는 외래 프로토콜로 통신
* 클라이언트 측 게이트웨이는 클라이언트와 외래 프로토콜로 통신하고, 서버와는 HTTP로 통신

## 8.2 프로토콜 게이트웨이
* 게이트웨이에도 HTTP 트래픽을 바로 보낼 수 있음
* 트래픽이 자연스럽게 거쳐가게 하거나, 대리 서버로 설정 할 수 있음

### 8.2.1 HTTP/*: 서버 측 웹 게이트웨이
* 클라이언트로부터 HTTP 요청이 원 서버 영역으로 들어오는 시점에 클라이언트 측의 HTTP 요청을 외래 프로토콜로 전환

### 8.2.2 HTTP/HTTPS: 서버 측 보안 게이트웨이
* 기업 내부의 모든 웹 요청을 암호화함으로써 개인 정보 보호와 보안을 제공하는데 게이트웨이를 사용할 수 있다.

### 8.2.3 HTTPS/HTTP: 클라이언트 측 보안 가속 게이트웨이
* 웹 서버의 앞단에 위치해, 보이지 않는 인터셉트 게이트웨이나 리버스 프락시 역할을 함
* HTTPS 트래픽을 받아서 복호화하고, 웹 서버로 보낼 일반 HTTP 요청을 만듬

## 8.3 리소스 게이트웨이
* 게이트웨이의 일반적인 형태인 애플리케이션 서버는 목적지와 게이트웨이를 한 개의 서버로 결합
* 유명했던 최초의 API는 공용 게이트웨이 인터페이스(CGI)였다

## 8.5 터널
* HTTP 프로토콜을 지원하지 않는 애플리케이션에 HTTP 애플리케이션을 사용해 접근하는 방법을 제공

### 8.5.1 CONNECT로 HTTP 터널 커넥션 맺기
* 웹 터널은 HTTP의 CONNECT 메서드를 사용해 커넥션을 맺음

## 8.6 릴레이
* HTTP 명세를 완전히 준수하지는 않는 간단한 HTTP 프락시

# 9장 웹  로봇
* 웹 사이트를 떠돌아 다니며, 콘텐츠를 가져오고, 하이퍼링크를 따라가고, 발견한 데이터를 처리함

## 9.1 클로러와 크롤링
* 웹 크롤러는 [웹 페이지 -> 그 다음 페이지의 모든 페이지 -> ...] 이런 순서를 재귀적으로 반복하는 방식으로 웹을 순회하는 로봇

### 9.1.1 어디에서 시작하는가: '루트 집합'
* 크롤러를 동작히기 위해선 출발지점을 주어야 함.
* 크롤러가 방문을 시작하는 URL들의 초기 집합을 루트 집합(root set)이라 부름

### 9.1.2 링크 추출과 상대 링크 정상화
* 크롤러는 검색한 각 페이지 안에 들어있는 URL 링크들을 파싱해서 크롤링할 페이지들의 목록에 추가
* 추출된 링크는 상대 링크에서 절대 링크로 변환되어야 함

### 9.1.3 순환 피하기
* 순환을 피하기 위해 방문한 곳을 알아야 됨

### 9.1.4 루프와 중복
* 크롤러가 순환에 빠지면 아무것도 못함
* 같은 페이지를 반복해서 가져오면 서버에 부담이 됨
* 중복된 페이지로 인해 쓸모없는 중복된 컨텐츠가 넘쳐나게 됨

## 9.2 로봇의 HTTP
* HTTP 명세 규칙을 지켜야 됨

### 9.2.1 요청 헤더 식별하기
* 로봇들은 신원 식별 헤더를 구현하고 전송함
* `User-Agent` : 서버에게 요청을 만든 로봇의 이름을 말해줌
* `From` : 로봇의 사용자/관리자의 이메일 주소를 제공
* `Accpet` : 서버에게 어떤 미디어 타입을 보내도 되는지 말해줌
* `Referer` : 현재의 요청 URL을 포함한 문서의 URL을 제공

### 9.2.2 가상 호스팅
* 로봇 구현자들은 Host 헤더를 지원할 필요가 있음
* 요청에 Host 헤더를 포함하지 않으면 로봇이 어떤 URL에 대해 잘못된 컨텐츠를 찾게 만듬

### 9.2.3 조건부 요청
* 로봇이 검색하는 콘텐츠의 양을 최소화하는 것은 의미 있음
* 로봇 중의 몇몇은 시간이나 엔터티 태그를 비교함으로써 받아간 마지막 버전 이후에 업데이트 된 것이 있는지 알아보는 조건부 HTTP 요청을 구현

### 9.3 부적절하게 동작하는 로봇들
* 제멋대로인 로봇들이 아수라장을 만들 여러 가능성이 있음
* 폭주하는 로봇
    * 로봇이 논리적인 에러를 갖고 있거나 순환에 빠졌다면 웹 서버에 극심한 부하를 안겨줌
* 오래된 URL
    * 존재하지 않는 URL에 대한 요청으로, 문서에 대한 접근 요청으로 에러가 채워짐
* 길고 잘못된 URL
* 호기심이 지나친 로봇
    * 너무 적극적으로 알려고 하면, 사생활 침해라고 여길 수도 있음
* 동적 게이트웨이 접근
    * 게이트웨이 애플리케이션의 URL로 요청하면, 특수 목적을 위한 데이터를 받아 처리 비용이 많이 들 수 있음

## 9.4 로봇 차단하기
* 로봇이 웹의 특정 부분에만 접근 하도록 하기 위해 `robots.txt`라는 파일을 서버의 문서 루트에 두고 로봇에게 제공

## 9.6 검색엔진
* 인터넷 검색엔진은 웹 로봇을 가장 광범위하게 사용

### 9.6.2 현대적인 검색엔진의 아키텍처
* 전 세계의 웹페이지들에 대해 '풀 텍스트 색인(full-text indexes)'라고 하는 복잡한 로컬 데이터베이스를 생성
* 검색엔진 크롤러들은 웹페이지들을 수집하여, 풀 텍스트 색인에 추가

### 9.6.3 풀 텍스트 색인
* 단어 하나를 입력받아 그 단어를 포함하고 있는 문서를 즉각 알려줄 수 있는 데이터베이스

# 10장 HTTP/2.0
* HTTP의 성능 문제를 개선하기 위해 나옴

## 10.1 HTTP/2.0의 등장 배경
* HTTP/1.1은 구현의 단순성과 접근성에 주안점을 주고 최적화 됨. 그래서 성능은 어느정도 희생 시킴
* 회전 지연을 줄이기 위해 구글의 SPDY 프로토콜을 기반으로 HTTP/2.0을 설계

## 10.2 개요
* HTTP/2.0 요청과 응답은 길이가 정의된 한 개 이상의 프레임에 담김. 이때 HTTP 헤더는 압축되어 담김
* 프레임들에 담긴 요청과 응답은 스트림을 통해 보내짐. 하나의 커넥션 위에 여러 개의 스트림이 동시에 만들어질 수 있음
* 스트림에 대한 흐름 제어와 우선순위 부여 기능도 제공
* 서버 푸시 기능을 이용해 클라이언트에게 필요하다 생각되면 능동적으로 보내줄 수 있음
* HTTP/2.0은 요청과 응답 메시지의 의미를 HTTP/1.1과 같도록 유지

## 10.3 HTTP/1.1과의 차이점

### 10.3.1 프레임
* HTTP/2.0에서 모든 메시지는 프레임에 담겨 전송

### 10.3.2 스트림과 멀티플렉싱
* 스트림은 HTTP/2.0 커넥션을 통해 클라이언트와 서버 사이에 교환되는 프레임들의 독립된 양방향 시퀀스다
* 한 쌍의 HTTP 요청과 응답은 하나의 스트림을 통해 이루어 짐
* 하나의 커넥션에 여러 개의 스트림이 동시에 열릴 수 있음

### 10.3.3 헤더 압축
* 요즘에는 요청이 많아져 헤더의 크기가 회전 지연과 대역폭에 실질적인 영향을 끼치게 되었음

### 10.3.4 서버 푸시
* 서버가 하나의 요청에 대해 응답으로 여러 개의 리소스를 보낼 수 있도록 해줌

# 3부 식별, 인가, 보안
* 식별 추적, 보안 집행, 콘텐츠에 대한 접근제어에 대한 일련의 기법 및 기술들을 제시

# 11장 클라이언트 식별과 쿠키
* 서버가 통신하는 대상을 식별하는 데 사용하는 기술을 설명

## 11.1 개별 접촉
* HTTP는 익명으로 사용하며 상태가 없고 요청과 응답으로 통신하는 프로토콜
* 현대의 웹 사이트들은 개인화된 서비스를 제공하고 싶어 함. 네트워크로 연결된 사용자들에 대해 더 많은 것을 알고 싶어 함

**개별 인사**
* 개인에게 맞춰져 있는 것처럼 느끼게 하려고 사용자에게 특화된 환영 메시지나 페이지 내용을 만듬

**사용자 맞춤 추천**
* 고객의 흥미가 무엇인지 학습해서 고객이 좋아할 것이라고 예상되는 제품들을 추천

**저장된 사용자 정보**
* 사용자가 매번 정보를 입력하지 않아도 되도록 DB에 정보를 저장

**세션 추적**
* 사용자가 사이트와 상호작용할 수 있게 사용자 상태를 남김
* 상태를 유지하려면, 각 사용자에게서 오는 HTTP 트랜잭션을 식별할 방법이 필요

## 11.2 HTTP 헤더
* `From`: 요청, 사용자의 이메일 주소
* `User-Agent`: 요청, 사용자의 브라우저
* `Referer`: 요청, 현재 링크를 타고 온 근원 페이지
* `Authorization`: 사용자 이름과 비밀번호
* `Client-ip`: 클라이언의 IP 주소
* `X-Forwarded-For`: 클라이언트의 IP 주소
* `Cookie`: 서버가 생성한 ID 라벨

## 11.3 클라이언트 IP 주소
* 초기에는 사용자 식별에 클라이언트 IP 주소를 사용하려 했음
* 단점
    * IP 주소는 특정 PC를 가리킴, 특정 PC를 여러명이 쓴다면 식별 불가능
    * ISP는 사용자가 로그인하면 동적으로 IP 주소를 할당
    * NAT 때문에 실제 IP 주소를 알 수 없음
    * 클라이언트의 IP 대신 프락시 서버의 IP를 보게 됨

## 11.4 사용자 로그인
* 사용자에게 이름과 비밀번호로 로그인 할 것을 요구해서 사용자를 명시적으로 식별
* HTTP는 `WWW-Authenticate`와 `Authorization` 헤더를 사용하는 자체적인 체계를 가지고 있음

## 11.5 뚱뚱한 URL
* 사용자의 URL마다 버전을 기술하여 사용자를 식별하고 추척하였음. 사용자의 상태 정보를 포함하고 있는 URL을 뚱뚱한 URL이라고 함
*  웹 서버와 통신하는 독립적인 HTTP 트랜잭션을 하나의 '세션' 혹은 '방문'으로 묶는 용도로 뚱뚱한 URL을 사용
* 단점
    * 못생긴 URL
    * 공유하지 못하는 URL : URL에 특정 사용자와 세션에 대한 상태 정보가 포함됨. 해당 URL을 공유할 경우, 누적된 개인 정보를 본의 아니게 공유하게 됨
    * 캐시를 사용할 수 없음 : URL이 자꾸 변경되기 때문에 기존 캐시에 접근할 수 없음
    * 서버 부하 가중 : 뚱뚱한 URL에 해당하는 HTP을 다시 그려야 됨
    * 이탈 : 사용자가 이탈하게 되면 진척 사항들이 다 초기화 됨
    * 세션 간 지속성의 부재 : 로그아웃 하면 모든 정보를 잃게 됨
    
## 11.6 쿠키
* 사용자를 식별하고 세션을 유지하는 방식 중에서 현재까지 가장 널리 사용하는 방식

### 11.6.1 쿠키의 타입
* 쿠키는 크게 `세션 쿠키(session cookie)`와 `지속 쿠키(persistent cookie)`로 나뉨
* `세션 쿠키`: 사용자가 사이트를 탐색할 때 관련한 설정과 선호 사항들을 저장하는 임시 쿠키
* `지속 쿠키`: 삭제되지 않고 더 길게 유지. 디스크에 저장되어 브라우저를 닫거나 컴퓨터를 재시작하더라도 남아 있음

### 11.6.2 쿠키는 어떻게 동작하는가
* 사용자를 식별하기 위한 유일한 값을 쿠키에 할당
* 사용자가 요청시 Set-Cookie 같은 HTTP 응답 헤더에 기술되어 전달됨

### 11.6.3 쿠키 상자: 클라이언트 측 상태
* 쿠키의 기본적인 발상은 브라우저가 서버 관련 정보를 저장하고, 사용자가 해당 서버에 접근할 때마다 그 정보를 함께 전송
* 브라우저는 쿠키 정보를 저장할 책임이 있는데, 이를 `클라이언트 측 상태`라고 함. 명세의 공식적인 이름은 `HTTP 상태 관리 체계(HTTP State Management Mechanism)`

### 11.6.4 사이트마다 각기 다른 쿠키들
* 브라우저는 많은 쿠키를 가지고 있을 수 있지만, 쿠키 전부를 모든 사이트에 보내지는 않음
    * 쿠키를 모두 전달하면 성능이 크게 저하된다.
    * 쿠키들 대부분은 서버에 특화된 이름/값 쌍을 포함하고 있기 때문에, 대부분 사이트에서는 인식하지 않는 무의미한 값이다.
    * 신뢰하지 못한 사이트에서 쿠키를 가져가 잠재적인 개인정보 문제를 일으킬 수 있음

**쿠키 Domain 속성**
* 서버는 쿠키를 생성할 때 Set-Cookie 응답 헤더에 Domain 속성을 기술해서 어떤 사이트가 그 쿠키를 읽을 수 있는지 제어할 수 있음

**쿠키 Path 속성**
* 웹 사이트 일부에만 쿠키를 적용 할 수도 있음.
* Path 속성을 기술해서 해당 경로에 속하는 페이지에만 쿠키를 전달

### 11.6.5 쿠키 구성요소
* 현재 사용되는 쿠키 명세에는 Version 0 쿠키와 Version 1쿠키가 있다.
* Version 0, 1 쿠키 명세 모두 HTTP/1.1 명세 일부로 기술되어 있지는 않음

### 11.6.6 Version 0 쿠키
* Version 0 쿠키는 Set-Cookie 응답 헤더와 Cookie 요청 헤더와 쿠키를 조작하는 데 필요한 필드들을 정의
```
Set-Cookie: name=value [; expires=date] [; path=path] [; domain=domain] [; secure]
Cookie: name1=value1 [; name2=value2]
```

**Version 0 Set-Cookie 헤더**
* 이름=값 - 필수 속성
    * 이름과 값 모두 큰따옴표로 감싸지 않은 세미콜론, 쉼표, 기호, 등호, 공백을 포함하지 않는 문자열
    * 웹 서버에서 다시 방문하면 읽어올 그 어떤 이름=값 조합이든 만들 수 있다
* Expires - 선택 속성
    * 쿠키의 생명주기를 가리키는 날짜 문자열을 기술
* Doamin - 선택 속성
     * 속성에 기술된 도메인을 사용하는 서버 호스트 명으로만 쿠키를 전송
     * 명시되어 있지 않으면 Set-Cookie 응답을 생성한 호스트 명을 기본값으로 사용
* Path - 선택 속성
    * 서버에 있는 특정 문서에만 쿠키를 할당할 수 있다
* Secure - 선택 속성
    * 해당 속성이 포함되어 있으면, 쿠키는 HTTP가 SSL 보안 연결을 사용할 때만 쿠키를 전송

**Version 0 Cookie 헤더**
* 모든 쿠키는 Cookie 헤더에 한데 이어 붙여 보냄
```
Cookie: session-id=00212-2314-1231; secure; expire=2022-12-20 12:23:21
```

### 11.6.7 Version 1 쿠키(RFC 2965)
* Versino 1 표준은 Set-Cookie2와 Cookie2 헤더를 소개하고 있음
* 추가된 사항
    * 쿠키마다 그 목적을 설명하는 설명문이 있음
    * 브라우저가 닫히면 쿠키를 강제로 삭제 할 수 있음
    * 초 단위의 상대 값으로 쿠키의 생명주기를 결정, Max-Age
    * 단순히 도메인과 경로뿐 아니라 URL의 포트번호로도 쿠키를 제어할 수 있다
    * 도메인, 포트, 경로 필터가 있으면 Cookie 헤더에 담겨 되돌려 보낸다
    * 호환되는 버전 번호
    * 사용자 이름과 추가적인 키워드를 구별하기 위해 Cookie 헤더에 $ 접두어가 있음

### 11.6.8 쿠키와 세션 추적
* 쿠키는 웹 사이트에 수차례 트랜잭션을 만들어내는 사용자를 추적하는 데 사용

### 11.6.9 쿠키와 캐싱
* 쿠키를 캐싱하는 것은 주의해야 함. 이전 사용자의 쿠키가 다른 사용자에게 할당돼버리거나, 누군가의 개인 정보가 다른 이이게 노출되는 최악의 상황이 일어날 수도 있다.

# 12장 기본 인증
* 모든 정보나 업무가 공용은 아니기 때문에, 허가된 사람만이 데이터에 접근하고 업무를 처리할 수 있어야 한다.
* 그러기 위해서는 서버가 사용자가 누구인지 식별할 수 있어야 함

## 12.1 인증
* 인증은 당신이 누구인지 증명하는 것

### 12.1.1 HTTP의 인증요구/응답 프레임워크
* HTTP는 사용자 인증을 하는 데 사용하는 자체 인증요구/응답 프레임워크를 제공
* 서버는 요청을 받으면, 현재 사용자가 누구인지 알 수 있게 비밀번호 같이 개인 정보를 요구하는 `인증 요구`로 응답할 수 있다.

### 12.1.2 인증 프로토콜과 헤더
* HTTP는 필요에 따라 고쳐 쓸 수 있는 제어 헤더를 통해, 다른 인증 프로토콜에 맞추어 확장할 수 있는 프레임워크를 제공
* HTTP에는 기본 인증과 다이제스트 인증이라는 두 가지 공식적인 인증 프로토콜이 있다

|단계   |헤더   |설명   |메서드/상태|
|--|--|--|--|
|요청| |첫 번째 요청에는 인증 정보가 없음|GET
|인증요구|WWW-Authenticate|사용자에게 사용자 이름과 비밀번호를 제공하라는 지시의 의미로 401 상태 정보와 함께 요청을 반려|401 Unauthorized|
|인증|Authorization|클라이언트는 요청을 다시 보낼 때, 인증 알고리즘과 사용자 이름과 비밀번호를 기술한 Authorization 헤더를 함께 보냄| GET
|성공| 인증 정보과 정확하면, 서버는 문서와 함께 응답|200 OK


## 12.3 기본 인증의 보안 결함
* base-64 인코딩은 누구나 디코딩 할 수 있어서 위험함
* 디코딩하기에 복잡한 방식으로 인코딩되어 있다고 하더라도, 인코딩된 문자열 자체를 이용해서 원 서버에 보내서 인증에 성공하고 서버에 접근할 수 있다.

# 13장 다이제스트 인증
* 기본 보안을 안전하게 이용하는 유일한 방법은 SSL과 결합해서 사용하는 것
* 다이제스트 인증은 기본 인증과 호환되는 더 안전한 대체재로서 개발

## 13.1 다이제스트 인증의 개선점
* 다이제스트 인증은 기본 인증의 가장 심각한 결함을 수정한 또 다른 HTTP 인증 프로토콜
    * 비밀번호를 절대로 네트워크를 통해 평문으로 전송하지 않음
    * 인증 체결을 가로채서 재현하려는 악의적인 사람들을 차단
    * 구현하기에 따라서, 메시지 내용 위조를 막는 것도 가능
    * 그 외 몇몇 잘 알려진 형태의 공격을 막음

### 13.1.1 비밀번호를 안전하게 지키기 위해 요약 사용하기
* 다이제스트 인증은 클라이언트의 비밀번호를 비가역적으로 뒤섞은 '지문(fingerprint)' 혹은 '요약(digest)'를 보냄

### 13.1.2 단방향 요약
* 요약은 '정보 본문의 압축'이다
* 요약은 단방향 함수로 동작

### 13.1.3 재전송 방지를 위한 난스(nonce) 사용
* 비밀번호에 대한 단방향 요약을 보내주고, 악의적인 집단이 쉽게 요약에서 원래 비밀번호를 해독할 수 없음을 보장
* 서버는 요약 자체를 재전송하지 못하도록, 클라이언트에게 난스라고 불리는 특별한 증표를 건네줌
* 난스를 비밀번호에 섞으면 난스가 바뀔 때마다 요약도 바뀜


# 14장 보안 HTTP

## 14.1 HTTP를 안전하게 만들기
* 웹은 안전한 방식의 HTTP를 필요로 함
* HTTP 보안 기술을 통해 제공 받아야 하는 것
    * 서버 인증 - 클라이언트는 자신이 위조된 서버가 아닌 진짜와 이야기하고 있음을 알 수 있어야 함
    * 클라이언트 인증 - 서버는 자신이 가짜가 아닌 진짜 사용자와 이야기하고 있음을 알 수 있어야 함
    * 무결성 - 데이터가 위조되는 것으로부터 안전해야 함
    * 암호화 - 도청에 대한 걱정 없이 서로 대화할 수 있어야 함
    * 효율 - 알고리즘이 빨라야 됨
    * 편재성(Ubiquity) - 모든 클라이언트와 서버에서 지원되어야 함
    * 관리상 확장성 - 어디서든 즉각적인 보안 통신을 할 수 있어야 함
    * 적응성 - 현재 알려진 최서의 보안 방법을 지원해야 한다
    * 사회적 생존성 - 사회의 문화적, 정치적 요구를 만족시켜야 한다

### 14.1.1 HTTPS
* HTTPS는 HTTP를 안전하게 만드는 방식 중에서 가장 인기 있는 것
* HTTPS를 사용할 때, 모든 HTTP 요청과 응답 데이터는 네트워크로 보내지기 전에 암호화 됨
* HTTPS는 HTTP의 하부에 전송 레벨 암호 보안 계층을 제공. 이 보안 계층은 SSL 혹은 TLS를 이용하여 구현

## 14.2 디지털 암호학
* 암호
    * 텍스트를 아무나 읽지 못하도록 인코딩하는 알고리즘
* 키
    * 암호의 동작을 변경하는 숫자로 된 매개변수
* 대칭키 암호 체계
    * 인코딩과 디코딩에 같은 키를 사용
* 비대칭키 암호 체계
    * 인코딩과 디코딩에 다른 키를 사용
* 공개키 암호법
    * 비밀 메시지를 전달하는 수백만 대의 컴퓨터를 쉽게 만들 수 있는 시스템
* 디지털 서명
    * 메시지가 위조 혹은 변조되지 않았음을 입증하는 체크섬
* 디지털 인증서
    * 신뢰할 만한 조직에 의해 서명되고 검증된 신원 확인 정보

### 14.2.1 비밀 코드의 기술과 과학
* 암호법은 메시지 인코딩과 디코딩에 대한 과학이자 기술임

### 14.2.2 암호(cipher)
* 암호법은 암호라 불리는 비밀 코드에 기반함
* 암호란 메시지를 인코딩하는 어떤 특정한 방법과 나중에 그 비밀 메시지를 디코딩하는 방법

### 14.2.3 암호 기계
* 기술이 진보하면서, 사람들은 복잡한 암호로 메시지를 빠르고 정확하게 인코딩하고 디코딩하는 기계를 만듬

### 14.2.4 키가 있는 암호
* 기계들에는 암호의 동작방식을 변경할 수 있는 큰 숫자로 된 다른 값을 설정할 수 있는 다이얼이 달려있다.
* 이러한 암호 매개변수를 키라고 부름

### 14.2.5 디지털 암호
* 디지털 계산의 도래로, 두 가지 주요한 발전이 있음
    * 복잡한 인코딩과 디코딩 알고리즘이 가능해짐
    * 매우 큰 키를 지원하는 것이 가능해짐. 키가 길수록 인코딩의 많은 조합이 가능해지고 무작위로 추측한 키에 의한 크래킹이 어려워 짐

## 14.3 대칭키 암호법
* 인코딩 할때외 디코딩 할때의 키가 같음
* 발송자와 수신자 모두 통신을 위해 비밀키를 똑같이 공유해야 함
* DES, Triple-DES, RC2, RC4

### 14.3.1 키 길이와 열거 공격
* 비밀 키가 누설되면 안됨
* 무차별로 모든 키 값을 대입해보는 공격을 열거 공격이라 함(무차별 대입공격, 브루스 포스가 맞지 않나?)

### 14.3.2 공유키 발급하기
* 대칭키 암호화의 단점은 발송자와 수신자가 서로 대화하려면 둘 다 공유키를 가져야 한다는 것

## 14.4 공개키 암호법
* 두 개의 비대칭 키를 사용
* 하나는 메시지를 인코딩, 하나는 메시지를 디코딩
* 인코딩 키는 공개 되어 있음
* 호스트만 개인 디코딩 키를 알고 있음

## 14.5 디지털 서명
* 누가 메시지를 썼는지 알려주고 그 메시지가 위조되지 않았음을 증명하기 위해 메시지에 서명을 하도록 하는데 사용

### 14.5.1 서명은 암호 체크섬이다
* 디지털 서명은 메시지에 붙어이쓴 특별한 암호 체크섬이다
    * 서명은 메시지를 작성한 저자가 누군지 알려줌
    * 서명은 메시지 위조를 방지

## 14.6 디지털 인증서
* 디지털 인증서(cert)는 신뢰할 수 있는 기관으로부터 보증 받은 사용자나 회사에 대한 정보를 담고 있음

### 14.6.1 인증서의 내부
* 디지털 인증서에는 또한 공식적으로 '인증 기관'에 의해 디지털 서명된 정보의 집합이 담겨 있음
    * 대상의 이름(사람, 서버, 조직 등)
    * 유효 기간
    * 인증서 발급자(누가 이 인증서를 보증하는가)
    * 인증서 발급자의 디지털 서명
    * 보통 공개키도 담고 있음

### 14.6.3 서버 인증을 위해 인증서 사용하기
* 사용자가 HTTPS를 통한 안전한 웹 트랜잭션을 시작할 때, 최신 브라우저는 자동으로 접속한 서버에서 디지털 인증서를 가져옴
* 서버 인증서가 담고 있는 필드
    * 웹 사이트의 이름과 호스트 명
    * 웹 사이트의 공개키
    * 서명 기관의 이름
    * 서명 기관의 서명

## 14.7 HTTPS의 세부사항
* HTTPS는 HTTP 프로토콜에 대칭, 비대칭 인증서 기반 암호 기법의 강력한 집합을 결합한 것

### 14.7.1 HTTPS 개요
* HTTPS는 보안 전송 계층을 통해 전송되는 HTTP이다
* HTTPS의 보안 계층은 SSL과 그것의 현대적 대체품인 TLS로 구현

### 14.7.2 HTTPS 스킴
* URL 스킴에 HTTPS를 적용함으로써 HTTP의 보안 프로토콜 버전을 수행한다고 말해줌

### 14.7.3 보안 전송 셋업
1. 443번 포트로 TCP 커넥션 핸드셰이크 
2. 암호법 매개변수와 교환 키를 협상하면서 SSL 계층 핸드셰이크
3. SSL을 통해 HTTP 요청
4. SSL을 통해 HTTP 응답
5. SSL 닫힘
6. TCP 커넥션 닫힘

### 14.7.4 SSL 핸드셰이크
* 암호화된 HTTP 메시지를 보낼 수 있게 되기 전에, 클라이언트와 서버는 SSL 핸드셰이크를 해야 됨
    * 프로토콜 버전 번호 교환
    * 양쪽이 알고 있는 암호 선택
    * 양쪽의 신원을 인증
    * 채널을 암호화하기 위한 임시 세션 키 생성

### 14.7.5 서버 인증서
* SSL은 서버 인증서를 클라이언트로 나르고, 다시 클라이언트 인증서를 서버로 날라주는 상호 인증을 지원
* 클라이언트 인증서는 잘 안씀
* 보안 HTTPS 트랜잭션은 항상 서버 인증서를 요구

### 14.7.6 사이트 인증서 검사
* 최신 웹브라우저들 대부분은 인증서에 대해 간단하게 기본적인 검사를 하고 그 결과를 더 철저한 검사를 할 수 있는 방법과 함께 사용자에게 알려줌

* 날짜 검사 : 인증서의 시작 및 종료일 검사
* 서명자 신뢰도 검사 : 모든 인증서는 서버를 보증하는 어떤 인증 기관에 의해 서명되어 있다. 여러 가지 수준의 인증서가 있음
* 서명 검사 : 서명 기관이 믿을 만하다고 판단하면, 브라우저는 서명기관의 공개키를 서명에 적용하여 그의 체크섬과 비교해봄으로써 인증서의 무결성을 검사
* 사이트 신원 검사 : 인증서의 도메인 이름이 대화 중인 서버의 도메인 이름과 맞는지 검사

### 14.7.7 가상 호스팅과 인증서
* 가상 호스트(하나의 서버에 여러 호스트 명)로 운영되는 사이트 보안 트래픽을 다루는 것은 까다로운 경우도 많음

## 14.9 프락시를 통한 보안 트래픽 터널링
* 클라이언트가 서버로 보낼 데이터를 서버의 공개키로 암호화하기 시작했다면, 프락시는 HTTP 헤더를 읽을 수 없고, 요청을 어디로 보내야 하는지 알 수 없다
* HTTPS SSL 터널링 프로토콜을 이용해서, 클라이언트는 프락시에게 자신이 연결하고자 하는 호스트와 포트를 말해줌

# 4부, 엔터티, 인코딩, 국제화
* 엔터티, 인코딩 : HTTP 콘텐츠의 형식과 문법에 대해 설명
* 국제화 : 전 세계 사람들이 여러 언어와 문자 집합으로 된 콘텐츠를 주고받을 수 있게 해주는 웹 표준
* 콘텐츠 협상, 트랜스코딩 : 어떤 콘텐츠를 받아들일 것인지 협상하는 메커니즘에 대해 설명

# 15장 엔터티와 인코딩
* HTTP는 콘텐츠를 나르기 위한 잘 라벨링된 엔터티를 사용

## 15.1 메시지는 컨테이너, 엔터티는 화물
* HTTP 메시지를 인터넷 운송 시스템의 컨테이너라고 생각하면, HTTP 엔터티는 메시지의 실질적인 화물임
* 엔터티는 HTTP 헤더에서 엔터티와 관련된 헤더와 HTTP 메시지의 본문을 가리킴
```http
HTTP/1.0 200 OK
Server. Netspace-Interprice/3.6
Date: Sun, 17 Sep 2000 00:01:05 GMT
Content-type: text/plain    ← 엔터티 헤더
Content-length: 18          ↵

Hi! I'm a message!          ← 엔터티 본문
```

* Content-Type : 엔터티에 의해 전달된 객체의 종류
* Content-Length : 전달되는 메시지의 길이나 크기
* Content-Language : 전달되는 객체와 가장 잘 대응되는 자연어
* Content-Encoding : 객체 데이터에 대해 행해진 변형
* Content-Location : 요청 시점을 기준으로 객체의 또 다른 위치
* Content-Range : 받은 엔터티가 부분 엔터티라면, 엔터티가 전체에서 어느 부분에 해당하는지 정의
* Content-MD5 : 엔터티 본문의 콘텐츠에 대한 체크섬
* Last-Modified : 서버에서 이 콘텐츠가 생성 혹은 수정된 날
* Expires : 이 엔터티 데이터가 더 이상 신선하지 않은 것으로 간주되기 시작하는 날짜와 시각
* Allow : 이 리소스에 대해 어떤 요청 메서드가 허용되는지
* ETag : 이 인스턴스에 대한 고유한 검사기. 엔터티 헤더는 아니지만 엔터티와 관련된 많은 동작을 위해 중요흠
* Cache-Control : 이 문서가 어떻게 캐시될 수 있는지에 대한 지시자. 엔터티 헤더는 아님

### 15.1.1 엔터티 본문
* 엔터티 본문은 가공되지 않은 데이터만을 담고 있음
* 다른 정보들은 모두 헤더에 담겨 있음

## 15.2 Content-Length: 엔터티의 길이
* Content-Length 헤더는 메시지의 엔터티 본문의 크기를 바이트 단위로 나타냄
* 압축된 파일은 압축된 후의 크기
* 서버 충돌로 인해 메시지가 잘렸는지 감시할 때, 지속 커넥션을 공유하는 메시지를 올마르게 분할하고자 할 때 필요

### 15.2.1 잘림 검출
* 옛날 버전의 HTTP는 커넥션이 닫힌 것을 보고 메시지가 끝났음을 인지
* 클라이언트는 Content-Length가 없으면 커넥션이 정상적으로 닫힌 것인지 메시지 전송 중에 서버에 충돌이 발생한 것인지 구분하지 못함

### 15.2.2 잘못된 Content-Length
* Content-Length가 잘못되면 없는 것 보다 못함

### 15.2.3 Content-Length와 지속 커넥션(Persistent Connection)
* 지속커넥션에서 Content-Length 헤더는 클라이언트에게 메시지 하나가 어디서 끝나고 다음 시작은 어딘지 알려준다.

### 15.2.4 콘텐츠 인코딩
* HTTP는 보안을 강화하거나 압축을 통해 공간을 절약할 수 있도록, 엔터티 본문을 인코딩할 수 있게 해줌
* 본문의 컨텐츠가 인코딩되어 있다면, Content-Length 헤더는 인코딩된 본문의 길이를 바이트 단위로 정의

## 15.3 엔터티 요약
* HTTP가 일반적으로 TCP/IP와 같이 신뢰할 만한 전송 프로토콜 위에서 구현됨에도 여러가지 이유로 메시지의 일부분이 전송 중에 변형되는 일이 일어남
* 엔터티 본문 데이터에 대한 의도하지 않은 변경을 감지하기 위해, 최도 엔터티가 생성될 때 송신자는 데이터에 대한 체크섬을 생성할 수 있음
* 수신자는 변경을 잡아내기 위해 해당 체크섬으로 기본적인 검사를 할 수 있음
* Content-MD5 헤더는 서버가 엔터티 본문에 MD5 알고리즘을 적용한 결과를 보내기 위해 사용
* Content-MD5는 잘 사용 안되고 Want-Digest를 제안. 헤더에 품질값(quality value)를 이용해 여러 요약 알고리즘을 제안하고 각각에 대한 선호도를 지정할 수 있다.

## 15.4 미디어 타입과 차셋(Charset)
* Content-Type 헤더 필드는 엔터티 본문의 MIME 타입을 기술
* MIME 타입은 전달되는 데이터 매체의 기저 형식의 표준화된 이름
* MIME 형식
    * `주 미디어 타입(텍스트 이미지 오디오)/부 타입(subtype)`

### 15.4.1 텍스트 매체를 위한 문자 인코딩
* Content-Type 헤더는 내용 유형을 더 자세히 지정하기 위한 선택적인 매개변수도 지원
* 엔터티 비트 집합을 텍스트 파일의 글자들로 변환하기 위한 charset 매개변수가 대표적인 예
```http
Content-Type: text/html; charset=iso-8859-4
```

### 15.4.2 멀티파트 미디어 타입
* MIME 멀티파트 이메일 메시지는 서로 붙어있는 여러 개의 메시지를 포함하며, 하나의 복합 메시지로 보내짐
* 각 구성요소는 자족적으로 자신에 대해 서술하는 헤더를 포함
* 문자열 하나로 서로의 경계가 식별

### 15.4.3 멀티파트 폼 제출
* HTTP 폼을 채우서 제출하면, 가변 길이 텍스트 필드와 업로드 될 객체는 각각이 멀티파트 본문을 구성하는 하나의 파트가 되어 보내짐
* Content-Type에서 multipart/* 타입은 boundary=[String]를 이용해서 본문의 서로 다른 부분을 구분하기 위한 구분자를 지정

## 15.5 콘텐츠 인코딩
* HTTP 애플리케이션은 콘텐츠를 보내기 전에 인코딩 하려고 할때가 있음
* 인코딩은 발송하는 쪽에서 콘텐츠에 적용

### 15.5.1 콘텐츠 인코딩 과정
1. 웹 서버가 원본 Content-Type과 Content-Length 헤더를 수반한 원본 응답 메시지를 생성
2. 콘텐츠 인코딩 서버가 인코딩된 메시지를 생성. 인코딩된 메시지는 Content-Type은 같지만 Content-Length가 변경. Content-Encoding 헤더를 인코딩된 메시지에 추가
3. 수신 측은 인코딩된 메시지를 받아서 디코딩하고 원본을 얻음

### 15.5.2 콘텐츠 인코딩 유형
* gzip : GNU zip 인코딩이 적용. 가장 효율적이고 널리 쓰임
* compress : 유닉스 파일 압축 프로그램인 compress가 실행
* delfate : zlib 포맷으로 압축
* identity : 어떤 인코딩도 수행하지 않음. 기본값

### 15.5.3 Accept-Encoding 헤더
* 클라이언트가 해독할 수 없는 방법으로 콘텐츠를 인코딩 하면 안됨
* 클라이언트는 자신이 지원하는 인코딩 목록을 Accpet-Encoding 요청 헤더를 통해 전달

## 15.6 전송 인코딩과 청크 인코딩
* 메시지 데이터가 네트워크를 통해 전송되는 방법을 바꾸기 위해 전송 인코딩을 메시지에 적용할 수 있다

### 15.6.1 안전한 전송
* HTTP에서 전송된 메시지의 본문이 문제를 일으킬 수 있는 이유

* 알 수 없는 크기
    * 몇몇 서버는 데이터의 끝을 알리는 특별한 종결 꼬리말을 포함시켜 전송 인코딩으로 데이터를 보내려 시도
* 보안
    * 메시지를 알아보기 어렵게 뒤섞는 방법. 흔한 방법은 아님

### 15.6.2 Transfer-Encoding 헤더
* Transfer-Encoding
    * 안전한 전송을 위해 어떤 인코딩이 메시지에 적용되었는지 알림
* TE
    * 어떤 확장된 전송 인코딩을 사용할 수 있는지 서버에서 알려주기 위해 요청 헤더에서 사용

### 15.6.3 청크 인코딩
* 청크 인코딩은 메시지를 일정 크기의 청크 여럿으로 쪼갬
* 각 청크는 순차적으로 전송
* 청크 인코딩은 전송 인코딩의 한 형태이며 본문이 아닌 메시지의 속성임
* 지속 커넥션에서 서버는 일정 크기의 청크를 계속 보내다가 크기가 0인 청크를 통해서 메시지가 끝났음을 알리고 다음 메시지가 시작

### 15.6.4 콘텐츠와 전송 인코딩의 조합
* 콘텐츠 인코딩과 전송 인코딩은 동시에 사용될 수 있음

## 15.7 시간에 따라 비뀌는 인스턴스
* 같은 URL은 시간에 따라 다른 버전의 객체를 가리킬 수 있다
    * 뉴스 홈페이지 같은 경우 시간에 따라 보여지는게 다름

## 15.8 검사기와 신선도
* 클라이언트에서 캐시된 문서가 만료되면, 클라이언트는 반드시 서버에게 최신 사본을 요구

### 15.8.1 신선도
* 서버는 클라이언트에게 얼마나 오랫동안 콘텐츠를 캐시하고 그것이 신선하다고 가정할 수 있는지에 대한 정보를 줌
* Expires나 Cache-Control 헤더를 통해 정보 제공
* Expires : 문서가 만료되어 더 이상 신선하다고 간주할 수 없게 되는 정확한 날짤르 명시
* Cache-Control : 문서의 최대 수명을 문서가 서버를 떠난 후로부터의 총 시간을 초 단위로 정함

### 15.8.2 조건부 요청과 검시가
* 캐시의 사본이 요청되었을 때, 더 이상 신선하지 않다면 캐시는 자신이 갖고 있는 사본을 신선한 것으로 만들어야 됨
* HTTP는 클라이언트에게 리소스가 바뀐 경우에만 사보을 요청하는 조건부 요청을 할 수 있는 방법을 제공
* 조건부 요청은 'If-'로 시작하는 조건부 헤더에 의해 구현

|요청 유형  |검사기 |설명   |
|--|--|--|
|If-Modified-Since|Last-Modified|지난번 Last-Modified 응답 헤더에 들어있던 시각에 마지막으로 수정된 버전이 더 이상 최신 버전이 아니라면 그 리소스의 사본을 보냄|
|If-Unmodified-Since|Last-Modified|마지막으로 수정된 버전에서 변한것이 없다면 리소스의 사본을 보냄|
|if-Match|ETag| 지난번 엔터티 태그와 같다면 리소스의 사본을 보내라
|if-None-Match|ETag | 지난번 엔터티 태그와 다르면 리소스 사본을 보내라

## 15.9 범위 요청
* HTTP는 클라이언트가 문서의 일부분이나 특정 범위만 요청할 수 있도록 해줌
* 다운로드 하다가 3/4 지점에서 문제가 생겼다 복구되면 해당 지점부터 다시 받을 수 있게 해줌

## 15.10 델타 인코딩
* 델타 인코딩은 객체 전체가 아닌 변경된 부분에 대해서만 통신하여 전송량을 최적화하는 HTTP 프로토콜의 확장

# 16장 국제화
* HTTP는 여러 언어와 문자로 된 국제 문서들의 처리 및 전송을 지원해야 함

## 16.1 국제적인 콘텐츠를 다루기 위해 필요한 HTTP 지원
* HTTP 메시지는 어떤 언어로 된 콘텐츠든, 이미지, 동영상 혹은 그 외 다른 종류의 미디어처럼 실어 나를 수 있다.
* 서버는 클라이언트에게 문서의 문자와 언어를 HTTP Content-Type charset 매개 변수와 Content-Language 헤더를 통해 알려줌
* 클라이언트는 서버에게 어떤 차셋 인코딩 알고리즘들과 언어들을 이해하며 그중 무엇을 선호하는지 말해주기 위해 Accept-Charset과 Accept-Language 헤더를 보냄

## 16.2 문자집합과 HTTP
* 웹 국제화에서 가장 중요한 국제 알파벳 스크립트와 그들의 문자집합 인코딩에 대해 설명

### 16.2.1 차셋(Charset)은 글자를 비트로 변환하는 인코딩이다
* HTTP 차셋 값은, 어떻게 엔터티 콘텐츠 비트들을 특정 문자 체계의 글자들로 바꾸는지 말해줌.

### 16.2.2 문자집합과 인코딩은 어떻게 동작하는가
* 비트들을 문자로 변환하는 디코딩 알고리즘을 지칭하고 적용하는 표준화된 방법이 필요하다
* 문서를 이루는 비트를 특정 코딩된 문자집합의 특정 문자 코드로 변환. 문자 코드는 문자집합의 특정 요소를 선택하기 위해 사용

### 16.2.3 잘못된 차셋은 잘못된 글자들을 낳는다
* 클라이언트가 잘못된 charset 매개변수를 사용한다면, 클라이언트는 이상한 깨진 글자를 보여주게 됨

### 16.2.4 표준화된 MIME 차셋 값
* 특정 문자 인코딩과 특정 코딩된 문자집합의 결합을 MIME 차셋이라고 부름

### 16.2.5 Content-Type charset 헤더와 META 태그
* 웹 서버는 클라이언트에게 MIME 차셋 태그를 charset 매개변수와 함께 Content-Type 헤더에 담아 보냄
* 문자집합이 명시적으로 나열되지 않았다면 수신자는 문서의 콘텐츠로부터 문자집합을 추측

### 16.2.6 Accept-Charset 헤더
* HTTP 클라이언트는 서버에게 어떤 문자 체계를 지원하는지 Accept-Charset 요청 헤더를  통해 알려줌

## 16.3 다중언어 문자 인코딩에 대한 지침
* 국제화 애플리케이션과 콘텐츠로 많은 작업을 하는 HTTP 프로그래머는 기술 명세를 이해하고 올바르게 소프트웨어를 구현하기 위해 다중언어 문자집합 체계에 대해 이해해야 함

### 16.3.1 문자집합 용어
* 문자
    * 알파벳, 글자, 숫자, 구두점, 표의문자, 기호 등 글쓰기의 최소 단위.
* 글리프(glyph)
    * 하나의 글자를 표현하기 위한, 획의 패턴이나 다른 것과 구분되는 유일한 시각적 형태
* 코딩된 문자(coded character)
    * 우리가 글자를 다룰 수 있도록 각 글자에 할당된 유일한 숫자
* 코드 공간(coding space)
    * 문자 코드 값으로 사용하려고 계획해 둔 정수의 범위
* 코드 너비(code width)
    * 각 문자 코드의 (고정된 크기의) 비트 개수
* 사용 가능 문자집합(character repertoire)
    * 글자들에 대한 특정한 작업 집합
* 코딩된 문자집합(coded character set)
    * 사용 가능 문자집합을 받아서 각 글자에 코드 공간의 코드를 할당해주는 코딩된 문자들의 집합
* 문자 인코딩 구조
    * 숫자로 된 문자 코드들을 콘텐츠 비트의 연속으로 인코딩하는 알고리즘

### 16.3.2 charset은 형편없는 이름이다
* MIME 차셋 값은 데이터 비트를 고유한 문자의 코드로 매핑하는 알고리즘의 이름. 이것은 문자 인코딩 구조와 코딩된 문자집합의 개념을 합친것

### 16.3.3 문자
* 문자는 쓰기의 기본적인 구성요소
* 문자는 글꼴이나 스타일에 독립적

### 16.3.4 글리프(glyphs), 연자(ligatures) 그리고 표현 형태
* 문자는 유일하고 추상화된 언어의 요소
* 글리프는 각 글자를 그리는 특정한 방법
* 많은 필기체와 활자체가 인접한 글자들이 부드럽게 이어지는 연자를 지원

### 16.3.5 코딩된 문자집합
* 정수를 글자로 대응시킴
* 코드 번호로 인덱싱된 배열로 구현

### 16.3.6 문자 인코딩 구조
* 문자 인코딩 구조들은 숫자로 된 문자 코드를 콘텐츠 비트들로 변환하고 다른 쪽에서는 그들을 다시 문자 코드로 환원
* 문자 인코딩 구조의 종류
    * 고정폭 : 각 코딩된 문자를 고정된 길이의 비트로 표현
    * 가변폭(비모달) : 다른 문자 코드 번호에 다른 길이의 비트를 사용
    * 가변폭(모달) : 다른 모드로의 전환을 위해 특별한 escape 패턴을 사용

## 16.4 언어 태그와 HTTP
* 언어 태그는 언어에 이름을 붙이기 위한 짧고 표준화된 문자열

### 16.4.1 Content-Language 헤더
* Content-Language 엔터티 헤더 필드는 엔터티가 어떤 언어 사용자를 대상으로 하고 있는지 서술

### 16.4.2 Accept-Language 헤더
* HTTP는 우리에게 우리의 언어 제약과 선호도를 웹 서버에 전달할 수 있게 해줌

### 16.4.5 대소문자의 구분 및 표현
* 모든 태그는 대소문자가 구분되지는 않음
* 관용적으로 언어는 소문자, 국가는 대문자 사용

## 16.5 국제화된 URI
* URI는 국제화를 그다지 지원하지 않음
* URI는 US-ASCII의 부분집합으로 구성되어 있음

### 16.5.1 국제적 가독성 vs 의미 있는 문자들
* URI 설계자들은 전 세계의 모두가 다른 이들과 공유할 수 있기를 원했고, URI가 사용하기 쉽고 기억하기 쉽길 바랬다. 이 두 목표는 서로 충돌함
* 지구 곳곳의 사람등리 URI에 접근하기 쉽게, 설계자들은 매우 제한된 공통 문자집합을 선택
* 그래서 비영어권 사람들은 쉽게 사용하진 못함

### 16.5.2 URI에서 사용될 수 있는 문자들
* 예약되지 않은 문자 [A-Za-z0-9] - _ . ! ~ * " ( )
* 예약된 문자 : ; / ? : @ & = = $ ,
* 이스케이프 : "%" <HEX> <HEX>

### 16.5.3 이스케이핑과 역이스케이핑
* URI 이스케이프는 예약된 문자나 다른 지원하지 않는 글자들을 안전하게 URI에 삽입할 수 있는 방법을 제공
* 이스케이프는 퍼센트 하나와 뒤이은 16진수 글자 둘로 이루어진 세 글자 문자열

# 17장 내용 협상과 트랜스코딩
* 종종 하나의 URL이 여러 리소스에 대응할 필요가 있는 경우가 있음(클라이언트가 요청하는 언어가 다른경우)
* HTTP는 클라이언트와 서버가 이러한 판단을 할 수 있도록 내용 협상 방법을 제공
* 트랜스코딩은 HTTP 클라이언트와 서버 사이의 내용 협상에 대한 응답에서 수행

## 17.1 내용 협상 기법
|기법|동작 방법|장점|단점|
|-|-|-|-|
|클라이언트 주도|클라이언트가 선택지 중에 선택|서버 입장에서 구현이 단순|대기시간이 증가|
|서버 주도|요청 헤더를 검증해서 서버가 결정|클라이언트 주도보빠름|결정을 추측해야 하는 상황이 있음|
|투명|투명한 중간 장치가 서버 대신 협상|웹 서버가 협상을 할 필요가 없음. 클라이언트 주도보다 빠름|정형화된 명세가 없음

## 17.2 클라이언트 주도 협상
* 서버에게 있어 가장 쉬운 방법
* 두 번의 요청이 필요
* 북마크가 어려움

## 17.3 서버 주도 협상
* 클라이언트가 반드시 선호하는 것을 보내야만 서버가 현명한 결정 가능
* 응답 시간을 줄일 수 있음
* 적절한 응답을 계산하기 위한 방법 2가지
    * 내용 협상 헤더
    * 내용 협상 헤더 외 다른 헤더

### 17.3.1 내용 협상 헤더
* Accept : 미디어 타입
* Accept-Language : 언어
* Accept-Charset : 차셋
* Accept-Encoding : 인코딩
* HTTP는 상태가 없는 프로토콜이기 때문에, 클라이언트는 자신의 선호 정보를 반드시 매 요청마다 보내야 함

### 17.3.2 내용 협상 헤더의 품질값
* HTTP 프로토콜은 클라이언트가 각 선호의 카테고리마다 여러 선택 가능한 항목을 선호도와 함께 나열 할 수 있도록 품질값을 정의
```http
Accept-Language: en;q=0.5, fr;q=0.0, nl;q=1.0, tr;q=0.0
```
* 0.0(min) ~ 1.0(max)까지의 범위로 입력 가능.

## 17.4 투명 협상
* 클라이언트 입장에서 협상하는 중개자 프락시를 둠
* 프락시는 클라이언트의 기대가 무엇인지 알고 있고, 클라이언트의 입장에서 협상을 수행할 수 있음
* HTTP/1.1 명세는 투명 협상에 대한 매커니즘이 없음. 대신 Vary 헤더를 정의
* 서버 응답에 Vary 헤더를 포함시켜 보냄으로써 중개자에게 내용 협상을 위해 어떤 헤더를 사용하고 있는지 알려줌

### 17.4.1 캐시와 얼터네이트
* 콘텐츠를 캐시하는 것은 그 콘텐츠가 나중에 재사용될 것이라고 예상하기 때문
* 캐시는 클라이언트에게 올바로 캐시된 응답을 돌려주기 위해, 서버가 응답을 돌려줄 때 사용했던 의사결정 로직의 상당 부분을 그대로 사용

### 17.4.2 Vary 헤더
* HTTP Vary 응답 헤더는 서버가 문서를 선택하거나 커스텀 콘텐츠를 생성할 때 고려한 클라이언트 요청 헤더 모두를 나열

## 17.5 트랜스코딩
* 서버가 클라이언트의 요구에 맞는 문서를 갖고 있지 않다면, 트랜스코딩 옵션을 사용해서 클라이언트가 사용할 수 있는 무언가로 변환할 수 있다.

### 17.5.1 포맷 변환
* 데이터를 클라이언트가 볼 수 있도록 다른 포맷으로 변환하는 것

### 17.5.2 정보 합성
* 문서에서 정보의 요점을 추출하는 것
* 각 절의 제목에 기반한 문서의 개요 생성, 페이지에서 광고 및 로고 제거 등

### 17.5.3 콘텐츠 주입
* 동적으로 페이지에 콘텐츠를 추가하는 것
* 자동 광고 생성, 사용자 추적 시스템 등

### 17.5.4 트랜스코딩 vs 정적으로 미리 생성해놓기
* 트랜스코딩의 대안은 웹 서버에서 웹페이지 여러 가지 사본을 만드는 것

# 5부 콘텐츠 발행 및 배포
* 웹 호스팅 : HTTP가 가상 웹 호스팅을 지원하는 현대의 웹 호스팅 환경에서 서버에 배포하는 방법들에 대해 논의
* 배포 시스템 : 웹 콘텐츠를 만들고, 그것을 웹 서버에 올리는 기술들을 알아봄
* 리다이렉션과 부하 균형 : 유입되는 웹 트래픽을 서버군에 분산시키는 기법과 도구
* 로깅과 사용 추적 : 로그 포맷과 일반적인 질문

# 18장 웹 호스팅
* 콘텐츠 리소스를 저장, 중개, 관리하는 일을 통틀어 웹 호스팅이라 함

## 18.1 호스팅 서비스
* 웹이 빠르게 성장하면서 전문적으로 관리하는 웹 호스팅 서비스를 제공하는 여러 신사업이 만들어 짐
    * 물리적인 장비 관리
    * 고객이 직접 콘텐츠를 제공할 수 있는 총체적인 웹 호스팅

### 18.1.1 간단한 예: 전용 호스팅
* 대여할 수 있는 고성능 웹 서버들로 구성된 랙을 ISPS가 가지고 있음
* 사용자는 ISP가 구매해 유지보수하고 있는 전용 웹 서버를 임대
* 추가적인 서버를 즉시 제공할 수 있음
* 다양한 도메인을 적용할 수 있음

## 18.2 가상 호스팅
* 웹 호스팅 업자는 컴퓨터 한 대를 여러 고객이 공유하게 해서 저렴한 웹 호스팅 서비스를 제공. 이를 공유 호스팅 혹은 가상 호스팅이라 부름

### 18.2.1 호스트 정보가 없는 가상 서버 요청
* HTTP/1.0 명세는 공용 웹 서버가 호스팅하고 있는 가상 웹 사이트에 누가 접근하고 있는지 식별하는 기능을 제공하지 않는다
* 때문에 서버가 여러 개의 사이트를 가상 호스팅 하고 있으면, 사용자가 어떤 가상 웹 사이트로 접근하려고 하는것인지 아는 데 필요한 정보가 충분하지 않다

### 18.2.2 가상 호스팅 동작하게 하기
* 초기 명세는 가상 호스팅을 고려하지 않았음. 해당 문제는 모든 HTTP 요청 메시지에 완전한 URL도 포함해 보내게 해서 해결
* 기존 모든 애플리케이션이, 이 명세에 맞추어 업그레이드하기 까지는 오랜 시간이 걸림. 그 와중 생긴 네 가지 기술
    * URL 경로를 통한 가상 호스팅
    * 포트번호를 통한 가상 호스팅
    * IP 주소를 통한 가상 호스팅
    * Host 헤더를 통한 가상 호스팅

### 18.2.3 HTTP/1.1 Host 헤더
* RFC 2068에 정의되어 있는 HTTP/1.1 요청 헤더
* 문법과 사용 방법
    * Host 헤더에는 원본 URL에 있는 요청 리로스에 대한 인터넷 호스트와 포트번호를 기술
    * `Host = "Host" ":" 호스트[":"포트]`
    * Host 헤더에 포트가 기술되어 있지 않으면, 해당 스킴의 기본 포트 사용
    * URL에 IP 주소가 있으면, Host 헤더는 같은 주소를 포함
    * URL에 호스트 명이 기술되어 있으면, Host 헤더는 같은 호스트 명을 포함
    * URL에 호스트 명이 기술되어 있으면, Host 헤더는 URL의 호스트 명이 가리키는 IP 주소를 포함하면 안 됨
    * 클라이언트가 특정 프락시 서버를 사용한다면, Host 헤더에 프락시 서버가 아닌 원 서버의 호스트 명과 포트를 기술
    * 웹 클라이언트는 모든 요청 메시지에 Host 헤더를 기술
    * 웹 프락시는 요청을 전달하기 전에 요청 메시지에 Host 헤더를 추가
    * HTTP/1.1 웹 서버는 Host 헤더 필드가 없는 HTTP/1.1 요청 메시지를 받으면 400 상태 코드로 응답

* Host 헤더의 누락
    * 아직 Host 헤더를 보내지 않는 브라우저가 있음. 가상 호스팅 서버는 Host 헤더가 없을 때 브라우저를 업그레이드 하라는 에러 페이지를 반환

* Host 헤더 해석하기
    1. 요청 메시지에 전체 URL이 기술되어 있으면 Host 헤더 값 무시
    2. 요청 메시지에 없으면 Host 헤더에서 가져옴
    3. 1, 2단계에서 결정 못하면 400 Bad Request 반환

* Host 헤더와 프락시
    * 프락시를 사용할 경우, 원 서버의 이름이 아닌 프락시의 이름을 Host 헤더에 담아서 전송하는 문제가 있음

## 18.3 안정적인 웹 사이트 만들기
* 웹 사이트에 장애가 생기는 몇 가지 상황
    * 서버 다운
    * 트래픽 폭증
    * 네트워크 장애나 손실

### 18.3.1 미러링 된 서버 팜
* 서버 팜은 서로 대신할 수 있고 식별할 수 있게 설정된 웹 서버들의 집합
* 한 곳에서 문제가 생기면 다른 곳에서 전달할 수 있게 미러링 가능
* 클라이언트의 요청이 특정 서버로 가는 두 가지 방법
    * HTTP 리다이렉션 : 콘텐츠에 대한 URL은 마스터 서버의 IP를 가리키고, 마스터 서버는 요청을 받는 즉시 복제 서버로 리다이렉트
    * DNS 리다이렉션 : 콘텐츠의 URL은 네 개의 IP 주소를 가리킬 수 있고, DNS 서버는 클라이언트에게 전송할 IP 주소를 선택할 수 있음

### 18.3.2 콘텐츠 분산 네트워크
* 콘텐츠 분산 네트워크(CDN)은 특정 콘텐츠의 분산을 목적으로 하는 단순한 네트워크

### 18.3.3 CDN의 대리 캐시
* 대리 캐시는 복제 원 서버를 대신해 사용될 수 있음
* 리버스 프락시라고도 불리는 대리 서버는 미러링 된 웹 서버처럼 콘텐츠에 대한 요청을 받음

### 18.3.4 CDN의 프락시 캐시
* 어떤 웹 서버 요청이든지 다 받을 수 있음
* 대리 서버가 있다면 프락시 캐시는 콘텐츠 요청이 있을 때만 저장될 것. 원본 서버 콘텐츠를 정확히 복제한다는 보장이 없음

# 20장 리다이렉션과 부하 군형
* 리다이렉션 기술은 보통 메시지가 프락시, 캐시, 서버 팜의 특정 웹 서버 중 어디에서 끝나는지 판별하기 위해 사용

## 20.1 왜 리다이렉트인가?
* HTTP 애플리케이션은 아래 세 가지를 원하기 때문에 리다이렉션은 필수
    * 신뢰할 수 있는 HTTP 트랜잭션의 수행
    * 지연 최소화
    * 네트워크 대역폭 절약
* 위 이유들 때문에, 웹 콘텐츠는 여러 장소에 배포. 그러면 한 곳에서 실패해도 다른 곳에서 이용 할 수 있으므로 신뢰성 개선
* 기까운 곳에서 데이터를 가져 올 수 있어서 응답시간 단축
* 리다이렉션이란 최적의 분산된 콘텐츠를 찾는 것을 도와주는 기법의 집합

## 20.2 리다이렉트 할 곳
* 서버, 프락시, 캐시, 게이트웨이는 클라이언트 관점에서 보면 모두 서버
* 많은 리다이렉션 기법이 위의 모두에서 동작

## 20.3 리다이렉션 프로토콜의 개요
* 리다이렉션의 목표는 HTTP 메시지를 가용한 웹 서버로 가급적 빨리 보내는 것
* 브라우저 설정, DNS, TCP/IP 라우팅, HTTP는 모두 메시지를 리다이렉트하는 메커니즘을 제공

## 20.4 일반적인 리다이렉션 방법

## 20.4.1 HTTP 리다이렉션
* 웹 서버들은 다른 곳에 요청을 보내라고 말해주는 리다이렉트 메시지를 클라이언트에게 돌려줄 수 있음
* 단점
    * 어떤 서버로 리다이렉트 할지 결정하기 힘듬
    * 페이지에 접근할 때마다 두 번의 왕복이 필요
    * 리다이렉트 서버가 고장나면 다같이 뻗음

## 20.4.2 DNS 리다이렉션
* 클라이언트가 웹 사이트에 접근하려고 시도할 때, DNS는 반드시 아이피 주소로 분석되어야 함
* DNS는 하나의 도메인에 여러 아이피 주소가 결부되는 것을 허용

* DNS 라운드 로빈
    * 웹 서버 팜 전체에 대한 부하의 균형을 유지하기 위한 방법
* 다중 주소와 라운드 로빈 주소 순환
    * DNS 클라이언트는 다중 주소 집합의 첫 번째 주소를 사용
    * 부하 균형을 위해, DNS 서버는 룩업이 끝났을 때마다 주소를 순환
* DNS 캐싱의 효과
    * 클라이언트들이 DNS 결과를 자체적으로 캐싱하면 한 번 간곳만 계속 호출
* 다른 DNS 기반 리다이렉션 알고리즘
    * 부하 균형 알고리즘 : 가장 로드가 적은 웹 서버의 목록을 가장 위로
    * 근접 라우팅 알고리즘 : DNS 서버는 사용자 근처의 웹 서버로 보내는 시도
    * 결함 마스킹 알고리즘 : DNS 서버는 네트워크의 상태를 모니터링하고 요청을 정전이나 기타 장애를 피해서 라우팅 할 수 있음

### 20.4.3 임의 캐스트 어드레싱
* 여러 지리적으로 흩어진 웹 서버들은 정확히 같은 아이피 주소를 갖고 클라이언트의 요청을 클라이언트에서 가장 가까운 서버로 보내주기 위해 백본 라우터의 '최단거리' 라우팅 능력에 의지하는 방식

### 20.4.4 아이피 맥 포워딩
* 특정 맥 주소의 패킷을 받아서 나가는 특정 맥 주소로 포워딩하는 방식

### 20.4.5 아이피 주소 포워딩
* 들어오는 패킷에 대해 TCP/IP 어드레싱을 검증하고 패킷을 목적지 맥 주소가 아니라 목적지 아이피 주소의 변경에 따라 라우팅한다
* NAT를 이용한 방식

## 20.5 프락시 리다이렉션 방법
* 프락시는 클라이언트의 요청을 다른 프락시로 리다이렉트 할 수 있다

### 20.5.1 명시적 브라우저 설정
* 대부분의 브라우저에는 프락시 서버에 접속하기 위해 프락시 이름, 아이피 주소, 포트번호를 설정할 수 있는 풀다운 메뉴가 존재
* 단점
    * 설정 오류나 프락시 서버가 문제가 생기면 접속이 안됨
    * 네트워크 아키텍처를 변경했을 때 그 변경사항을 모든 최종사용자에게 전파하는 것이 어려움

### 20.5.2 프락시 자동 설정
* 올바른 프락시 서버에 접촉하기 위해 브라우저가 동적으로 자신을 설정할 수 있게 하는 자동 설정 방법
* 프락시 자동 설정이라 불림(PAC)

### 20.5.3 웹 프락시 자동발견 프로토콜
* 웹브라우저가 근처의 프락시를 찾아내어 사용할 수 있게 해주는 방법을 제공하는 것을 목적

## 20.6 캐시 리다이렉션 방법

### 20.6.1 WCCP 리다이렉션
* 시스코 시스템즈는 웹 라우터들이 웹 트래픽을 프락시 캐시로 리다이렉트 할 수 있도록 하기 위해 캐시 조직 프로토콜을 개발

## 20.7 인터넷 캐시 프로토콜
* 캐시들이 형제 캐시에서 일어난 캐시 적중을 찾아볼 수 있도록 해줌
* 일종의 캐시 클러스터링 프로토콜

## 20.8 캐시 배열 라우팅 프로토콜
* 대량의 트래픽은 프락시 서버 자체에 과도한 부하를 줌
* 부하를 분산하기 위해 사용하는 프락시 서버를 여러 대로 늘릴 수 있음
* 해당 프로토콜은 프락시의 배열이 클라이언트의 시점에서는 마치 하나의 논리적인 캐시처럼 보이도록 관리해줌

## 20.9 하이퍼텍스트 캐싱 프로토콜
* 형제들이 URL과 모든 요청 및 응답 헤더를 사용하여 서로에게 문서의 존재 여부에 대한 질의를 할 수 있도록 해줌

# 21장 로깅과 사용 추적
* 거의 모든 서버와 프락시는 처리했던 HTTP 트랜잭션을 요약해서 기록

## 21.1 로그란 무엇인가
* 로깅을 하는 이유는 두 가지임
    * 서버나 프락시의 문제 찾기
    * 웹 사이트 접근 통계를 내기 위함
* 일반적으로 로깅하는 필드
    * HTTP 메서드
    * 클라이언트와 서버의 HTTP 버전
    * 요청받은 리소스의 URL
    * 응답 HTTP 상태 코드
    * 요청과 응답 메시지의 크기
    * 트랜잭션이 일어난 시간
    * Referer와 User-Agent 헤더 값

## 21.2 로그 포맷

### 21.2.1 일반 로그 포맷
* remotehost : 요청한 컴퓨터의 호스트
* username : 인증된 요청자의 사용자 이름
* auth-username : 인증된 요청자의 이름
* timestamp : 요청 날짜와 시간
* request-line : HTTP 요청의 행을 그대로 기술
* response-code : 응답의 HTTP 상태 코드
* response-size : 응답 엔터티의 Content-Length

### 21.2.2 혼합 로그 포맷
* 일반 로그 포맷에서 아래 2개가 추가된 것
    * Referer : HTTP 헤더의 Referer
    * User-Agent : HTTP 헤더의 User-Agent

## 21.4 개인 정보 보호에 대해
* 로깅하는 웹 서버와 프락시는 최종 사용자의 개인 정보를 보호하는데 신경을 많이 써야 함
